Singularity> accelerate config
-----------------------------------------------------------------------In which compute environment are you running?
Please select a choice using the arrow or number keys, and selecting wiThis machine                                                           
-----------------------------------------------------------------------Which type of machine are you using?                                   
Please select a choice using the arrow or number keys, and selecting wimulti-GPU                                                              
How many different machines will you use (use more than 1 for multi-node training)? [1]: 1                                                    
Should distributed operations be checked while running for errors? This can avoid timeout issues but will be slower. [yes/NO]: no             
Do you wish to optimize your script with torch dynamo?[yes/NO]:no      
Do you want to use DeepSpeed? [yes/NO]: no                             
Do you want to use FullyShardedDataParallel? [yes/NO]: yes             
-----------------------------------------------------------------------What should be your sharding strategy?
Please select a choice using the arrow or number keys, and selecting wiSHARD_GRAD_OP                                                          
Do you want to offload parameters and gradients to CPU? [yes/NO]: no   
-----------------------------------------------------------------------What should be your auto wrap policy?                                  
Please select a choice using the arrow or number keys, and selecting wiTRANSFORMER_BASED_WRAP                                                 
Do you want to use the model's `_no_split_modules` to wrap. Only applicable for ðŸ¤— Transformers [yes/NO]: yes                                  
-----------------------------------------------------------------------What should be your FSDP's backward prefetch policy?
Please select a choice using the arrow or number keys, and selecting wiBACKWARD_PRE                                                           
-----------------------------------------------------------------------What should be your FSDP's state dict type?                            
Please select a choice using the arrow or number keys, and selecting wiFULL_STATE_DICT                                                        
Do you want to enable FSDP's forward prefetch policy? [yes/NO]: yes    
Do you want to enable FSDP's `use_orig_params` feature? [YES/no]: no   
Do you want to enable CPU RAM efficient model loading? Only applicable for ðŸ¤— Transformers models. [YES/no]: yes
Do you want to enable FSDP activation checkpointing? [yes/NO]: yes
How many GPU(s) should be used for distributed training? [1]:2
-----------------------------------------------------------------------Do you wish to use mixed precision?
Please select a choice using the arrow or number keys, and selecting wifp16                                                                   
accelerate configuration saved at /home/zl5604/.cache/huggingface/accelerate/default_config.yaml 