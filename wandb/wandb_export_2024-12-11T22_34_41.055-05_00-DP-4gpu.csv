"Name","Device Time Total (ms)","CPU Time Total (ms)","Self Device Time Total (ms)","Self CPU Time Total (ms)","Calls","Input Shapes","Device Memory Usage (MB)","Self Device Memory Usage (MB)","CPU Memory Usage (MB)","Self CPU Memory Usage (MB)"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#2}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#2}, at::detail::Array<char*, 2>)","198.52838099999667","0","198.52838099999667","0","973","","0","0","0","0"
"Memset (Device)","12.691340000039366","0","12.691340000039366","0","10272","","0","0","0","0"
"ampere_sgemm_128x64_nn","2263.7879799999996","0","2263.7879799999996","0","3892","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)","631.9473020000044","0","631.9473020000044","0","5042","","0","0","0","0"
"ProfilerStep*","7805.123407000013","13683.648908000001","0","3980.3021229999445","10","","-137719.904296875","-208919.40771484375","0","-0.00000762939453125"
"void at::native::vectorized_elementwise_kernel<4, at::native::tanh_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::tanh_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)","76.47158899998475","0","76.47158899998475","0","974","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)","699.6157559999858","0","699.6157559999858","0","5077","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<float>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<float>, at::detail::Array<char*, 2>)","85.65177700000015","0","85.65177700000015","0","985","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)","735.9956030000338","0","735.9956030000338","0","3086","","0","0","0","0"
"enumerate(DataLoader)#_MultiProcessingDataLoaderIter.__next__","0","9.063809000003026","0","7.546489000002728","21","","0","0","0","0"
"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)","40.43171999999075","0","40.43171999999075","0","2028","","0","0","0","0"
"aten::to","0.6176670000068843","3924.7898830000336","0","1.2804440000180621","3140","","26.40283203125","22.01318359375","-0.0000152587890625","-0.0000152587890625"
"aten::_to_copy","0.6176670000068843","3923.5094390000154","0","2.231798000013456","190","","4.3896484375","0","0","0"
"aten::empty_strided","0","18.255328999967553","0","16.701632999967092","2060","","9510.8115234375","9510.8115234375","0","0"
"aten::copy_","4212.781284000019","4189.445719999977","4212.781284000019","108.54662199991208","2978","","-10046.30126953125","-7266.89453125","-0.000030517578125","-0.00002288818359375"
"cudaMemcpyAsync","0","124.09619800002349","0","124.09619800002349","551","","445.7861328125","445.7861328125","0","0"
"cudaStreamSynchronize","0","6586.855735000012","0","6586.77074700001","201","","0","0","0","0"
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)","577.0133029999747","0","577.0133029999747","0","972","","0","0","0","0"
"cudaPointerGetAttributes","0","0.302960000001955","0","0.2763680000036388","56","","0","0","0","0"
"ampere_sgemm_128x64_tn","2631.928291999996","0","2631.928291999996","0","2196","","0","0","0","0"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})","1828.173637000016","0","1828.173637000016","0","2672","","0","0","0","0"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1} const&)::{lambda(int)#1})","0.40877000000310726","0","0.40877000000310726","0","84","","0","0","0","0"
"void at::native::(anonymous namespace)::cunn_SoftMaxForward<4, float, float, float, at::native::(anonymous namespace)::LogSoftMaxForwardEpilogue>(float*, float const*, int)","299.2424710000027","0","299.2424710000027","0","84","","0","0","0","0"
"void at::native::(anonymous namespace)::nll_loss_forward_reduce_cuda_kernel_2d<float, float, long>(float*, float*, float const*, long const*, float const*, bool, long, long, long, long)","6.414275000002366","0","6.414275000002366","0","84","","0","0","0","0"
"Memcpy DtoD (Device -> Device)","226.25854799999655","0","226.25854799999655","0","86","","0","0","0","0"
"Memcpy PtoP (Device -> Device)","2575.2738159999976","0","2575.2738159999976","0","279","","0","0","0","0"
"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4>)","0.0668149999982561","0","0.0668149999982561","0","21","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)","227.53834699999007","0","227.53834699999007","0","242","","0","0","0","0"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})","0.018145000000251457","0","0.018145000000251457","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::nll_loss_backward_reduce_cuda_kernel_2d<float, long>(float*, float const*, long const*, float const*, float const*, bool, int, int, long, long)","1.602463000004762","0","1.602463000004762","0","44","","0","0","0","0"
"void at::native::(anonymous namespace)::cunn_SoftMaxBackward<4, float, float, float, at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue>(float*, float const*, float const*, long)","273.9113440000025","0","273.9113440000025","0","44","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_128x256_8x4_nt_align1>(cutlass_80_simt_sgemm_128x256_8x4_nt_align1::Params)","705.6154049999864","0","705.6154049999864","0","572","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_256x128_8x4_nn_align1>(cutlass_80_simt_sgemm_256x128_8x4_nn_align1::Params)","456.8858409999985","0","456.8858409999985","0","44","","0","0","0","0"
"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)","70.89368399999734","0","70.89368399999734","0","1100","","0","0","0","0"
"void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)","20.02994599998329","0","20.02994599998329","0","1100","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_64x128_8x5_nt_align1>(cutlass_80_simt_sgemm_64x128_8x5_nt_align1::Params)","436.32951299999536","0","436.32951299999536","0","528","","0","0","0","0"
"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)","48.0272510000004","0","48.0272510000004","0","2156","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::tanh_backward_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::tanh_backward_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)","167.4206840000053","0","167.4206840000053","0","528","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#1}, at::detail::Array<char*, 2>)","109.93990099998442","0","109.93990099998442","0","528","","0","0","0","0"
"ampere_sgemm_128x64_nt","449.73638900001674","0","449.73638900001674","0","528","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_128x64_8x5_nt_align1>(cutlass_80_simt_sgemm_128x64_8x5_nt_align1::Params)","115.1888059999838","0","115.1888059999838","0","528","","0","0","0","0"
"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)","12.955264999993553","0","12.955264999993553","0","528","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<unsigned char>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<unsigned char>, at::detail::Array<char*, 1>)","6.546435999985901","0","6.546435999985901","0","528","","0","0","0","0"
"fmha_cutlassB_f32_aligned_64x64_k64_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, false, false, 64, 64, 64, false>::Params)","614.3914650000023","0","614.3914650000023","0","336","","0","0","0","0"
"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 3, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)","26.011459000009985","0","26.011459000009985","0","528","","0","0","0","0"
"void at::native::(anonymous namespace)::embedding_backward_feature_kernel<float, float, long>(long const*, float const*, float*, int, long, int)","8.309570000001754","0","8.309570000001754","0","88","","0","0","0","0"
"ncclDevKernel_Reduce_Sum_f32_RING_LL(ncclDevComm*, unsigned long, ncclWork*)","4026.547684000006","0","4026.547684000006","0","1672","","0","0","0","0"
"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)","103.31237999998807","0","103.31237999998807","0","2150","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::LpNormFunctor<float, (at::native::NormType)1, float, 1, 1, 0>, float*, int>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::LpNormFunctor<float, (at::native::NormType)1, float, 1, 1, 0>, float*, int)","22.06526700000587","0","22.06526700000587","0","77","","0","0","0","0"
"void at::native::lpnorm_cleanup<float, (at::native::NormType)1, float, float>(float const*, at::native::TensorListAddresses, int)","0.040925999999570195","0","0.040925999999570195","0","11","","0","0","0","0"
"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::NormTwoOps<float, float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::NormTwoOps<float, float, float>, unsigned int, float, 4>)","0.03363100000034319","0","0.03363100000034319","0","11","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::reciprocal_kernel_cuda(at::TensorIteratorBase&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::reciprocal_kernel_cuda(at::TensorIteratorBase&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)","0.01475200000195764","0","0.01475200000195764","0","11","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)","0.016480000002833547","0","0.016480000002833547","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarTensorFunctor<float, 1, 1, 0>, std::multiplies<float>, float*, float>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarTensorFunctor<float, 1, 1, 0>, std::multiplies<float>, float*, float)","46.54904699999164","0","46.54904699999164","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::multiplies<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::multiplies<float>, float)","94.57917799999471","0","94.57917799999471","0","154","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::TernaryOpScalarFunctor<float, 2, 2, 0>, at::native::LerpFunctor<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::TernaryOpScalarFunctor<float, 2, 2, 0>, at::native::LerpFunctor<float>, float)","69.27517999999738","0","69.27517999999738","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<3>, at::native::(anonymous namespace)::PointwiseOpScalarFunctor<float, 3, 3, 0>, std::multiplies<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<3>, at::native::(anonymous namespace)::PointwiseOpScalarFunctor<float, 3, 3, 0>, std::multiplies<float>, float)","69.1962290000142","0","69.1962290000142","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::UnaryOpFunctor<float, 2, 1, 1>, at::native::Sqrt<float> >(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::UnaryOpFunctor<float, 2, 1, 1>, at::native::Sqrt<float>)","46.86690599999862","0","46.86690599999862","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 1>, at::native::(anonymous namespace)::BinaryOpScalarListFunctor<float, 1, 1, 0>, std::divides<float> >(at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 1>, at::native::(anonymous namespace)::BinaryOpScalarListFunctor<float, 1, 1, 0>, std::divides<float>)","46.86405299999804","0","46.86405299999804","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::plus<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::plus<float>, float)","47.02794999999926","0","47.02794999999926","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 3>, at::native::(anonymous namespace)::PointwiseOpScalarListFunctor<float, 3, 3, 0>, std::divides<float> >(at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 3>, at::native::(anonymous namespace)::PointwiseOpScalarListFunctor<float, 3, 3, 0>, std::divides<float>)","88.44632199999329","0","88.44632199999329","0","77","","0","0","0","0"
"ProfilerStep*","13239.241545000003","0","13239.241545000003","0","10","","0","0","0","0"
"Memcpy HtoD (Pinned -> Device)","0.31888099999981934","0","0.31888099999981934","0","40","","0","0","0","0"
"DataParallel.forward","7221.7527270000155","1865.6351459999996","0","886.6665100000209","20","","72808.73046875","-3525.8203125","0","0"
"Scatter","0.298786000007065","23.396405999998446","0","4.411258999999846","50","","1.8896484375","0","0","0"
"aten::chunk","0","2.1594999999997673","0","0.24082600000256207","40","","0","0","0","0"
"aten::split","0","1.9186739999972051","0","0.6366540000047535","40","","0","0","0","0"
"aten::narrow","0","76.26342299995804","0","24.26922899991693","11960","","0","0","0","0"
"aten::slice","0","52.600072000044634","0","44.05621200005931","12040","","-1135.1318359375","-760.4990234375","0","0"
"aten::as_strided","0","25.748734999931067","0","25.748734999931067","26440","","-2198.12744140625","-2198.12744140625","0.00005340576171875","0.00005340576171875"
"cudaEventRecord","0","14.864745000075665","0","14.864745000075665","10940","","0","0","0","0"
"cudaStreamWaitEvent","0","29.088240999944624","0","29.077563999944484","10940","","0","0","0","0"
"DataParallel.forward","28671.521503","0","28671.521503","0","80","","0","0","0","0"
"Broadcast","3371.963102999999","144.133426999999","3354.721891999998","40.633733000082195","10","","14578.095703125","-3284.0625","0","0"
"aten::flatten_dense_tensors","98.93602499999048","102.3049560000191","0","21.81477299995639","2080","","19933.1279296875","0","0","0"
"aten::view","0","55.67248700000695","0","55.67248700000695","30640","","-7254.2236328125","-7254.2236328125","0.0000152587890625","0.0000152587890625"
"aten::empty","0","125.03054299996141","0","105.57787299996149","8477","","137695.86279296875","137695.86279296875","0.0000152587890625","0.0000152587890625"
"cudaStreamGetCaptureInfo_v2","0","2.9235059999598887","0","2.9235059999598887","3760","","0","0","0","0"
"cudaLaunchKernelExC","0","30.762770999985978","0","30.752627999985823","3760","","0","0","0","0"
"ncclDevKernel_Broadcast_RING_LL(ncclDevComm*, unsigned long, ncclWork*)","6866.830274000014","0","6866.830274000014","0","2240","","0","0","0","0"
"aten::unflatten_dense_tensors","0","128.9610609999674","0","37.5708890000527","2060","","0","0","0","0"
"aten::cat","122.61916300000158","92.09645799997519","122.61916300000158","61.692979999967854","2510","","26989.86669921875","26838.64404296875","0","0.00002288818359375"
"cudaLaunchKernel","0","986.8221980000585","0","576.7398140000246","39722","","-29179.8134765625","-29179.8134765625","-0.00005340576171875","-0.00005340576171875"
"aten::view_as","0","4.832820999989751","0","2.56835600002401","1480","","0","0","0","0"
"cudaMemsetAsync","0","87.60669400003785","0","86.58715500002785","9634","","-6947.17236328125","-6947.17236328125","-0.00014495849609375","-0.00014495849609375"
"cudaOccupancyMaxActiveBlocksPerMultiprocessor","0","14.609396999993129","0","14.528386999988696","6316","","-447.0361328125","-447.0361328125","-0.0000457763671875","-0.0000457763671875"
"cudaStreamIsCapturing","0","4.494483000055072","0","4.494483000055072","2734","","66.9482421875","66.9482421875","0","0"
"Gather","3829.134111999997","202.82647200002114","0","39.30939800000389","520","","42930.634765625","0","0","0"
"aten::split_with_sizes","0","11.898951000000118","0","9.488465999980807","530","","0","0","0","0"
"cudaFree","0","806.1750349999909","0","806.1750349999909","421","","0","0","0","0"
"void at::native::(anonymous namespace)::CatArrayBatchedCopy_contig<at::native::(anonymous namespace)::OpaqueType<1u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<1u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<1u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)","1.7944090000032447","0","1.7944090000032447","0","40","","0","0","0","0"
"void (anonymous namespace)::elementwise_kernel_with_index<int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}, function_traits<at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>::result_type*)","0.08358699999458623","0","0.08358699999458623","0","80","","0","0","0","0"
"void at::native::(anonymous namespace)::indexSelectLargeIndex<float, long, unsigned int, 2, 2, -2, true>(at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<long const, unsigned int>, int, int, unsigned int, unsigned int, long)","4.380194000006304","0","4.380194000006304","0","160","","0","0","0","0"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})","0.8641300000066403","0","0.8641300000066403","0","80","","0","0","0","0"
"aten::mean","0.06377499999827706","2.0107639999985696","0.06377499999827706","1.3954589999999152","20","","0.009765625","0.009765625","0","0"
"aten::ones_like","0.01036599999992177","0.5438420000008773","0","0.07373400000005495","10","","0.0048828125","0","0","0"
"aten::empty_like","0","20.0964210000023","0","5.146971000029589","1270","","6862.71728515625","-74.41455078125","0.00000762939453125","0.00000762939453125"
"aten::fill_","212.96861599997607","16.70517600003758","212.96861599997607","9.518668000038364","700","","9429.060546875","5014.8291015625","0.00000762939453125","0.00002288818359375"
"autograd::engine::evaluate_function: MeanBackward0","0.01651300000026822","1.5419939999989","0","0.2352540000018198","10","","0.0048828125","0","0","0"
"MeanBackward0","0.01651300000026822","1.3067399999970803","0","0.17471399999421555","10","","0.0048828125","0","0","0"
"aten::expand","0","0.18698800000257323","0","0.15507600000221283","10","","0","0","0","0"
"aten::div","0.01651300000026822","0.9450380000002915","0.01651300000026822","0.6899700000023004","10","","0.0048828125","0.0048828125","0","0"
"autograd::engine::evaluate_function: GatherBackward","0.04016100000077859","6.360251000001794","0","0.40018899999919816","10","","0.0146484375","0","0","0"
"GatherBackward","0.04016100000077859","5.960062000002596","0","1.0833460000028134","10","","0.0146484375","0","0","0"
"aten::select","0","0.381850000000326","0","0.2214280000019353","40","","0","0","0","0"
"autograd::engine::evaluate_function: NllLossBackward0","62.267185999999754","28.342375999995742","0","2.3738129999949598","40","","41546.70263671875","-3534.67626953125","0","0"
"NllLossBackward0","62.267185999999754","25.96856300000078","0","0.5208779999989783","40","","45081.37890625","1471.58984375","0","0"
"aten::nll_loss_backward","62.267185999999754","25.4476850000018","1.460671000004746","1.803059999997844","40","","43609.7890625","32707.35546875","0","0"
"aten::zero_","212.95824999997615","21.027865000011634","0","4.596985999973956","690","","10722.6181640625","1293.5576171875","0.0000457763671875","0.00003814697265625"
"autograd::engine::evaluate_function: LogSoftmaxBackward0","243.13975400000263","25.60526800000423","0","0.5544600000049686","40","","-17782.501953125","-34128.462890625","0","0"
"LogSoftmaxBackward0","243.13975400000263","25.05080799999926","0","0.7465680000006687","40","","16345.9609375","2349.74853515625","0","0"
"aten::_log_softmax_backward_data","243.13975400000263","24.304239999998593","243.13975400000263","6.515413000001455","40","","13996.21240234375","19204.29931640625","0","0"
"autograd::engine::evaluate_function: ViewBackward0","0","129.96471299997276","0","83.00176899994398","5880","","-35415.33642578125","-22692.67431640625","0.0000152587890625","0.0000762939453125"
"ViewBackward0","0","46.96294400002877","0","17.821172000000136","5880","","-12722.662109375","-5020.4873046875","-0.00006103515625","-0.00000762939453125"
"aten::reshape","0","29.465521000033828","0","13.734470000053173","5920","","-10305.2216796875","-5973.15869140625","-0.00005340576171875","-0.0000457763671875"
"autograd::engine::evaluate_function: CloneBackward0","0","0.508142000002088","0","0.4826770000029355","40","","791.65673828125","791.65673828125","0","0"
"CloneBackward0","0","0.025464999999152495","0","0.025464999999152495","40","","0","0","0","0"
"autograd::engine::evaluate_function: SliceBackward0","405.34586299999955","12.656468000005697","0","2.8582630000106293","80","","-2114.29833984375","-35898.17236328125","0","0"
"SliceBackward0","405.34586299999955","9.798204999995068","0","0.29423899999062997","80","","33783.8740234375","399.01904296875","0","0"
"aten::slice_backward","405.34586299999955","9.50396600000444","0","0.8453460000082851","80","","33384.85498046875","-328.25390625","0","0"
"aten::zeros","146.2014919999952","9.319787000002922","0","2.321654000022332","170","","50838.4658203125","3442.06396484375","-0.00000762939453125","-0.00000762939453125"
"autograd::engine::evaluate_function: UnsafeViewBackward0","0","0.8374900000024355","0","0.3928999999999069","40","","-5336.09375","-1679.15234375","0","0"
"UnsafeViewBackward0","0","0.4445900000025285","0","0.12084099999733734","40","","-3656.94140625","-1053.89453125","0","0"
"autograd::engine::evaluate_function: MmBackward0","787.2572179999956","8.489109000004827","0","1.2804339999983785","40","","-39884.25048828125","-26677.08154296875","0","0"
"MmBackward0","787.2572179999956","7.2086750000064495","0","0.7039139999976615","40","","-13207.1689453125","-398.9287109375","0","0"
"aten::t","0","36.10750000002747","0","15.530161000043387","4000","","-4960.42041015625","-1371.998046875","-0.00003814697265625","-0.00000762939453125"
"aten::transpose","0","39.49811699998984","0","27.566636000094704","8800","","-6436.1767578125","-4658.5849609375","-0.00003814697265625","-0.000091552734375"
"aten::mm","3283.6285309999766","231.4816560000264","3283.6285309999766","151.5696320000185","3920","","8786.05224609375","23083.5849609375","0.0000152587890625","0.00018310546875"
"cudaMalloc","0","173.2948880000019","0","151.3164809999871","390","","-2923.7880859375","-2923.7880859375","0","0"
"cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags","0","2.9939449999846985","0","2.9939449999846985","1520","","-612.84033203125","-612.84033203125","-0.0000152587890625","-0.0000152587890625"
"cudaFuncSetAttribute","0","1115.6563670000069","0","1115.6563670000069","1040","","-1952.54931640625","-1952.54931640625","-0.00000762939453125","-0.00000762939453125"
"autograd::engine::evaluate_function: TBackward0","0","1.5139840000043623","0","1.0836930000047433","40","","-3633.82861328125","-2800.18896484375","0","0"
"TBackward0","0","0.43029099999961906","0","0.08282300000067334","40","","-833.6396484375","-296.009765625","0","0"
"autograd::engine::evaluate_function: NativeLayerNormBackward0","116.2805379999876","159.24671300003027","0","42.31518700006394","1000","","-38348.6650390625","-31116.9921875","-0.000030517578125","-0.00003814697265625"
"NativeLayerNormBackward0","82.66615599998087","92.73398499999603","0","8.031790999985649","1000","","-4612.0087890625","-166.361328125","0.00005340576171875","-0.0000152587890625"
"aten::native_layer_norm_backward","82.66615599998087","84.70219400001038","82.66615599998087","26.873117000000203","1000","","-4445.6474609375","-4952.98583984375","0.00006866455078125","0.000030517578125"
"autograd::engine::evaluate_function: AddBackward0","0.7195549999992363","44.509575999954365","0","40.81678099994559","1960","","-11917.39306640625","-12238.03955078125","0.00003814697265625","0.00002288818359375"
"AddBackward0","0","2.163437000008533","0","2.163437000008533","1960","","177.4453125","177.4453125","0.0000152587890625","0.0000152587890625"
"autograd::engine::evaluate_function: AddmmBackward0","2541.585552000011","478.86817099995665","0","74.35350499991851","1920","","-84433.25244140625","-72742.99365234375","-0.00000762939453125","-0.000030517578125"
"AddmmBackward0","2496.371312999981","286.7816730000492","0","26.04474600000307","1920","","12701.2099609375","-4470.2919921875","0.00003814697265625","0.00006103515625"
"aten::sum","57.708644000022325","137.59543799997772","57.708644000022325","102.03088599993242","2440","","-24403.41748046875","-16005.6640625","-0.00008392333984375","-0.00003814697265625"
"autograd::engine::evaluate_function: MulBackward0","573.0494000000258","137.51590799998854","0","42.67138099995337","1920","","-40048.75048828125","-81934.615234375","-0.00000762939453125","0.0000457763671875"
"MulBackward0","469.8858780000214","86.61460000000324","0","8.458269000008702","1920","","42353.1845703125","-1128.15478515625","-0.0000457763671875","0.00003814697265625"
"aten::mul","653.8382610000378","129.68617999998025","653.8382610000378","90.9923919999539","3850","","62448.056640625","69716.91015625","-0.000244140625","-0.00017547607421875"
"autograd::engine::evaluate_function: TanhBackward0","152.18785200000508","26.311201000004658","0","8.042232999994303","480","","-19888.52734375","-27723.03662109375","-0.0001678466796875","-0.00008392333984375"
"TanhBackward0","152.18785200000508","18.268968000010354","0","2.7035500000034225","480","","7834.50927734375","-636.47314453125","-0.00008392333984375","0.000030517578125"
"aten::tanh_backward","152.18785200000508","15.565418000006932","152.18785200000508","10.623431000009761","480","","8470.982421875","9919.51220703125","-0.00011444091796875","-0.00005340576171875"
"autograd::engine::evaluate_function: PowBackward0","386.1414679999892","84.22646199999947","0","20.68484099999524","480","","-44719.87841796875","-46017.919921875","-0.0001068115234375","-0.00012969970703125"
"PowBackward0","271.45207599999816","52.95624600000598","0","5.098995000014547","480","","3161.728515625","-23876.80908203125","0.000091552734375","0.00006866455078125"
"aten::pow","99.94786599998456","18.96323700000276","99.94786599998456","13.71447300000349","480","","10192.833984375","11436.83935546875","0.00023651123046875","0.0001373291015625"
"aten::result_type","0","1.349635999974562","0","1.349635999974562","9360","","-182.26513671875","-182.26513671875","0","0"
"aten::add_","251.46729600000208","44.44685999997891","251.46729600000208","28.70966500001785","3400","","-4950.6708984375","-4302.82861328125","-0.0001220703125","-0.0001220703125"
"autograd::engine::evaluate_function: TransposeBackward0","0","10.763348000005818","0","5.742391000017873","480","","-1048.3828125","-920.81591796875","-0.00002288818359375","-0.000030517578125"
"TransposeBackward0","0","5.020956999987946","0","1.067557999996934","480","","-127.56689453125","-29.16015625","0.00000762939453125","0"
"autograd::engine::evaluate_function: ScaledDotProductEfficientAttentionBackward0","940.9123670000129","1309.5918999999888","0","17.02755100000836","480","","-23636.048828125","-18604.78759765625","0.000030517578125","0.000030517578125"
"ScaledDotProductEfficientAttentionBackward0","940.9123670000129","1292.5643489999804","0","5.866376999992994","480","","-5031.26123046875","522.623046875","0","-0.0000152587890625"
"aten::_scaled_dot_product_efficient_attention_backward","940.9123670000129","1286.6979719999874","0","15.378503999987501","480","","-5553.88427734375","-1604.23095703125","0.0000152587890625","0.00005340576171875"
"aten::_efficient_attention_backward","940.9123670000129","1258.0807970000174","909.1216230000206","25.688021999966935","480","","-1832.23974609375","-9639.87890625","-0.000030517578125","0"
"aten::contiguous","1.629318000009167","23.629770999994943","0","0.9714130000011064","480","","-2154.619140625","-164.09912109375","-0.00002288818359375","0"
"aten::clone","1.629318000009167","22.658357999993836","0","2.6150390000006882","480","","-1990.52001953125","-663.3154296875","-0.00002288818359375","0"
"cudaFuncGetAttributes","0","2.8418859999935377","0","2.8418859999935377","480","","-215.5029296875","-215.5029296875","0.00000762939453125","0.00000762939453125"
"autograd::engine::evaluate_function: PermuteBackward0","0","28.86912299998966","0","16.365272999981187","1440","","-1504.41748046875","-1710.1689453125","0.00000762939453125","0.00002288818359375"
"PermuteBackward0","0","12.503850000008475","0","4.224871999980183","1440","","205.75146484375","312.11474609375","-0.0000152587890625","0.00000762939453125"
"aten::permute","0","8.278978000028292","0","6.891214000008185","1440","","-106.36328125","-219.5927734375","-0.00002288818359375","-0.00002288818359375"
"autograd::engine::evaluate_function: SplitBackward0","23.647425000009942","36.211979999985545","0","8.225165999963064","480","","-4091.67138671875","-10878.94384765625","0.00002288818359375","0.00000762939453125"
"SplitBackward0","23.647425000009942","27.98681400002248","0","2.4828910000199684","480","","6787.2724609375","-269.45654296875","0.0000152587890625","0.0000152587890625"
"autograd::engine::evaluate_function: EmbeddingBackward0","107.92790300000645","8.83155299999297","0","2.0422720000011614","80","","-50.84033203125","-12849.04541015625","0","-0.00000762939453125"
"EmbeddingBackward0","29.581386000001338","5.780241999993566","0","0.33840399998717474","80","","6760.685546875","-62.0341796875","0.00000762939453125","0.00000762939453125"
"aten::embedding_backward","29.581386000001338","5.441838000006392","0","0.21482200000202284","80","","6822.7197265625","26.0791015625","0","0"
"aten::embedding_dense_backward","29.581386000001338","5.227016000004369","7.554945000001695","1.388045000004","80","","6796.640625","512.68994140625","0","0.00000762939453125"
"aten::add","78.36059800000558","1.2755509999978822","78.36059800000558","0.8960669999996899","50","","6037.5244140625","5940.447265625","0","0.00000762939453125"
"autograd::engine::evaluate_function: BroadcastBackward","3719.018885999981","195.1826180000014","0","8.917383000001893","10","","-14619.1767578125","-19369.009765625","0","0"
"BroadcastBackward","3719.018885999981","186.2652349999995","0","5.645333000001148","10","","4749.8330078125","0","0","0"
"ReduceAddCoalesced","3719.018885999981","180.61990199999838","3657.7209590000057","70.80800199999625","10","","4749.8330078125","-13123.9775390625","0","0"
"autograd::engine::evaluate_function: torch::autograd::AccumulateGrad","0","13.984765999981319","0","7.56477599999588","1480","","0","0","0","0"
"torch::autograd::AccumulateGrad","0","6.419989999985439","0","3.4920050000072225","1480","","0","0","0","0"
"aten::detach","0","3.275724999993341","0","1.5675830000040587","1629","","0","0","0","0"
"detach","0","1.7081419999892824","0","1.7081419999892824","1629","","0","0","0","0"
"aten::_foreach_norm","20.109160000005737","6.647048999999534","20.097577000005405","5.4859440000053725","10","","0.72265625","-2.607421875","0","0"
"aten::stack","0.035713000001152975","5.291788000002503","0","1.511746999994968","10","","0.009765625","0","0","0"
"aten::unsqueeze","0","2.873315000010887","0","2.226406999996165","1480","","0","0","0","0"
"aten::linalg_vector_norm","0.03049500000034459","0.44394800000207035","0.03049500000034459","0.3207400000039488","10","","0.0048828125","0.0048828125","0","0"
"aten::reciprocal","0.013408000001916661","0.2545130000031786","0.013408000001916661","0.16538100000307895","10","","0.0048828125","0.0048828125","0","0"
"aten::clamp","0.014976000002818183","0.33782200000225565","0.014976000002818183","0.23623700000112877","10","","0.0048828125","0.0048828125","0","0"
"aten::_foreach_mul_","128.2851019999862","5.36007500000298","128.2851019999862","3.635171999974642","30","","0","0","0","0"
"Optimizer.step#AdamW.step","420.20013799999515","59.161806999999214","0","22.9148250000173","10","","0","-4756.583984375","0","-0.00003814697265625"
"aten::lift_fresh","0","0.006041999996057711","0","0.006041999996057711","10","","0","0","0","0"
"aten::detach_","0","0.05444899999839254","0","0.02390899999823887","10","","0","0","0","0"
"detach_","0","0.03054000000015367","0","0.03054000000015367","10","","0","0","0","0"
"aten::_foreach_add_","42.736574999999256","5.587305999997072","42.736574999999256","3.5570420000271405","20","","0","0","0","0"
"aten::_foreach_lerp_","62.97937999999733","1.0415049999979091","62.97937999999733","0.5687550000009359","10","","0","0","0","0"
"aten::_foreach_addcmul_","62.90478100001416","2.257860000000219","62.90478100001416","1.7173620000123047","10","","0","0","0","0"
"aten::item","0.023808999999426306","2686.6727479999886","0","3.060405000002589","2974","","0","0","0","0"
"aten::_local_scalar_dense","0.023808999999426306","2683.6123429999866","0.023808999999426306","0.9899819999884348","2974","","0","0","0","0"
"aten::_foreach_sqrt","42.59834699999867","14.235359000001335","42.59834699999867","4.245510000016075","10","","4756.583984375","0","0","0"
"aten::_foreach_div_","42.597346999997974","2.3739919999986885","42.597346999997974","1.750371999988798","10","","0","0","0","0"
"aten::_foreach_addcdiv_","80.4048519999932","2.6704270000021206","80.4048519999932","2.0113980000136653","10","","0","0","0","0"
"Optimizer.step#AdamW.step","420.5797279999978","0","420.5797279999978","0","10","","0","0","0","0"
"cudaDeviceSynchronize","0","734.765334999999","0","734.765334999999","12","","0","0","0","0"
"cudaHostAlloc","0.08867200000025333","5.789909999999217","0","3.0809110000021755","19","","80.482421875","16.607421875","0","0"
"Memcpy DtoH (Device -> Pinned)","0.023808999999426306","0","0.023808999999426306","0","13","","0","0","0","0"
"aten::random_","0","0.01911699999962002","0","0.01911699999962002","1","","0","0","0","0"
"aten::set_","0","1.4798910000044851","0","1.4798910000044851","296","","0","0","0","0"
"Memcpy DtoH (Device -> Pageable)","100.2177920000013","0","100.2177920000013","0","148","","0","0","0","0"
"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)","6.328669000038877","0","6.328669000038877","0","400","","0","0","0","0"
"autograd::engine::evaluate_function: NativeDropoutBackward0","5.762558000020682","26.12074999995716","0","6.000702999947593","400","","161.25048828125","-2284.83154296875","0.00002288818359375","0"
"NativeDropoutBackward0","5.762558000020682","20.120047000009567","0","1.604723000017926","400","","2446.08203125","131.97705078125","0.00002288818359375","0"
"aten::native_dropout_backward","5.762558000020682","18.51532399999164","5.762558000020682","7.004179999994114","400","","2314.10498046875","-22.7861328125","0.00002288818359375","0.0000152587890625"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)","5.762558000020682","0","5.762558000020682","0","400","","0","0","0","0"
"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)","382.05648700001836","0","382.05648700001836","0","192","","0","0","0","0"