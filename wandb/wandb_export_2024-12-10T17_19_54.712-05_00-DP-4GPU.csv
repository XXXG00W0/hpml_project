"Name","Device Time Total (ms)","CPU Time Total (ms)","Self Device Time Total (ms)","Self CPU Time Total (ms)","Calls","Input Shapes","Device Memory Usage (MB)","Self Device Memory Usage (MB)","CPU Memory Usage (MB)","Self CPU Memory Usage (MB)"
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)","768.9578520000354","0","768.9578520000354","0","1217","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)","951.7461890001011","0","951.7461890001011","0","6795","","0","0","0","0"
"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)","50.19259399998597","0","50.19259399998597","0","2539","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)","840.9162160000596","0","840.9162160000596","0","6748","","0","0","0","0"
"Memset (Device)","17.635160999844373","0","17.635160999844373","0","14153","","0","0","0","0"
"ampere_sgemm_128x64_nn","2835.8553699999943","0","2835.8553699999943","0","4873","","0","0","0","0"
"ProfilerStep*","10668.403440999995","18680.729198999998","0","5902.397818000047","15","","-195954.0234375","-286955.90380859375","0","-0.00000762939453125"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#2}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#2}, at::detail::Array<char*, 2>)","250.49483900001698","0","250.49483900001698","0","1220","","0","0","0","0"
"enumerate(DataLoader)#_MultiProcessingDataLoaderIter.__next__","0","8.991166999999397","0","7.530185999999484","26","","0","0","0","0"
"aten::to","0.7821839999986114","6140.397063999936","0","1.669602999932482","4670","","53.2763671875","47.78564453125","0.00000762939453125","0.00000762939453125"
"aten::_to_copy","0.7821839999986114","6138.727461000004","0","1.9852040000024718","245","","5.49072265625","0","0","0"
"aten::empty_strided","0","24.996654000047297","0","23.437617000048682","3050","","14264.1845703125","14264.1845703125","0","0"
"aten::copy_","5262.8236320000715","6409.486240000021","5262.8236320000715","115.38592500006128","3833","","-4791.93359375","-8239.3681640625","0.0000457763671875","0.000030517578125"
"cudaMemcpyAsync","0","125.48800799998155","0","125.48800799998155","666","","3930.40478515625","3930.40478515625","0.00000762939453125","0.00000762939453125"
"cudaStreamSynchronize","0","8806.272763999998","0","8806.161248999995","211","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::tanh_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::tanh_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)","95.45008400001998","0","95.45008400001998","0","1220","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<float>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<float>, at::detail::Array<char*, 2>)","106.14221200001538","0","106.14221200001538","0","1236","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)","1014.1007199999716","0","1014.1007199999716","0","4292","","0","0","0","0"
"cudaPointerGetAttributes","0","0.35844800000259514","0","0.3503580000018128","66","","18.0205078125","18.0205078125","0","0"
"ampere_sgemm_128x64_tn","3585.057912999995","0","3585.057912999995","0","3176","","0","0","0","0"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})","2269.748013000082","0","2269.748013000082","0","3432","","0","0","0","0"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1} const&)::{lambda(int)#1})","0.5115199999899706","0","0.5115199999899706","0","104","","0","0","0","0"
"void at::native::(anonymous namespace)::cunn_SoftMaxForward<4, float, float, float, at::native::(anonymous namespace)::LogSoftMaxForwardEpilogue>(float*, float const*, int)","370.2132120000003","0","370.2132120000003","0","104","","0","0","0","0"
"void at::native::(anonymous namespace)::nll_loss_forward_reduce_cuda_kernel_2d<float, float, long>(float*, float*, float const*, long const*, float const*, bool, long, long, long, long)","8.014071000002318","0","8.014071000002318","0","104","","0","0","0","0"
"Memcpy DtoD (Device -> Device)","313.5339419999971","0","313.5339419999971","0","116","","0","0","0","0"
"Memcpy PtoP (Device -> Device)","3167.8585739999903","0","3167.8585739999903","0","354","","0","0","0","0"
"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4>)","0.08371399999439018","0","0.08371399999439018","0","26","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)","330.5143020000113","0","330.5143020000113","0","352","","0","0","0","0"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})","0.02662400000006892","0","0.02662400000006892","0","16","","0","0","0","0"
"void at::native::(anonymous namespace)::nll_loss_backward_reduce_cuda_kernel_2d<float, long>(float*, float const*, long const*, float const*, float const*, bool, int, int, long, long)","2.3283479999926056","0","2.3283479999926056","0","64","","0","0","0","0"
"void at::native::(anonymous namespace)::cunn_SoftMaxBackward<4, float, float, float, at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue>(float*, float const*, float const*, long)","396.84825899999544","0","396.84825899999544","0","64","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_128x256_8x4_nt_align1>(cutlass_80_simt_sgemm_128x256_8x4_nt_align1::Params)","1028.3201789999625","0","1028.3201789999625","0","832","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_256x128_8x4_nn_align1>(cutlass_80_simt_sgemm_256x128_8x4_nn_align1::Params)","664.8166020000042","0","664.8166020000042","0","64","","0","0","0","0"
"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)","103.14062899994099","0","103.14062899994099","0","1600","","0","0","0","0"
"void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)","29.328012000045682","0","29.328012000045682","0","1600","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_64x128_8x5_nt_align1>(cutlass_80_simt_sgemm_64x128_8x5_nt_align1::Params)","637.5197699999649","0","637.5197699999649","0","768","","0","0","0","0"
"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)","70.20062200002901","0","70.20062200002901","0","3136","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::tanh_backward_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::tanh_backward_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)","243.14558699999313","0","243.14558699999313","0","768","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#1}, at::detail::Array<char*, 2>)","159.8981220000438","0","159.8981220000438","0","768","","0","0","0","0"
"ampere_sgemm_128x64_nt","658.037336000002","0","658.037336000002","0","768","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_128x64_8x5_nt_align1>(cutlass_80_simt_sgemm_128x64_8x5_nt_align1::Params)","168.38282800001716","0","168.38282800001716","0","768","","0","0","0","0"
"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)","18.93023200003989","0","18.93023200003989","0","768","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<unsigned char>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<unsigned char>, at::detail::Array<char*, 1>)","9.557662999962574","0","9.557662999962574","0","768","","0","0","0","0"
"fmha_cutlassB_f32_aligned_64x64_k64_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, false, false, 64, 64, 64, false>::Params)","175.7992170000001","0","175.7992170000001","0","96","","0","0","0","0"
"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 3, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)","37.52438399999676","0","37.52438399999676","0","768","","0","0","0","0"
"void at::native::(anonymous namespace)::embedding_backward_feature_kernel<float, float, long>(long const*, float const*, float*, int, long, int)","12.185112000000256","0","12.185112000000256","0","128","","0","0","0","0"
"ncclDevKernel_Reduce_Sum_f32_RING_LL(ncclDevComm*, unsigned long, ncclWork*)","5879.652611000054","0","5879.652611000054","0","2432","","0","0","0","0"
"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)","141.61366399993747","0","141.61366399993747","0","3025","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::LpNormFunctor<float, (at::native::NormType)1, float, 1, 1, 0>, float*, int>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::LpNormFunctor<float, (at::native::NormType)1, float, 1, 1, 0>, float*, int)","32.10148200000642","0","32.10148200000642","0","112","","0","0","0","0"
"void at::native::lpnorm_cleanup<float, (at::native::NormType)1, float, float>(float const*, at::native::TensorListAddresses, int)","0.06019200000062119","0","0.06019200000062119","0","16","","0","0","0","0"
"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::NormTwoOps<float, float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::NormTwoOps<float, float, float>, unsigned int, float, 4>)","0.04873599999770522","0","0.04873599999770522","0","16","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::reciprocal_kernel_cuda(at::TensorIteratorBase&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::reciprocal_kernel_cuda(at::TensorIteratorBase&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)","0.021566999995091464","0","0.021566999995091464","0","16","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)","0.024127999991644174","0","0.024127999991644174","0","16","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarTensorFunctor<float, 1, 1, 0>, std::multiplies<float>, float*, float>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarTensorFunctor<float, 1, 1, 0>, std::multiplies<float>, float*, float)","67.62073900000344","0","67.62073900000344","0","112","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::multiplies<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::multiplies<float>, float)","137.4776360000003","0","137.4776360000003","0","224","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::TernaryOpScalarFunctor<float, 2, 2, 0>, at::native::LerpFunctor<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::TernaryOpScalarFunctor<float, 2, 2, 0>, at::native::LerpFunctor<float>, float)","100.74299499999411","0","100.74299499999411","0","112","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<3>, at::native::(anonymous namespace)::PointwiseOpScalarFunctor<float, 3, 3, 0>, std::multiplies<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<3>, at::native::(anonymous namespace)::PointwiseOpScalarFunctor<float, 3, 3, 0>, std::multiplies<float>, float)","100.80762700000516","0","100.80762700000516","0","112","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::UnaryOpFunctor<float, 2, 1, 1>, at::native::Sqrt<float> >(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::UnaryOpFunctor<float, 2, 1, 1>, at::native::Sqrt<float>)","68.09097100000928","0","68.09097100000928","0","112","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 1>, at::native::(anonymous namespace)::BinaryOpScalarListFunctor<float, 1, 1, 0>, std::divides<float> >(at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 1>, at::native::(anonymous namespace)::BinaryOpScalarListFunctor<float, 1, 1, 0>, std::divides<float>)","68.21081700001686","0","68.21081700001686","0","112","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::plus<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::plus<float>, float)","68.41606900001835","0","68.41606900001835","0","112","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 3>, at::native::(anonymous namespace)::PointwiseOpScalarListFunctor<float, 3, 3, 0>, std::divides<float> >(at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 3>, at::native::(anonymous namespace)::PointwiseOpScalarListFunctor<float, 3, 3, 0>, std::divides<float>)","128.66155399999127","0","128.66155399999127","0","112","","0","0","0","0"
"ProfilerStep*","18018.103338999998","0","18018.103338999998","0","15","","0","0","0","0"
"Memcpy HtoD (Pinned -> Device)","0.3994220000106143","0","0.3994220000106143","0","50","","0","0","0","0"
"DataParallel.forward","9843.688016999977","2379.8817870000003","0","1207.5345989998366","25","","91010.9130859375","-3589.21533203125","0","0"
"Scatter","0.3827619999879971","27.364687999995773","0","4.763178999998374","65","","2.36572265625","0","0","0"
"aten::chunk","0","2.169205000002985","0","0.23921299999649637","50","","0","0","0","0"
"aten::split","0","1.9299920000064885","0","0.5754470000111033","50","","0","0","0","0"
"aten::narrow","0","97.91654400008254","0","30.5564730000298","15320","","0","0","0","0"
"aten::slice","0","68.17861200005643","0","58.05465499994275","15440","","279.16064453125","-1169.21240234375","0","0"
"aten::as_strided","0","35.962724000064426","0","35.962724000064426","36515","","-2953.3251953125","-2953.3251953125","-0.00000762939453125","-0.00000762939453125"
"cudaEventRecord","0.9119030000008642","18.997352000041282","0.9119030000008642","18.997352000041282","14450","","0","0","0","0"
"cudaStreamWaitEvent","4.667675000000745","29.714326000160423","4.667675000000745","29.714326000160423","14450","","0","0","0","0"
"DataParallel.forward","36003.50168299999","0","36003.50168299999","0","100","","0","0","0","0"
"Broadcast","5057.363775999918","204.43649400000484","5032.858865999961","58.16076899981627","15","","21867.1435546875","-4926.3095703125","0","0"
"aten::flatten_dense_tensors","137.59046999995994","151.3149599999528","0","32.71703299997165","2980","","28193.84521484375","0","0","0"
"aten::view","0","77.09554499994462","0","77.08264599994489","42500","","-8894.560546875","-8894.560546875","-0.0000457763671875","-0.0000457763671875"
"aten::empty","0","182.10307399997953","0","163.72900699998974","12817","","164421.6689453125","164421.6689453125","-0.000064849853515625","-0.000064849853515625"
"cudaStreamGetCaptureInfo_v2","0.435327999997884","3.9945480000484967","0.435327999997884","3.9945480000484967","5080","","0","0","0","0"
"cudaLaunchKernelExC","0.36025700000673533","40.03400000001316","0.36025700000673533","40.01623600001319","5080","","0","0","0","0"
"ncclDevKernel_Broadcast_RING_LL(ncclDevComm*, unsigned long, ncclWork*)","8585.229519999928","0","8585.229519999928","0","2800","","0","0","0","0"
"aten::unflatten_dense_tensors","0","167.6286229998764","0","50.69083199981286","2670","","0","0","0","0"
"aten::cat","172.8188589999487","137.05058800002897","172.8188589999487","94.04042099998227","3630","","38150.13818359375","40027.04931640625","0.00000762939453125","0.000030517578125"
"cudaLaunchKernel","14.449116999998688","1008.9467740001114","13.507386999998241","818.7675810000986","56348","","-30895.85498046875","-30895.85498046875","-0.0003662109375","-0.0003662109375"
"aten::view_as","0","7.2338950000052575","0","3.8525020000629593","2220","","0","0","0","0"
"cudaMemsetAsync","4.330433999992907","123.10413399996422","4.330433999992907","121.48573199993884","13496","","-9253.52734375","-9253.52734375","-0.0000762939453125","-0.0000762939453125"
"cudaOccupancyMaxActiveBlocksPerMultiprocessor","2.6691810000017284","20.478546000018017","2.6691810000017284","20.3139520000231","8495","","-900.58642578125","-900.58642578125","0.00000762939453125","0.00000762939453125"
"cudaStreamIsCapturing","1.1542100000008941","9.45781899991748","1.1542100000008941","9.453548999918391","6432","","-143.7431640625","-143.7431640625","0","0"
"Gather","4737.2096260000535","206.3329420000437","0","44.62023700000683","650","","53663.29345703125","0","0","0"
"aten::split_with_sizes","0","14.625112000015449","0","11.729841999972356","665","","0","0","0","0"
"cudaFree","0","1110.7351009999973","0","1110.7351009999973","434","","0","0","0","0"
"void at::native::(anonymous namespace)::CatArrayBatchedCopy_contig<at::native::(anonymous namespace)::OpaqueType<1u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<1u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<1u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)","2.1613460000141056","0","2.1613460000141056","0","50","","0","0","0","0"
"void (anonymous namespace)::elementwise_kernel_with_index<int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}, function_traits<at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>::result_type*)","0.10501900000311434","0","0.10501900000311434","0","100","","0","0","0","0"
"void at::native::(anonymous namespace)::indexSelectLargeIndex<float, long, unsigned int, 2, 2, -2, true>(at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<long const, unsigned int>, int, int, unsigned int, unsigned int, long)","5.485306000000099","0","5.485306000000099","0","200","","0","0","0","0"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})","1.0536649999953807","0","1.0536649999953807","0","100","","0","0","0","0"
"aten::mean","0.08067399999441113","2.1261170000002023","0.08067399999441113","1.4581870000085329","25","","0.01220703125","0.01220703125","0","0"
"aten::ones_like","0.015522999997949228","0.6381020000029821","0","0.07773599999421277","15","","0.00732421875","0","0","0"
"aten::empty_like","0","47.49026300005696","0","10.26775200008042","2705","","13356.1455078125","-686.60888671875","-0.00008392333984375","-0.000030517578125"
"aten::fill_","318.95911799997407","25.917396999986494","318.95911799997407","15.477335999932256","1050","","11055.1142578125","6313.62109375","-0.00000762939453125","0"
"autograd::engine::evaluate_function: MeanBackward0","0.024960000000079162","1.705373000000487","0","0.265062000005506","15","","0.00732421875","0","0","0"
"MeanBackward0","0.024960000000079162","1.440310999994981","0","0.2104429999946151","15","","0.00732421875","0","0","0"
"aten::expand","0","0.19830299999786075","0","0.1609799999969546","15","","0","0","0","0"
"aten::div","0.024960000000079162","1.0315650000025052","0.024960000000079162","0.697811000005342","15","","0.00732421875","0.00732421875","0","0"
"autograd::engine::evaluate_function: GatherBackward","0.05948899999808054","8.135556999996188","0","0.5030599999943516","15","","0.02197265625","0","0","0"
"GatherBackward","0.05948899999808054","7.632497000001837","0","1.3750820000057575","15","","0.02197265625","0","0","0"
"aten::select","0","0.4575419999965234","0","0.3107669999953359","60","","0","0","0","0"
"autograd::engine::evaluate_function: NllLossBackward0","93.2101699999976","35.32728200000024","0","3.3091849999853875","60","","63450.33984375","-5109.19580078125","0","0"
"NllLossBackward0","93.2101699999976","32.018097000014855","0","0.5236880000114906","60","","68559.53564453125","3138.36328125","0","0"
"aten::nll_loss_backward","93.2101699999976","31.494409000003362","2.1837719999925467","2.435313000002294","60","","65421.17236328125","45932.04443359375","0","0"
"aten::zero_","318.9435949999761","34.02754599996761","0","8.44209999998554","1035","","9890.408203125","-1164.7060546875","-0.00000762939453125","0"
"autograd::engine::evaluate_function: LogSoftmaxBackward0","372.3806309999954","41.52952800000377","0","0.8743259999995353","60","","-34845.32177734375","-50322.91357421875","0","0"
"LogSoftmaxBackward0","372.3806309999954","40.65520200000424","0","0.4264450000195065","60","","15477.591796875","392.19873046875","0","0"
"aten::_log_softmax_backward_data","372.3806309999954","40.22875699998473","372.3806309999954","1.6326989999876824","60","","15085.39306640625","22352.89306640625","0","0"
"autograd::engine::evaluate_function: ViewBackward0","0","192.25202099997654","0","123.09949899998132","8820","","-37751.892578125","-29754.93115234375","-0.00006103515625","-0.00006103515625"
"ViewBackward0","0","69.15252199999523","0","26.261212999865645","8820","","-7996.96142578125","-2807.87060546875","0","0"
"aten::reshape","0","43.40459800011746","0","19.60873500009964","8880","","-7947.9833984375","-3523.43701171875","0","0.00005340576171875"
"autograd::engine::evaluate_function: CloneBackward0","0","0.5948939999975265","0","0.5646419999977806","60","","-2744.9970703125","-2352.74755859375","0","0"
"CloneBackward0","0","0.03025199999974575","0","0.03025199999974575","60","","-392.24951171875","-392.24951171875","0","0"
"autograd::engine::evaluate_function: SliceBackward0","608.2670330000269","17.382383999995653","0","4.783930999991717","120","","-13329.23193359375","-52669.51806640625","-0.00000762939453125","-0.00000762939453125"
"SliceBackward0","608.2670330000269","12.598453000003937","0","1.0974449999899372","120","","39340.2861328125","-750.0380859375","0","-0.00000762939453125"
"aten::slice_backward","608.2670330000269","11.501008000014","0","1.1804540000134147","120","","40090.32421875","2936.88916015625","0.00000762939453125","0"
"aten::zeros","218.95972500000846","11.702419000007678","0","1.3514980000348296","255","","48595.6826171875","-863.009765625","-0.00000762939453125","0"
"cudaMalloc","0","200.18522099999174","0","176.79422000000835","403","","-6584.95751953125","-6584.95751953125","0","0"
"autograd::engine::evaluate_function: UnsafeViewBackward0","0","1.2999650000064866","0","0.6154489999986253","60","","-3787.259765625","-789.7255859375","0","0"
"UnsafeViewBackward0","0","0.6845160000078613","0","0.17122700001997873","60","","-2997.5341796875","-238.6416015625","0","0"
"autograd::engine::evaluate_function: MmBackward0","1182.3726170000143","12.52026199999766","0","1.3776810000014956","60","","-57753.642578125","-36824.294921875","0","0"
"MmBackward0","1182.3726170000143","11.142580999996165","0","0.8938119999801274","60","","-20929.34765625","-2537.09912109375","0","0"
"aten::t","0","55.19810900006059","0","22.758792999906234","6000","","-8281.83935546875","-2139.67138671875","0.00006103515625","0.00002288818359375"
"aten::transpose","0","60.19926900016947","0","41.33091000029759","13200","","-8754.23193359375","-4660.435546875","0.000030517578125","0.00003814697265625"
"aten::mm","4942.164333999931","360.0240179999437","4942.164333999931","241.09025799990283","5880","","7987.10498046875","30093.986328125","0.00034332275390625","0.00045013427734375"
"cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags","0","4.21850300004473","0","4.21850300004473","2280","","-2633.03125","-2633.03125","0","0"
"cudaFuncSetAttribute","0","955.783482999988","0","955.783482999988","1560","","-1816.201171875","-1816.201171875","0","0"
"autograd::engine::evaluate_function: TBackward0","0","2.5005679999897255","0","1.9212319999886676","60","","-4012.9052734375","-2992.8544921875","0","0"
"TBackward0","0","0.579336000001058","0","0.13123199998831842","60","","-1020.05078125","-178.7705078125","0","0"
"autograd::engine::evaluate_function: NativeLayerNormBackward0","174.4619509999993","240.68728299998887","0","60.86744200002053","1500","","-65020.9462890625","-45676.4638671875","-0.00012969970703125","-0.00003814697265625"
"NativeLayerNormBackward0","124.17542799998668","145.38098799995646","0","12.317021000007982","1500","","-16209.7734375","-1721.57177734375","-0.0000457763671875","-0.00003814697265625"
"aten::native_layer_norm_backward","124.17542799998668","133.0639669999485","124.17542799998668","41.584261999974146","1500","","-14488.20166015625","-5576.21240234375","-0.00000762939453125","0.00009918212890625"
"autograd::engine::evaluate_function: AddBackward0","1.0996140000068118","65.7533860000159","0","60.521017999913546","2940","","-18281.6240234375","-17763.50927734375","-0.0000152587890625","-0.00002288818359375"
"AddBackward0","0","3.0745490001060536","0","3.0745490001060536","2940","","-1452.25048828125","-1452.25048828125","0.0000152587890625","0.0000152587890625"
"autograd::engine::evaluate_function: AddmmBackward0","3827.9179499999104","739.4693129999517","0","107.5287159998219","2880","","-127946.10205078125","-108523.56201171875","0.00019073486328125","0.00002288818359375"
"AddmmBackward0","3759.7917169999164","442.6993770000824","0","38.17412300010689","2880","","16158.62646484375","-2780.16796875","0.0005035400390625","0.00009918212890625"
"aten::sum","86.97306700004056","214.6937040000479","86.97306700004056","158.5130610000612","3660","","-32579.94580078125","-22336.83544921875","-0.00032806396484375","-0.0002593994140625"
"autograd::engine::evaluate_function: MulBackward0","857.9009600000328","204.7207089999467","0","66.71920299990323","2880","","-61151.49658203125","-128794.2998046875","-0.00006866455078125","0.00016021728515625"
"MulBackward0","701.1541419999936","125.53631499998575","0","12.215450999835971","2880","","66572.12353515625","-1864.25830078125","-0.00029754638671875","-0.00005340576171875"
"aten::mul","977.0274930000237","224.51397200017283","977.0274930000237","131.83532600025646","5775","","99531.82666015625","106888.89208984375","-0.00060272216796875","-0.00028228759765625"
"autograd::engine::evaluate_function: TanhBackward0","227.92246199999332","40.319355999994556","0","12.13228299999307","720","","-32704.2314453125","-42087.62841796875","-0.00011444091796875","-0.00003814697265625"
"TanhBackward0","227.92246199999332","28.187073000001487","0","4.039573999998858","720","","9383.39697265625","-1240.84814453125","-0.0000762939453125","-0.00003814697265625"
"aten::tanh_backward","227.92246199999332","24.14749900000263","227.92246199999332","16.63129000001657","720","","10624.2451171875","13276.81298828125","-0.00003814697265625","-0.0000152587890625"
"autograd::engine::evaluate_function: PowBackward0","578.7781150001302","126.37333899999585","0","29.22668900002737","720","","-69086.447265625","-70239.31298828125","-0.0001220703125","-0.00008392333984375"
"PowBackward0","406.2349180000591","81.26804999999818","0","8.199307999968761","720","","6435.15673828125","-36043.25537109375","0.0000762939453125","0.00000762939453125"
"aten::pow","149.85720200004394","28.76642999995942","149.85720200004394","20.858003999984124","720","","15041.6689453125","15259.29833984375","0.00037384033203125","0.00028228759765625"
"aten::result_type","0","1.8860859998624073","0","1.8860859998624073","14040","","-8.49267578125","-8.49267578125","0","0"
"aten::add_","379.576538000123","64.98103400004224","379.576538000123","41.64987300002493","5100","","-7346.3203125","-5132.4326171875","-0.000091552734375","-0.00006866455078125"
"autograd::engine::evaluate_function: TransposeBackward0","0","16.042323999999674","0","8.952372999957763","720","","-2527.25048828125","-1781.3984375","0","-0.0000152587890625"
"TransposeBackward0","0","7.089951000041911","0","1.4766640000867193","720","","-745.85205078125","-153.70751953125","0.0000152587890625","0.00000762939453125"
"autograd::engine::evaluate_function: ScaledDotProductEfficientAttentionBackward0","1494.4474830000681","1290.6125619999593","0","28.216833999976632","720","","-34489.9599609375","-26300.3232421875","-0.0000457763671875","-0.0000152587890625"
"ScaledDotProductEfficientAttentionBackward0","1494.4474830000681","1262.3957279999827","0","8.057032999955467","720","","-8189.63671875","-1284.970703125","-0.000030517578125","0.0000152587890625"
"aten::_scaled_dot_product_efficient_attention_backward","1494.4474830000681","1254.3386950000272","0","20.242624999927706","720","","-6904.666015625","-2029.63330078125","-0.0000457763671875","0"
"aten::_efficient_attention_backward","1494.4474830000681","1214.5264410000048","1445.8072860000352","43.49326400013501","720","","-2928.3046875","-13166.39599609375","-0.00003814697265625","0.00002288818359375"
"aten::contiguous","2.4577270000145073","42.00640099999879","0","1.4434189999904483","720","","-4380.53759765625","-78.396484375","0.00000762939453125","-0.00000762939453125"
"aten::clone","2.4577270000145073","40.56298200000834","0","3.652847000003909","720","","-4302.14111328125","-634.84814453125","0.0000152587890625","0"
"cudaFuncGetAttributes","0","4.536901000003796","0","4.536901000003796","720","","-695.451171875","-695.451171875","0","0"
"autograd::engine::evaluate_function: PermuteBackward0","0","45.536941000044116","0","26.67168399996392","2160","","-3354.9453125","-1740.36962890625","0.00002288818359375","0.000030517578125"
"PermuteBackward0","0","18.865257000080195","0","5.950414000052959","2160","","-1614.57568359375","-717.67236328125","-0.00000762939453125","0.00000762939453125"
"aten::permute","0","12.914843000027235","0","10.863531000026269","2160","","-896.9033203125","-670.63037109375","-0.0000152587890625","-0.0000152587890625"
"autograd::engine::evaluate_function: SplitBackward0","35.17427599999658","52.74688999995566","0","12.632064999942552","720","","-5752.45068359375","-15649.609375","-0.00000762939453125","-0.0000152587890625"
"SplitBackward0","35.17427599999658","40.114825000013106","0","3.3464329999636395","720","","9897.15869140625","-59.11962890625","0.00000762939453125","0"
"autograd::engine::evaluate_function: EmbeddingBackward0","161.82556500000925","14.961188000018941","0","3.027558000031742","120","","-1357.73486328125","-19529.978515625","0","0"
"EmbeddingBackward0","44.44172399999318","8.758432999994257","0","0.4608200000189245","120","","9252.83203125","201.36376953125","0","0.00000762939453125"
"aten::embedding_backward","44.44172399999318","8.297612999975332","0","0.3337459999824641","120","","9051.46826171875","338.22705078125","-0.00000762939453125","0"
"aten::embedding_dense_backward","44.44172399999318","7.9638669999928675","11.445593000000343","1.9911569999996572","120","","8713.2412109375","-364.3271484375","-0.00000762939453125","0"
"aten::add","117.40518600001465","3.5326619999835964","117.40518600001465","2.9761209999842104","75","","8919.4189453125","8897.51171875","0","0"
"autograd::engine::evaluate_function: BroadcastBackward","5608.888101000042","292.3197530000021","0","12.724462000009604","15","","-21929.5126953125","-29054.8076171875","0","0"
"BroadcastBackward","5608.888101000042","279.5952909999925","0","8.257753999996348","15","","7125.294921875","0","0","0"
"ReduceAddCoalesced","5608.888101000042","271.3375369999962","5516.557508000054","104.67938200007298","15","","7125.294921875","-19680.4658203125","0","0"
"autograd::engine::evaluate_function: torch::autograd::AccumulateGrad","0","23.289410000042523","0","13.949725000100676","2220","","0","0","0","0"
"torch::autograd::AccumulateGrad","0","9.339684999941849","0","4.873596999880858","2220","","0","0","0","0"
"aten::detach","0","4.830680000064895","0","2.3235470000350613","2369","","0","0","0","0"
"detach","0","2.507133000029833","0","2.507133000029833","2369","","0","0","0","0"
"aten::_foreach_norm","30.17130600000359","9.971948000003001","30.153769000007074","8.302939000004203","15","","1.083984375","-3.9111328125","0","0"
"aten::stack","0.05411299999221228","7.828498999999603","0","2.257682000060682","15","","0.0146484375","0","0","0"
"aten::unsqueeze","0","4.1878099999423135","0","3.23012899989693","2220","","0","0","0","0"
"aten::linalg_vector_norm","0.04569599999766797","0.6128509999964153","0.04569599999766797","0.4502149999999674","15","","0.00732421875","0.00732421875","0","0"
"aten::reciprocal","0.020222999995108695","0.3665519999990938","0.020222999995108695","0.24171300000103657","15","","0.00732421875","0.00732421875","0","0"
"aten::clamp","0.022623999991687016","0.421091999997152","0.022623999991687016","0.2830649999995949","15","","0.00732421875","0.00732421875","0","0"
"aten::_foreach_mul_","192.33297900000377","7.915899000008125","192.33297900000377","5.433171000062721","45","","0","0","0","0"
"Optimizer.step#AdamW.step","630.3757030000356","87.94697300000395","0","33.430546000031754","15","","0","-7133.3916015625","0","-0.000057220458984375"
"aten::lift_fresh","0","0.006844000001205132","0","0.006844000001205132","15","","0","0","0","0"
"aten::detach_","0","0.05002899999986403","0","0.03288000000570901","15","","0","0","0","0"
"detach_","0","0.01714899999415502","0","0.01714899999415502","15","","0","0","0","0"
"aten::_foreach_add_","64.1324140000185","8.494903999996371","64.1324140000185","5.40003100002918","30","","0","0","0","0"
"aten::_foreach_lerp_","94.44288899999414","1.4335110000052955","94.44288899999414","0.817978999998304","15","","0","0","0","0"
"aten::_foreach_addcmul_","94.50806600000523","3.418959999999497","94.50806600000523","2.5816510000061244","15","","0","0","0","0"
"aten::item","0.023680000000167636","2695.8636489999667","0","4.463689000038081","4454","","0","0","0","0"
"aten::_local_scalar_dense","0.023680000000167636","2691.399959999929","0.023680000000167636","1.2462659999290482","4454","","0","0","0","0"
"aten::_foreach_sqrt","63.82834100000933","21.13277099999797","63.82834100000933","6.657427999955951","15","","7133.3916015625","0","0","0"
"aten::_foreach_div_","63.924187000016914","3.634568999998039","63.924187000016914","2.7144129999618745","15","","0","0","0","0"
"aten::_foreach_addcdiv_","120.62096599999117","4.277375000003725","120.62096599999117","3.3499950000570387","15","","0","0","0","0"
"cudaDeviceSynchronize","0","732.4006030000007","0","732.4006030000007","12","","0","0","0","0"
"Optimizer.step#AdamW.step","630.945122999998","0","630.945122999998","0","15","","0","0","0","0"
"cudaHostAlloc","0.0664320000000298","5.566295999999391","0","2.7167069999987725","19","","31.392578125","-15.875","0","0"
"Memcpy DtoH (Device -> Pinned)","0.023680000000167636","0","0.023680000000167636","0","13","","0","0","0","0"
"aten::random_","0","0.013013999999966473","0","0.013013999999966473","1","","0","0","0","0"
"aten::set_","0","1.3892869999939577","0","1.3892869999939577","296","","0","0","0","0"
"Memcpy DtoH (Device -> Pageable)","100.05311899999809","0","100.05311899999809","0","148","","0","0","0","0"
"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)","22.38724600001611","0","22.38724600001611","0","1400","","0","0","0","0"
"autograd::engine::evaluate_function: NativeDropoutBackward0","20.245459000019355","93.36564700001851","0","23.56970700000599","1400","","394.31396484375","-6676.01513671875","0.0000762939453125","0"
"NativeDropoutBackward0","20.245459000019355","69.79594000001252","0","5.268505999978632","1400","","7070.3291015625","259.39501953125","0.0000762939453125","-0.000030517578125"
"aten::native_dropout_backward","20.245459000019355","64.52743400003388","20.245459000019355","24.886101000022144","1400","","6810.93408203125","-551.029296875","0.0001068115234375","0.00006103515625"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)","20.245459000019355","0","20.245459000019355","0","1400","","0","0","0","0"
"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)","1358.197600000035","0","1358.197600000035","0","672","","0","0","0","0"