"Name","Device Time Total (ms)","CPU Time Total (ms)","Self Device Time Total (ms)","Self CPU Time Total (ms)","Calls","Input Shapes","Device Memory Usage (MB)","Self Device Memory Usage (MB)","CPU Memory Usage (MB)","Self CPU Memory Usage (MB)"
"ProfilerStep*","8065.317240000066","20204.107582","0","6039.944603000041","10","","0.80078125","-347814.3349609375","0","-0.00183868408203125"
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)","613.0169909999985","0","613.0169909999985","0","250","","0","0","0","0"
"enumerate(DataLoader)#_MultiProcessingDataLoaderIter.__next__","0","13.352988999998907","0","12.857202999998593","21","","0","0","0","0"
"aten::to","0.3277119999988936","8557.97586299998","0","0.7467439999862109","2190","","2.5","0","0","0"
"aten::_to_copy","0.3277119999988936","8557.229118999994","0","0.7425469999965281","40","","2.5","0","0","0"
"aten::empty_strided","0","13.754620000010512","0","12.18892300001361","1730","","7752.9814453125","7752.9814453125","0","0"
"aten::copy_","663.4780689999945","8662.246841999984","663.4780689999945","4.937891000006115","368","","0","0","0","0"
"cudaMemcpyAsync","0","102.0196439999866","0","102.0196439999866","211","","0","0","0","0"
"cudaStreamSynchronize","0","12123.489975999986","0","12123.415167999985","201","","0","0","0","0"
"Memset (Device)","2.4552820000279225","0","2.4552820000279225","0","1834","","0","0","0","0"
"ampere_sgemm_128x64_nn","221.88430100001622","0","221.88430100001622","0","250","","0","0","0","0"
"cudaPointerGetAttributes","0","0.27167300000964495","0","0.2676070000100026","56","","-71.0625","-71.0625","0.0000152587890625","0.00000762939453125"
"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)","866.5897420000184","0","866.5897420000184","0","1289","","0","0","0","0"
"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)","61.7609750000133","0","61.7609750000133","0","520","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_256x128_8x4_nn_align1>(cutlass_80_simt_sgemm_256x128_8x4_nn_align1::Params)","2075.681446999966","0","2075.681446999966","0","510","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)","1078.026050000032","0","1078.026050000032","0","1289","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#2}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#2}, at::detail::Array<char*, 2>)","215.8160949999924","0","215.8160949999924","0","250","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::tanh_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::tanh_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)","216.0428300000179","0","216.0428300000179","0","250","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<float>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<float>, at::detail::Array<char*, 2>)","215.66599900001447","0","215.66599900001447","0","261","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)","859.5729149999528","0","859.5729149999528","0","778","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_128x64_8x5_nn_align1>(cutlass_80_simt_sgemm_128x64_8x5_nn_align1::Params)","859.243151000014","0","859.243151000014","0","250","","0","0","0","0"
"ampere_sgemm_128x128_tn","1968.8762830000003","0","1968.8762830000003","0","21","","0","0","0","0"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})","462.22040699999553","0","462.22040699999553","0","164","","0","0","0","0"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1} const&)::{lambda(int)#1})","0.14137399999715852","0","0.14137399999715852","0","21","","0","0","0","0"
"void at::native::(anonymous namespace)::cunn_SoftMaxForward<4, float, float, float, at::native::(anonymous namespace)::LogSoftMaxForwardEpilogue>(float*, float const*, int)","297.88892500000446","0","297.88892500000446","0","21","","0","0","0","0"
"void at::native::(anonymous namespace)::nll_loss_forward_reduce_cuda_kernel_2d<float, float, long>(float*, float*, float const*, long const*, float const*, bool, long, long, long, long)","7.260367999999784","0","7.260367999999784","0","21","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)","218.564542000008","0","218.564542000008","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::nll_loss_backward_reduce_cuda_kernel_2d<float, long>(float*, float const*, long const*, float const*, float const*, bool, int, int, long, long)","2.276385000003909","0","2.276385000003909","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::cunn_SoftMaxBackward<4, float, float, float, at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue>(float*, float const*, float const*, long)","270.14546599999596","0","270.14546599999596","0","11","","0","0","0","0"
"Memcpy DtoD (Device -> Device)","155.33933899999673","0","155.33933899999673","0","11","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_128x256_8x4_nt_align1>(cutlass_80_simt_sgemm_128x256_8x4_nt_align1::Params)","835.3519219999976","0","835.3519219999976","0","143","","0","0","0","0"
"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)","61.92883799997968","0","61.92883799997968","0","275","","0","0","0","0"
"void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)","75.1193550000175","0","75.1193550000175","0","275","","0","0","0","0"
"ampere_sgemm_128x64_tn","1452.1296329999902","0","1452.1296329999902","0","528","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_128x64_8x5_nt_align1>(cutlass_80_simt_sgemm_128x64_8x5_nt_align1::Params)","846.7799810000172","0","846.7799810000172","0","396","","0","0","0","0"
"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)","122.6605369999727","0","122.6605369999727","0","539","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::tanh_backward_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::tanh_backward_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)","171.0315340000026","0","171.0315340000026","0","132","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#1}, at::detail::Array<char*, 2>)","112.69226699998543","0","112.69226699998543","0","132","","0","0","0","0"
"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)","12.935615000001853","0","12.935615000001853","0","132","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<unsigned char>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<unsigned char>, at::detail::Array<char*, 1>)","6.208943000013823","0","6.208943000013823","0","132","","0","0","0","0"
"fmha_cutlassB_f32_aligned_64x64_k64_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, false, false, 64, 64, 64, false>::Params)","576.0504939999967","0","576.0504939999967","0","84","","0","0","0","0"
"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 3, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)","81.08131099997938","0","81.08131099997938","0","132","","0","0","0","0"
"void at::native::(anonymous namespace)::embedding_backward_feature_kernel<float, float, long>(long const*, float const*, float*, int, long, int)","0.44604800000053363","0","0.44604800000053363","0","11","","0","0","0","0"
"void (anonymous namespace)::elementwise_kernel_with_index<int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}, function_traits<at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>::result_type*)","0.06256400000036229","0","0.06256400000036229","0","31","","0","0","0","0"
"void at_cuda_detail::cub::DeviceRadixSortHistogramKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy800, false, long, unsigned long long>(unsigned long long*, long const*, unsigned long long, int, int)","0.09315200000058393","0","0.09315200000058393","0","11","","0","0","0","0"
"void at_cuda_detail::cub::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy800, unsigned long long>(unsigned long long*)","0.026656000001472422","0","0.026656000001472422","0","11","","0","0","0","0"
"void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy800, false, long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long, int, int>(int*, int*, unsigned long long*, unsigned long long const*, long*, long const*, at::cuda::cub::detail::OpaqueType<8>*, at::cuda::cub::detail::OpaqueType<8> const*, int, int, int)","1.0738280000035885","0","1.0738280000035885","0","88","","0","0","0","0"
"void at_cuda_detail::cub::DeviceCompactInitKernel<at_cuda_detail::cub::ScanTileState<int, true>, long*>(at_cuda_detail::cub::ScanTileState<int, true>, int, long*)","0.04784100000816397","0","0.04784100000816397","0","11","","0","0","0","0"
"void at_cuda_detail::cub::DeviceUniqueByKeySweepKernel<at_cuda_detail::cub::DeviceUniqueByKeyPolicy<long const*>::Policy520, long const*, thrust::counting_iterator<int, thrust::use_default, thrust::use_default, thrust::use_default>, long*, long*, long*, at_cuda_detail::cub::ScanTileState<int, true>, at_cuda_detail::cub::Equality, int>(long const*, thrust::counting_iterator<int, thrust::use_default, thrust::use_default, thrust::use_default>, long*, long*, long*, at_cuda_detail::cub::ScanTileState<int, true>, at_cuda_detail::cub::Equality, int, int)","0.07347100000281352","0","0.07347100000281352","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::krn_partials_per_segment<long>(long*, long const*, long const*, long)","0.029664000001735986","0","0.029664000001735986","0","11","","0","0","0","0"
"void at_cuda_detail::cub::DeviceScanInitKernel<at_cuda_detail::cub::ScanTileState<long, true> >(at_cuda_detail::cub::ScanTileState<long, true>, int)","0.019742999998736195","0","0.019742999998736195","0","11","","0","0","0","0"
"void at_cuda_detail::cub::DeviceScanKernel<at_cuda_detail::cub::DeviceScanPolicy<long>::Policy600, long const*, long*, at_cuda_detail::cub::ScanTileState<long, true>, at::cuda::cub::(anonymous namespace)::SumOp<long>, at_cuda_detail::cub::detail::InputValue<long, long*>, int, long>(long const*, long*, at_cuda_detail::cub::ScanTileState<long, true>, int, at::cuda::cub::(anonymous namespace)::SumOp<long>, at_cuda_detail::cub::detail::InputValue<long, long*>, int)","0.05279799999960232","0","0.05279799999960232","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::compute_num_of_partial_segments<long>(long const*, long const*, long const*, long*)","0.02556899999920279","0","0.02556899999920279","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::krn_partial_segment_offset<long>(long*, long const*, long const*, long const*, long const*)","0.05398199999413919","0","0.05398199999413919","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::compute_grad_weight<float, long>(long const*, float const*, long const*, long, long, long const*, long const*, at::AccumulateType<float, true>::type*, long)","2.237220999998972","0","2.237220999998972","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::sum_and_scatter<float, long>(long const*, float*, long, long const*, long const*, at::AccumulateType<float, true>::type const*, long const*, long const*, long, long)","1.0207690000003204","0","1.0207690000003204","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::LpNormFunctor<float, (at::native::NormType)1, float, 1, 1, 0>, float*, int>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::LpNormFunctor<float, (at::native::NormType)1, float, 1, 1, 0>, float*, int)","22.52949000001163","0","22.52949000001163","0","77","","0","0","0","0"
"void at::native::lpnorm_cleanup<float, (at::native::NormType)1, float, float>(float const*, at::native::TensorListAddresses, int)","0.056863999996799974","0","0.056863999996799974","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)","0.06703999999468215","0","0.06703999999468215","0","22","","0","0","0","0"
"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::NormTwoOps<float, float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::NormTwoOps<float, float, float>, unsigned int, float, 4>)","0.056672999996575525","0","0.056672999996575525","0","11","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::reciprocal_kernel_cuda(at::TensorIteratorBase&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::reciprocal_kernel_cuda(at::TensorIteratorBase&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)","0.025120000001741572","0","0.025120000001741572","0","11","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)","0.026433999999193474","0","0.026433999999193474","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarTensorFunctor<float, 1, 1, 0>, std::multiplies<float>, float*, float>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarTensorFunctor<float, 1, 1, 0>, std::multiplies<float>, float*, float)","46.731986999999386","0","46.731986999999386","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::multiplies<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::multiplies<float>, float)","94.97756800001825","0","94.97756800001825","0","154","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::TernaryOpScalarFunctor<float, 2, 2, 0>, at::native::LerpFunctor<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::TernaryOpScalarFunctor<float, 2, 2, 0>, at::native::LerpFunctor<float>, float)","69.67497999999964","0","69.67497999999964","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<3>, at::native::(anonymous namespace)::PointwiseOpScalarFunctor<float, 3, 3, 0>, std::multiplies<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<3>, at::native::(anonymous namespace)::PointwiseOpScalarFunctor<float, 3, 3, 0>, std::multiplies<float>, float)","69.36860900001635","0","69.36860900001635","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::UnaryOpFunctor<float, 2, 1, 1>, at::native::Sqrt<float> >(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::UnaryOpFunctor<float, 2, 1, 1>, at::native::Sqrt<float>)","46.983187999998684","0","46.983187999998684","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 1>, at::native::(anonymous namespace)::BinaryOpScalarListFunctor<float, 1, 1, 0>, std::divides<float> >(at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 1>, at::native::(anonymous namespace)::BinaryOpScalarListFunctor<float, 1, 1, 0>, std::divides<float>)","47.082251000008426","0","47.082251000008426","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::plus<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::plus<float>, float)","47.206548000006585","0","47.206548000006585","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 3>, at::native::(anonymous namespace)::PointwiseOpScalarListFunctor<float, 3, 3, 0>, std::divides<float> >(at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 3>, at::native::(anonymous namespace)::PointwiseOpScalarListFunctor<float, 3, 3, 0>, std::divides<float>)","88.53870499998587","0","88.53870499998587","0","77","","0","0","0","0"
"ProfilerStep*","19806.506787999995","0","19806.506787999995","0","10","","0","0","0","0"
"Memcpy HtoD (Pinned -> Device)","0.3277119999988936","0","0.3277119999988936","0","40","","0","0","0","0"
"aten::view","0","17.28182999999146","0","17.279858999990626","6040","","0","0","0","0"
"aten::arange","0.1215440000006929","3.8968020000034014","0.06077200000034645","0.8113769999931101","60","","1.5625","0","0","0"
"aten::empty","0","123.89152800009447","0","34.706846000089776","4371","","102355.537109375","102355.537109375","0.0029754638671875","0.0029754638671875"
"aten::resize_","0","0.6831630000059958","0","0.6831630000059958","90","","540.78125","540.78125","0","0"
"cudaLaunchKernel","0","186.67216800016422","0","186.64664900016203","9830","","0","0","0","0"
"aten::unsqueeze","0","3.323330000031041","0","2.6629200000448616","1500","","0","0","0","0"
"aten::as_strided","0","6.851752000035486","0","6.851752000035486","6930","","0","0","0","0"
"aten::embedding","3.6141880000007807","3.274430999995442","0","0.8078379999904428","40","","540","0","0","0"
"aten::reshape","0","6.746524000065867","0","3.0720520000911784","1540","","0","0","0","0"
"aten::index_select","3.6141880000007807","2.2456649999993386","3.6141880000007807","1.0016089999927207","40","","540","0","0","0"
"void at::native::(anonymous namespace)::indexSelectLargeIndex<float, long, unsigned int, 2, 2, -2, true>(at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<long const, unsigned int>, int, int, unsigned int, unsigned int, long)","3.6141880000007807","0","3.6141880000007807","0","40","","0","0","0","0"
"aten::add","665.0211740000116","28.384391999970422","665.0211740000116","18.957730999937514","1000","","59552.3779296875","59528.3779296875","0","0"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})","1.8067880000039003","0","1.8067880000039003","0","20","","0","0","0","0"
"aten::dropout","15.188067000010982","104.05604600000638","0","0.8298790000255686","500","","3000.474609375","0","0","0"
"aten::layer_norm","59.39172200001334","39.70747800000012","0","2.5650980000228154","500","","12015.625","-15.625","0","0"
"aten::native_layer_norm","59.39172200001334","37.1423799999773","59.39172200001334","15.904083999959985","500","","12031.25","0","0","0"
"aten::addmm","2387.4708780000087","65.52754899999476","2387.4708780000087","41.931047999986916","960","","51840.8642578125","51838.8642578125","0","0"
"cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags","0","3.6930100000055974","0","3.6930100000055974","1240","","0","0","0","0"
"cudaFuncSetAttribute","0","534.7408569999831","0","534.7408569999831","740","","0","0","0","0"
"aten::split","0","8.279410999999614","0","2.837672999993665","240","","0","0","0","0"
"aten::narrow","0","5.415670000005979","0","2.1467710000206717","720","","0","0","0","0"
"aten::slice","0","4.0335289999807715","0","2.936290999974124","800","","0","0","0","0"
"aten::permute","0","5.950685999978567","0","5.0934949999623935","1080","","0","0","0","0"
"aten::scaled_dot_product_attention","589.8186679999984","30.86904799999902","0","4.563853000007803","240","","5805","0","0.0018310546875","-0.0018310546875"
"aten::_scaled_dot_product_efficient_attention","589.8186679999984","26.30519499999122","0","4.7203390000246","240","","5805","0","0.003662109375","0"
"aten::transpose","0","14.527389000033262","0","10.43022499999986","3420","","0","0","0","0"
"aten::_efficient_attention_forward","589.8186679999984","17.890802999982842","589.8186679999984","7.745133999937679","240","","5805","-24","0.003662109375","-0.00000762939453125"
"cudaStreamIsCapturing","0","0.9703299999632873","0","0.9703299999632873","677","","0","0","0","0"
"cudaMemsetAsync","0","10.746996000028913","0","10.746996000028913","1680","","0","0","0","0"
"cudaOccupancyMaxActiveBlocksPerMultiprocessor","0","1.3611920000207611","0","1.3611920000207611","720","","0","0","0","0"
"aten::mul","1810.176911999984","48.98354700001213","1810.176911999984","31.077079000013416","1930","","175680.0048828125","175680.0048828125","0","0"
"aten::pow","309.67401599997794","12.47579000000516","309.67401599997794","8.20625700001954","360","","34560","34560","0","0"
"aten::result_type","0","1.0558469999511726","0","1.0558469999511726","9240","","0","0","0","0"
"aten::tanh","207.43253800001787","5.837480999986874","207.43253800001787","3.9476119999755173","240","","23040","23040","0","0"
"aten::linear","1875.884103","2.522505000000587","0","0.1567390000007581","20","","31410.625","0","0","0"
"aten::t","0","8.863247000029544","0","3.76431500001112","1020","","0","0","0","0"
"aten::matmul","1875.884103","2.0924090000004507","0","0.2796059999894351","20","","31410.625","0","0","0"
"aten::mm","5343.646549000026","44.12324300007569","5343.646549000026","27.87174700001045","1000","","56542.849609375","56542.849609375","0","0"
"aten::_unsafe_view","0","0.09792799999914133","0","0.09792799999914133","20","","0","0","0","0"
"aten::contiguous","290.46054899999194","7.114355000001844","0","0.36756600002455525","160","","31426.201171875","0","0","0"
"aten::clone","290.46054899999194","6.746788999977289","0","0.8341459999852814","160","","31426.201171875","0","0","0"
"aten::empty_like","0","7.994481999992626","0","1.6884889999313746","490","","36827.9306640625","0","0","0"
"aten::cross_entropy_loss","290.6400120000043","2.6819080000040123","0","0.23907800001231955","20","","15689.990234375","-15689.9755859375","0","0"
"aten::log_softmax","283.72172500000454","1.3101239999961107","0","0.1428979999879375","20","","31379.951171875","0","0","0"
"aten::_log_softmax","283.72172500000454","1.1583390000024811","283.72172500000454","0.5972949999985285","20","","31379.951171875","31379.951171875","0","0"
"aten::nll_loss_nd","6.918286999999778","1.1327059999955817","0","0.08806999999890104","20","","0.0146484375","0","0","0"
"aten::nll_loss","6.918286999999778","1.0446359999966808","0","0.1082549999996554","20","","0.0146484375","-0.0048828125","0","0"
"aten::nll_loss_forward","6.918286999999778","0.9363809999970254","6.918286999999778","0.6830959999952465","20","","0.01953125","0.01953125","0","0"
"cudaFree","0","801.5357430000096","0","801.5357430000096","89","","0","0","0","0"
"aten::ones_like","0.027615999999688938","0.683463000001153","0","0.05654199999780394","10","","0.0048828125","0","0","0"
"aten::fill_","204.65753400002163","3.555091999998549","204.65753400002163","1.6654320000102742","190","","0","0","0","0"
"autograd::engine::evaluate_function: NllLossBackward0","66.96088900000974","5.294094000003766","0","0.33419300000509244","10","","15689.345703125","-0.6298828125","0","0"
"NllLossBackward0","66.96088900000974","4.959900999998673","0","0.13571099999756553","10","","15689.9755859375","0","0","0"
"aten::nll_loss_backward","66.96088900000974","4.824190000001108","2.0687370000039227","0.38525599999236876","10","","15689.9755859375","15689.9755859375","0","0"
"cudaMalloc","0","183.9189060000018","0","183.9189060000018","83","","0","0","0","0"
"aten::zero_","204.62991800002195","4.102836999979336","0","0.9122559999837541","180","","0","0","0","0"
"autograd::engine::evaluate_function: LogSoftmaxBackward0","246.33053199999594","81.39580499999877","0","0.12045200000237674","10","","-15689.9755859375","-31379.951171875","0","0"
"LogSoftmaxBackward0","246.33053199999594","81.2753529999964","0","0.07889499999792315","10","","15689.9755859375","0","0","0"
"aten::_log_softmax_backward_data","246.33053199999594","81.19645799999847","246.33053199999594","0.2294899999939371","10","","15689.9755859375","15689.9755859375","0","0"
"autograd::engine::evaluate_function: ViewBackward0","0","19.684613000023877","0","8.991130000036907","1470","","0","0","0","0"
"ViewBackward0","0","10.69348299998697","0","4.307017999926582","1470","","0","0","0","0"
"autograd::engine::evaluate_function: CloneBackward0","0","0.062068000002531334","0","0.055049000000115485","10","","0","0","0","0"
"CloneBackward0","0","0.007019000002415851","0","0.007019000002415851","10","","0","0","0","0"
"autograd::engine::evaluate_function: SliceBackward0","412.9653529999999","90.54643399999942","0","0.1911980000117328","20","","15.3369140625","-31379.951171875","0","0"
"SliceBackward0","412.9653529999999","90.3552359999877","0","0.08251399999368005","20","","31395.2880859375","0","0","0"
"aten::slice_backward","412.9653529999999","90.27272199999402","0","0.3067579999915324","20","","31395.2880859375","0","0","0"
"aten::zeros","134.08504900000244","90.4427150000031","0","0.3202470000265166","50","","32900.9912109375","0","0","0"
"autograd::engine::evaluate_function: UnsafeViewBackward0","0","0.1552920000026934","0","0.0630620000057388","10","","0","0","0","0"
"UnsafeViewBackward0","0","0.09222999999695458","0","0.03335600000550039","10","","0","0","0","0"
"autograd::engine::evaluate_function: MmBackward0","1026.102705999992","2.0148929999987595","0","0.17004199999873526","10","","-14232.939453125","-15945.3125","0","0"
"MmBackward0","1026.102705999992","1.8448510000000242","0","0.38368299999972805","10","","1712.373046875","0","0","0"
"autograd::engine::evaluate_function: TBackward0","0","0.15933800000324846","0","0.07134500000951811","10","","0","0","0","0"
"TBackward0","0","0.08799299999373034","0","0.01651799999200739","10","","0","0","0","0"
"autograd::engine::evaluate_function: NativeLayerNormBackward0","173.5735220000185","27.461822000021115","0","5.669785000044852","250","","-11774.16015625","-17775.625","0","0"
"NativeLayerNormBackward0","124.59725599999773","17.222952000007034","0","1.9847710000385996","250","","6001.46484375","0","0","0"
"aten::native_layer_norm_backward","124.59725599999773","15.238180999968433","124.59725599999773","5.21832599996496","250","","6001.46484375","0","0","0"
"autograd::engine::evaluate_function: torch::autograd::AccumulateGrad","0","18.921093999975128","0","9.137378000030992","1480","","0","0","0","0"
"torch::autograd::AccumulateGrad","0","9.783715999944135","0","3.8876949999546633","1480","","0","0","0","0"
"aten::detach","0","6.421048999977298","0","2.6984459999764803","1629","","0","0","0","0"
"detach","0","3.722603000000818","0","3.722603000000818","1629","","0","0","0","0"
"autograd::engine::evaluate_function: AddBackward0","0.33596899999585","4.169606999988202","0","3.4062269999771377","490","","34.5","0","0","0"
"AddBackward0","0","0.45158800001163035","0","0.45158800001163035","490","","0","0","0","0"
"autograd::engine::evaluate_function: AddmmBackward0","2553.458912999995","88.87543999999272","0","11.428371999989961","480","","-16320.984375","-39744","0","0"
"AddmmBackward0","2441.6597400000346","55.31530399999488","0","5.718787999898428","480","","23419.8515625","0","0","0"
"aten::sum","123.94137799995835","24.864931999999563","123.94137799995835","17.204787999985506","610","","82.6640625","82.6640625","0","0"
"autograd::engine::evaluate_function: MulBackward0","754.2619740000437","21.540927999992157","0","5.283374000019626","480","","-11520","-69120","-0.00274658203125","-0.00274658203125"
"MulBackward0","600.2468280000298","14.70686799996416","0","1.8363379999785685","480","","57600","0","0","0"
"autograd::engine::evaluate_function: TanhBackward0","155.52429900000269","4.374643999994965","0","0.9787739999936893","120","","-11520","-23040","0","0"
"TanhBackward0","155.52429900000269","3.395870000001276","0","0.5152090000063181","120","","11520","0","0","0"
"aten::tanh_backward","155.52429900000269","2.8806609999949577","155.52429900000269","1.889092000005534","120","","11520","11520","0","0"
"autograd::engine::evaluate_function: PowBackward0","513.4254309999761","13.77052099999925","0","2.2328140000044367","120","","-23040","-34560","0","0"
"PowBackward0","361.6039509999859","9.485956000002567","0","1.108097999994643","120","","11520","-23040","0","0"
"aten::add_","354.81289200002493","9.674552999956068","354.81289200002493","6.303813999932725","1960","","0","0","0","0"
"autograd::engine::evaluate_function: TransposeBackward0","0","1.8116359999871348","0","0.7836519999871961","120","","0","0","0","0"
"TransposeBackward0","0","1.0279839999999385","0","0.23925999999209308","120","","0","0","0","0"
"autograd::engine::evaluate_function: ScaledDotProductEfficientAttentionBackward0","915.6803149999946","570.0797370000074","0","2.351657000007108","120","","2835","-5805","-0.0018310546875","-0.0018310546875"
"ScaledDotProductEfficientAttentionBackward0","915.6803149999946","567.7280800000003","0","1.1670159999944736","120","","8640","0","0","0"
"aten::_scaled_dot_product_efficient_attention_backward","915.6803149999946","566.5610640000058","0","3.0550790000048","120","","8640","0","0","0"
"aten::_efficient_attention_backward","915.6803149999946","560.3037559999984","866.2628800000019","6.887851000004448","120","","8640","-5852.8125","0","0"
"cudaFuncGetAttributes","0","0.6115440000137314","0","0.6115440000137314","120","","0","0","0","0"
"autograd::engine::evaluate_function: PermuteBackward0","0","5.315942000012379","0","2.514807000013301","360","","0","0","0","0"
"PermuteBackward0","0","2.801134999999078","0","0.9039199999948032","360","","0","0","0","0"
"autograd::engine::evaluate_function: SplitBackward0","73.6647499999795","5.998232999994885","0","1.2150020000040531","120","","0","-8640","0","0"
"SplitBackward0","73.6647499999795","4.783230999990832","0","0.5079299999861978","120","","8640","0","0","0"
"aten::cat","73.72638199997414","5.22149600000144","73.72638199997414","3.49344000000204","130","","8640.009765625","8640.009765625","0","0"
"autograd::engine::evaluate_function: EmbeddingBackward0","29.784163000017404","5.974447999996366","0","0.3591699999945704","20","","-244.578125","-3219.32421875","0","0"
"EmbeddingBackward0","10.46258100002259","5.385157999996794","0","0.07578399999532849","20","","1502.373046875","0","0","0"
"aten::embedding_backward","10.46258100002259","5.3093740000014655","0","0.12195299999974668","20","","1502.373046875","0","0","0"
"aten::embedding_dense_backward","10.46258100002259","5.187421000001719","4.920521000019741","1.5932649999866262","20","","1502.373046875","-268.4423828125","0","0"
"cudaDeviceGetAttribute","0","0.037556000004056844","0","0.037556000004056844","50","","0","0","0","0"
"cudaPeekAtLastError","0","0.030544999999459834","0","0.030544999999459834","170","","0","0","0","0"
"aten::_foreach_norm","20.56894200000819","7.090214999994728","20.5380620000083","5.950305999972392","10","","0.72265625","-2.607421875","0","0"
"aten::stack","0.06163199999462813","5.779124999998603","0","1.753977999974275","10","","0.009765625","0","0","0"
"aten::linalg_vector_norm","0.0521289999964647","0.4371449999988545","0.0521289999964647","0.3283840000005439","10","","0.0048828125","0.0048828125","0","0"
"aten::reciprocal","0.023104000001680107","0.2501170000003185","0.023104000001680107","0.16198299999488516","10","","0.0048828125","0.0048828125","0","0"
"aten::clamp","0.024321999999228863","0.35626800000364894","0.024321999999228863","0.2367890000117477","10","","0.0048828125","0.0048828125","0","0"
"aten::_foreach_mul_","128.90306100001746","6.015353999992367","128.90306100001746","4.279039999993984","30","","0","0","0","0"
"Optimizer.step#AdamW.step","421.7717530000345","61.93444599999883","0","23.669889999957057","10","","0","-4750.001953125","0","-0.00003814697265625"
"aten::lift_fresh","0","0.006416000003693625","0","0.006416000003693625","10","","0","0","0","0"
"aten::detach_","0","0.038004999994998796","0","0.024730999995721505","10","","0","0","0","0"
"detach_","0","0.013273999999277294","0","0.013273999999277294","10","","0","0","0","0"
"aten::_foreach_add_","42.90154500000691","5.686514999997569","42.90154500000691","3.6234550000962336","20","","0","0","0","0"
"aten::_foreach_lerp_","63.371477999999655","1.0154750000059138","63.371477999999655","0.578013000004692","10","","0","0","0","0"
"aten::_foreach_addcmul_","63.072627000016624","2.649240000002319","63.072627000016624","2.081940999961458","10","","0","0","0","0"
"aten::item","0.02505499999690801","3573.9672070000415","0","2.8880860000553077","2974","","0","0","0","0"
"aten::_local_scalar_dense","0.02505499999690801","3571.079120999986","0.02505499999690801","1.2262469999880996","2974","","0","0","0","0"
"aten::_foreach_sqrt","42.707656999998726","13.423430999995908","42.707656999998726","3.76137000000407","10","","4750.001953125","0","0","0"
"aten::_foreach_div_","42.8083530000085","2.4671940000040924","42.8083530000085","1.8572590000315103","10","","0","0","0","0"
"aten::_foreach_addcdiv_","80.50268699998595","4.598511999998009","80.50268699998595","2.3761399999782444","10","","0","0","0","0"
"Optimizer.step#AdamW.step","422.3017939999984","0","422.3017939999984","0","10","","0","0","0","0"
"cudaDeviceSynchronize","0","1766.8455360000012","0","1766.8455360000012","12","","0","0","0","0"
"cudaHostAlloc","0","2.3004869999997317","0","2.2820349999992176","19","","-71","-71","0","0"
"Memcpy DtoH (Device -> Pinned)","0.02505499999690801","0","0.02505499999690801","0","13","","0","0","0","0"
"aten::random_","0","0.020403999999165534","0","0.020403999999165534","1","","0","0","0","0"
"aten::set_","0","1.3020040000062436","0","1.3020040000062436","296","","0","0","0","0"
"Memcpy DtoH (Device -> Pageable)","88.25666200000606","0","88.25666200000606","0","148","","0","0","0","0"
"aten::native_dropout","15.188067000010982","103.2261669999808","15.188067000010982","2.8239010000005362","100","","3000.474609375","0","0","0"
"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)","15.188067000010982","0","15.188067000010982","0","100","","0","0","0","0"
"aten::scalar_tensor","0","0.38570300000719726","0","0.38570300000719726","96","","0","0","0.000732421875","0.000732421875"
"autograd::engine::evaluate_function: NativeDropoutBackward0","11.983324000004679","4.689206000033766","0","0.7953210000172257","100","","1703.525390625","-696.474609375","0","0"
"NativeDropoutBackward0","11.983324000004679","3.89388500001654","0","0.3616940000317991","100","","2400","0","0","0"
"aten::native_dropout_backward","11.983324000004679","3.532190999984741","11.983324000004679","1.412564999975264","100","","2400","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)","11.983324000004679","0","11.983324000004679","0","100","","0","0","0","0"
"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)","378.7024420000054","0","378.7024420000054","0","48","","0","0","0","0"