"Name","Device Time Total (ms)","CPU Time Total (ms)","Self Device Time Total (ms)","Self CPU Time Total (ms)","Calls","Input Shapes","Device Memory Usage (MB)","Self Device Memory Usage (MB)","CPU Memory Usage (MB)","Self CPU Memory Usage (MB)"
"ProfilerStep*","9699.833209999855","23368.143860000004","0","7809.007247999692","10","","0","-370777.78515625","0.000003814697265625","-0.002330780029296875"
"enumerate(DataLoader)#_MultiProcessingDataLoaderIter.__next__","0","11.035258999999856","0","10.599973999999706","21","","0","0","0","0"
"aten::to","442.4838779999366","133.50691100010096","0","8.95735400009781","11160","","14251.142578125","0","0.00026702880859375","0"
"aten::_to_copy","442.4838779999366","124.54955700000313","0","21.992624000094978","3090","","14251.142578125","0","0.00026702880859375","0"
"aten::empty_strided","0","46.246930999891255","0","39.621032999926754","3550","","21001.1474609375","21001.1474609375","0.00026702880859375","0.00026702880859375"
"cudaEventQuery","0","15.944191999822166","0","15.944191999822166","7740","","0","0","0","0"
"aten::copy_","3046.1640619998802","10843.953461000066","3046.1640619998802","249.1492560001486","9201","","0","0","0","0"
"cudaMemcpyAsync","0","1304.6462889999527","0","1304.6027869999525","6034","","0","0","0","0"
"ProfilerStep*","25377.997765000004","0","25377.997765000004","0","20","","0","0","0","0"
"Memcpy HtoD (Pinned -> Device)","412.49146500002564","0","412.49146500002564","0","1520","","0","0","0","0"
"cudaStreamSynchronize","0","12299.138542999926","0","12298.475280999906","1634","","0","0","0","0"
"cudaDeviceSynchronize","0","20.370509000094554","0","20.370509000094554","1517","","0","0","0","0"
"cudaEventRecord","0","16.695863999897128","0","16.695863999897128","8070","","0","0","0","0"
"cudaStreamWaitEvent","0","11.210620999917595","0","11.210620999917595","6050","","0","0","0","0"
"aten::view","0","40.865296999903435","0","40.86172299990341","13440","","0","0","0","0"
"aten::_has_compatible_shallow_copy_type","0","1.1579540000569328","0","1.1579540000569328","5920","","0","0","0","0"
"PostBackwardFunctionModule","0","73.87864100000125","0","56.18312299999038","3000","","0","0","0","0"
"aten::detach","0","50.77959099998411","0","21.199822999979272","9599","","0","0","0","0"
"detach","0","29.57637700000478","0","29.57331900000482","9599","","0","0","0","0"
"aten::arange","0.10777399998642613","4.497557999994748","0.053886999993213065","0.7958959999858398","60","","1.5625","0","0","0"
"aten::empty","0","54.09939499991319","0","49.2201199999754","5592","","105352.9697265625","105352.9697265625","0.0020904541015625","0.0020904541015625"
"aten::resize_","0","1.0696750000149695","0","1.057912000007862","120","","540.7958984375","540.7958984375","0","0"
"cudaLaunchKernel","0","302.8112670000249","0","302.8112670000249","18320","","0","0","0","0"
"void (anonymous namespace)::elementwise_kernel_with_index<int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}, function_traits<at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>::result_type*)","0.053886999993213065","0","0.053886999993213065","0","30","","0","0","0","0"
"aten::unsqueeze","0","0.2880010000043658","0","0.2256249999966549","30","","0","0","0","0"
"aten::as_strided","0","23.065718999959987","0","23.065718999959987","20290","","0","0","0","0"
"cudaPointerGetAttributes","0","0.3500019999949491","0","0.3347459999949615","56","","168.03125","168","0","0"
"aten::embedding","3.5614659999931217","4.194723000004948","0","0.7516589999967591","40","","540","0","0","0"
"aten::reshape","0","10.28683700006815","0","3.7369180000206716","1540","","0","0","0","0"
"aten::index_select","3.5614659999931217","3.2035930000002364","3.5614659999931217","1.3318820000090172","40","","540","0","0","0"
"void at::native::(anonymous namespace)::indexSelectLargeIndex<float, long, unsigned int, 2, 2, -2, true>(at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<long const, unsigned int>, int, int, unsigned int, unsigned int, long)","3.5614659999931217","0","3.5614659999931217","0","40","","0","0","0","0"
"PreBackwardFunctionForModule","0","111.80343499999194","0","88.82769599998358","4960","","0","0","0","0"
"aten::add","667.0717799999654","37.815596000010444","667.0717799999654","24.31577200004936","1020","","59552.3828125","59552.3828125","0.00003814697265625","0"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})","1.838783000002635","0","1.838783000002635","0","20","","0","0","0","0"
"aten::dropout","33.79003800002672","114.52411599999208","0","1.184163000010958","500","","6750","0","0","0"
"aten::layer_norm","58.19281000000966","47.26880999998383","0","2.5703999999726084","500","","12015.6875","-15.5625","0","0"
"aten::native_layer_norm","58.19281000000966","44.69246700001125","58.19281000000966","17.51767000005498","500","","12031.25","0","0","0"
"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)","58.19281000000966","0","58.19281000000966","0","500","","0","0","0","0"
"aten::addmm","2286.488665999987","82.1308290000323","2286.488665999987","52.53042800000249","960","","51840","51768","0","0"
"cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags","0","2.838739999997115","0","2.838739999997115","1240","","0","0","0","0"
"cudaFuncSetAttribute","0","470.67010800003925","0","470.67010800003925","740","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_256x128_8x4_nn_align1>(cutlass_80_simt_sgemm_256x128_8x4_nn_align1::Params)","1845.3785369999753","0","1845.3785369999753","0","490","","0","0","0","0"
"aten::split","0","27.88627699992963","0","9.769491999957173","1730","","0","0","0","0"
"aten::narrow","0","92.74077399997697","0","31.07339599996493","9610","","0","0","0","0"
"aten::slice","0","85.71179800004226","0","70.61789400018414","14130","","0","0","0","0"
"aten::permute","0","6.19933399999448","0","5.215158000030036","1080","","0","0","0","0"
"aten::scaled_dot_product_attention","586.5451139999897","31.422950000006097","0","4.938830000005071","240","","5805","0","0.0018310546875","-0.0018310546875"
"aten::_scaled_dot_product_efficient_attention","586.5451139999897","26.484120000001028","0","4.483490999988784","240","","5805","0","0.003662109375","0"
"aten::transpose","0","17.01391500006663","0","11.963463999938952","3420","","0","0","0","0"
"aten::_efficient_attention_forward","586.5451139999897","18.465668000000317","586.5451139999897","7.022106999985226","240","","5805","0","0.003662109375","0.00000762939453125"
"cudaStreamIsCapturing","0","1.562672999913324","0","1.562672999913324","1139","","0","0","0","0"
"cudaMemsetAsync","0","18.01567500000447","0","18.01567500000447","2180","","0","0","0","0"
"cudaOccupancyMaxActiveBlocksPerMultiprocessor","0","1.5785619999531608","0","1.5785619999531608","720","","0","0","0","0"
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)","586.5451139999897","0","586.5451139999897","0","240","","0","0","0","0"
"aten::mul","1813.9557229999625","61.742575000077736","1813.9557229999625","35.69277500020609","1980","","175680.01953125","175584.01953125","0.0000762939453125","0"
"aten::pow","315.6642860000705","122.85971600013876","315.6642860000705","79.32481100000527","4810","","34562.1728515625","34562.1728515625","0","0"
"aten::result_type","0","2.1200460000152996","0","2.1200460000152996","4810","","0","0","0","0"
"aten::tanh","207.00923900001428","5.6834379999989455","207.00923900001428","3.740020000013812","240","","23040","22944","0","0"
"Memset (Device)","2.436958999946344","0","2.436958999946344","0","2180","","0","0","0","0"
"ampere_sgemm_128x64_nn","205.3540750000062","0","205.3540750000062","0","240","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)","817.3060339999686","0","817.3060339999686","0","1220","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)","1015.0813549999891","0","1015.0813549999891","0","1220","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#2}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#2}, at::detail::Array<char*, 2>)","206.90987799999354","0","206.90987799999354","0","240","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::tanh_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::tanh_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)","207.00923900001428","0","207.00923900001428","0","240","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<float>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<float>, at::detail::Array<char*, 2>)","206.5969949999998","0","206.5969949999998","0","240","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)","798.8351019999736","0","798.8351019999736","0","720","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_128x64_8x5_nn_align1>(cutlass_80_simt_sgemm_128x64_8x5_nn_align1::Params)","792.8383899999976","0","792.8383899999976","0","240","","0","0","0","0"
"aten::linear","1633.7104510000054","2.557573000005679","0","0.13129599999909988","20","","31410.625","0","0","0"
"aten::t","0","11.04004400001136","0","4.4232919999790905","1020","","0","0","0","0"
"aten::matmul","1633.7104510000054","2.1370520000049438","0","0.2676410000153119","20","","31410.625","0","0","0"
"aten::mm","5006.664257000039","59.13981599996988","5006.664257000039","34.59841200003539","1000","","56570.498046875","56570.498046875","0","0"
"aten::_unsafe_view","0","0.09062599999386294","0","0.09062599999386294","20","","0","0","0","0"
"aten::contiguous","290.2140719999816","7.642380000006626","0","0.4162379999783298","160","","31426.201171875","0","0","0"
"aten::clone","290.2140719999816","7.226142000028296","0","0.9438540000279754","160","","31426.201171875","0","0","0"
"aten::empty_like","0","17.996247000018194","0","4.025593000075183","865","","43577.4560546875","0","0","0"
"aten::cross_entropy_loss","290.5349059999986","2.3992759999986157","0","0.21658199999906355","20","","15689.990234375","-15689.9755859375","0","0"
"aten::log_softmax","283.91712200000313","1.179802999997235","0","0.13957999998287415","20","","31379.951171875","0","0","0"
"aten::_log_softmax","283.91712200000313","1.0329810000027937","283.91712200000313","0.544811000008398","20","","31379.951171875","31379.951171875","0","0"
"aten::nll_loss_nd","6.6177839999955035","1.002891000002317","0","0.08962500000197907","20","","0.0146484375","0","0","0"
"aten::nll_loss","6.6177839999955035","0.913266000000338","0","0.09708699999873352","20","","0.0146484375","-0.0048828125","0","0"
"aten::nll_loss_forward","6.6177839999955035","0.8161790000016045","6.6177839999955035","0.5525360000035143","20","","0.01953125","0.01953125","0","0"
"aten::mean","0.05891199999972014","0.7896029999960156","0.05891199999972014","0.5681339999980409","10","","0.0048828125","0.0048828125","0","0"
"aten::ones_like","0.020223000003781636","0.44314700000337326","0","0.0528199999982462","10","","0.0048828125","0","0","0"
"aten::fill_","200.77746899999968","3.403171999996281","200.77746899999968","1.5524410000087518","180","","0","0","0","0"
"autograd::engine::evaluate_function: MulBackward0","759.4654179999662","28.50630899995609","0","6.255510999976628","490","","-11519.9951171875","-69120","-0.0028228759765625","-0.0028228759765625"
"MulBackward0","604.3542319999748","20.63848499999332","0","2.57569599998121","490","","57600.0048828125","0","0","0"
"autograd::engine::evaluate_function: PreBackwardFunctionForModuleBackward","0","179.91622099994933","0","15.369886999978116","1510","","0","0","0","0"
"PreBackwardFunctionForModuleBackward","0","164.5463339999712","0","158.41154700001658","1510","","0","0","0","0"
"autograd::engine::evaluate_function: NllLossBackward0","65.25903100000741","1.498610999997967","0","0.2309629999950994","10","","15689.3408203125","-0.634765625","0","0"
"NllLossBackward0","65.25903100000741","1.2676480000028678","0","0.3293480000013369","10","","15689.9755859375","0","0","0"
"aten::nll_loss_backward","65.25903100000741","0.9383000000015309","1.9478060000016122","0.317588999995598","10","","15689.9755859375","15689.9755859375","0","0"
"aten::zero_","200.75724599999592","4.067657000000342","0","0.890647000008903","170","","0","0","0","0"
"autograd::engine::evaluate_function: LogSoftmaxBackward0","236.79349900000204","0.8318360000009125","0","0.12654999999693245","10","","-15689.9755859375","-31379.951171875","0","0"
"LogSoftmaxBackward0","236.79349900000204","0.70528600000398","0","0.0851890000115818","10","","15689.9755859375","0","0","0"
"aten::_log_softmax_backward_data","236.79349900000204","0.6200969999923982","236.79349900000204","0.2334639999968058","10","","15689.9755859375","15689.9755859375","0","0"
"autograd::engine::evaluate_function: ViewBackward0","0","27.503720999978192","0","10.983566999991046","1470","","0","0","0","0"
"ViewBackward0","0","16.520153999987144","0","6.6454799999114185","1470","","0","0","0","0"
"autograd::engine::evaluate_function: CloneBackward0","0","0.08154599999646597","0","0.0724119999971299","10","","0","0","0","0"
"CloneBackward0","0","0.009133999999336083","0","0.009133999999336083","10","","0","0","0","0"
"autograd::engine::evaluate_function: SliceBackward0","407.91269999999383","3.3908509999968666","0","0.23153500000129862","20","","15.3369140625","-31379.951171875","0","0"
"SliceBackward0","407.91269999999383","3.159315999995568","0","0.11088000000106694","20","","31395.2880859375","0","0","0"
"aten::slice_backward","407.91269999999383","3.048435999994501","0","0.9945120000017632","20","","31395.2880859375","0","0","0"
"aten::zeros","131.8248109999892","2.0510049999940385","0","0.26223700000914685","40","","32898.423828125","0","0","0"
"autograd::engine::evaluate_function: UnsafeViewBackward0","0","0.2352779999986087","0","0.08718999999960943","10","","0","0","0","0"
"UnsafeViewBackward0","0","0.1480879999989993","0","0.06048400000318361","10","","0","0","0","0"
"autograd::engine::evaluate_function: MmBackward0","960.4503049999882","2.2524230000029637","0","0.2018689999982307","10","","-14232.939453125","-15945.3125","0","0"
"MmBackward0","960.4503049999882","2.050554000004733","0","0.24343200000173237","10","","1712.373046875","0","0","0"
"autograd::engine::evaluate_function: TBackward0","0","0.205229999999312","0","0.08851499999318913","10","","0","0","0","0"
"TBackward0","0","0.11671500000612287","0","0.024731000003943335","10","","0","0","0","0"
"autograd::engine::evaluate_function: PostBackwardFunctionModuleBackward","50.85641999999364","190.4465289999754","0","20.650863999919473","1470","","-5760","-5760","0","0"
"PostBackwardFunctionModuleBackward","0","161.92320400005187","0","155.25208200012023","1470","","0","0","0","0"
"autograd::engine::evaluate_function: NativeLayerNormBackward0","130.81517099997785","29.64680499999867","0","5.086032999986885","250","","-6014.16015625","-12015.625","0","0"
"NativeLayerNormBackward0","130.81517099997785","24.560772000011784","0","2.5751490000284685","250","","6001.46484375","0","0","0"
"aten::native_layer_norm_backward","130.81517099997785","21.985622999983317","130.81517099997785","5.845295000007493","250","","6001.46484375","0","0","0"
"autograd::engine::evaluate_function: torch::autograd::AccumulateGrad","55.14109700002032","400.16419600002837","0","283.7176260001634","1480","","-4794.501953125","-4794.501953125","0","0"
"torch::autograd::AccumulateGrad","0","15.624757000053185","0","6.02562700008975","1480","","0","0","0","0"
"aten::view_as","0","9.119522999952576","0","3.941957999990758","1480","","0","0","0","0"
"aten::record_stream","0","20.900621999847907","0","20.900621999847907","4440","","0","0","0","0"
"autograd::engine::evaluate_function: AddBackward0","0.33491099999507423","4.951838000018644","0","3.7814950000415704","490","","36.75","0","0","0"
"AddBackward0","0","0.7130899999792891","0","0.7130899999792891","490","","0","0","0","0"
"autograd::engine::evaluate_function: AddmmBackward0","2523.9997400000234","114.18895400000667","0","13.019069000010335","480","","-19173.3359375","-42624","0","0"
"AddmmBackward0","2412.503501000044","73.57647999996198","0","7.21886499998557","480","","23447.5","0","0","0"
"aten::sum","124.44211599997011","31.011508000062808","124.44211599997011","20.583613000107537","610","","84.9140625","84.9140625","0","0"
"autograd::engine::evaluate_function: TanhBackward0","155.6592810000068","5.474399999975882","0","1.0882139999740903","120","","-11520","-23040","0","0"
"TanhBackward0","155.6592810000068","4.386186000001792","0","0.868919999977792","120","","11520","0","0","0"
"aten::tanh_backward","155.6592810000068","3.5172660000239993","155.6592810000068","2.106728000028583","120","","11520","11520","0","0"
"autograd::engine::evaluate_function: PowBackward0","516.2797080000278","15.880335000013423","0","2.2635600000117266","120","","-23040","-34560","0","0"
"PowBackward0","363.5599040000145","11.418771000003646","0","1.3497679999641696","120","","11520","-23040","0","0"
"aten::add_","360.3940389999903","31.098303000144167","360.3940389999903","16.91036100013988","1950","","0","0","0","0"
"autograd::engine::evaluate_function: TransposeBackward0","0","2.1605619999821792","0","0.7513719999679451","120","","0","0","0","0"
"TransposeBackward0","0","1.4091900000142341","0","0.27392200002851314","120","","0","0","0","0"
"autograd::engine::evaluate_function: ScaledDotProductEfficientAttentionBackward0","953.3721809999852","510.83704500000636","0","2.822215000013224","120","","2835","-5805","-0.0018310546875","-0.0018310546875"
"ScaledDotProductEfficientAttentionBackward0","953.3721809999852","508.0148299999931","0","1.4552359999991458","120","","8640","0","0","0"
"aten::_scaled_dot_product_efficient_attention_backward","953.3721809999852","506.559593999994","0","3.214696999959895","120","","8640","0","0","0"
"aten::_efficient_attention_backward","953.3721809999852","499.6281230000065","903.8985030000027","5.96092699997146","120","","8640","-5852.8125","0","0"
"cudaFuncGetAttributes","0","0.6349879999975528","0","0.6349879999975528","120","","0","0","0","0"
"autograd::engine::evaluate_function: PermuteBackward0","0","5.23957299999606","0","2.2573090000223166","360","","0","0","0","0"
"PermuteBackward0","0","2.982263999973744","0","0.9795089999892661","360","","0","0","0","0"
"autograd::engine::evaluate_function: SplitBackward0","73.71725200000475","7.132066000000268","0","1.2223579999880168","120","","0","-8640","0","0"
"SplitBackward0","73.71725200000475","5.909708000012252","0","0.6777730000085576","120","","8640","0","0","0"
"aten::cat","116.83035800000572","6.969156000001502","116.83035800000572","4.320091000001965","140","","13387.001953125","13387.001953125","0.00003814697265625","0.00003814697265625"
"autograd::engine::evaluate_function: EmbeddingBackward0","29.58450999999186","6.982106999995711","0","0.45157699998904716","20","","-246.828125","-3222.3369140625","0","0"
"EmbeddingBackward0","10.335539999993518","6.234643000003475","0","0.11806200000279932","20","","1503.1357421875","0","0","0"
"aten::embedding_backward","10.335539999993518","6.116581000000675","0","0.10052199999528239","20","","1503.1357421875","0","0","0"
"aten::embedding_dense_backward","10.335539999993518","6.016059000005392","4.7637380000071134","1.6662689999599825","20","","1503.1357421875","-268.4423828125","0","0"
"cudaDeviceGetAttribute","0","0.03783999999659136","0","0.03783999999659136","50","","0","0","0","0"
"cudaPeekAtLastError","0","0.028288000012806153","0","0.028288000012806153","170","","0","0","0","0"
"aten::div_","40.91883299999835","0.30356599999713946","40.91883299999835","0.19913099998945835","10","","0","0","0","0"
"aten::chunk","0","0.22224199999976554","0","0.04353799999991315","10","","0","0","0","0"
"c10d::_reduce_scatter_base_","0","1.276107999999018","0","0.4177279999890889","10","","0","0","0","0"
"record_param_comms","0","1.906026000006561","0","1.6683320000227249","40","","0","0","0","0"
"nccl:_reduce_scatter_base","0","0.497999000005424","0","0","10","","0","0","0","0"
"aten::linalg_vector_norm","26.374157999941612","70.76923899996493","26.374157999941612","48.22655199991443","1490","","0.72265625","0.72265625","0.00003814697265625","0.00003814697265625"
"ampere_sgemm_128x128_tn","1633.7104510000054","0","1633.7104510000054","0","20","","0","0","0","0"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})","432.87951499998206","0","432.87951499998206","0","150","","0","0","0","0"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1} const&)::{lambda(int)#1})","0.12457699999772012","0","0.12457699999772012","0","20","","0","0","0","0"
"void at::native::(anonymous namespace)::cunn_SoftMaxForward<4, float, float, float, at::native::(anonymous namespace)::LogSoftMaxForwardEpilogue>(float*, float const*, int)","283.91712200000313","0","283.91712200000313","0","20","","0","0","0","0"
"void at::native::(anonymous namespace)::nll_loss_forward_reduce_cuda_kernel_2d<float, float, long>(float*, float*, float const*, long const*, float const*, bool, long, long, long, long)","6.6177839999955035","0","6.6177839999955035","0","20","","0","0","0","0"
"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4>)","0.05891199999972014","0","0.05891199999972014","0","10","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)","195.15625899999878","0","195.15625899999878","0","60","","0","0","0","0"
"void at::native::(anonymous namespace)::nll_loss_backward_reduce_cuda_kernel_2d<float, long>(float*, float const*, long const*, float const*, float const*, bool, int, int, long, long)","1.9478060000016122","0","1.9478060000016122","0","10","","0","0","0","0"
"void at::native::(anonymous namespace)::cunn_SoftMaxBackward<4, float, float, float, at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue>(float*, float const*, float const*, long)","236.79349900000204","0","236.79349900000204","0","10","","0","0","0","0"
"Memcpy DtoD (Device -> Device)","194.10987300002202","0","194.10987300002202","0","1490","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_128x256_8x4_nt_align1>(cutlass_80_simt_sgemm_128x256_8x4_nt_align1::Params)","745.4396399999994","0","745.4396399999994","0","130","","0","0","0","0"
"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)","56.47567399999022","0","56.47567399999022","0","250","","0","0","0","0"
"void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)","74.33949699998763","0","74.33949699998763","0","250","","0","0","0","0"
"ampere_sgemm_128x64_tn","1307.825633000062","0","1307.825633000062","0","480","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_128x64_8x5_nt_align1>(cutlass_80_simt_sgemm_128x64_8x5_nt_align1::Params)","761.1048579999822","0","761.1048579999822","0","360","","0","0","0","0"
"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)","111.22609299998847","0","111.22609299998847","0","490","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::tanh_backward_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::tanh_backward_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)","155.6592810000068","0","155.6592810000068","0","120","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#1}, at::detail::Array<char*, 2>)","103.26760000000253","0","103.26760000000253","0","120","","0","0","0","0"
"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)","12.61096599999559","0","12.61096599999559","0","120","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<unsigned char>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<unsigned char>, at::detail::Array<char*, 1>)","5.621210000000894","0","5.621210000000894","0","120","","0","0","0","0"
"fmha_cutlassB_f32_aligned_64x64_k64_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, false, false, 64, 64, 64, false>::Params)","81.36038399999997","0","81.36038399999997","0","12","","0","0","0","0"
"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 3, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)","73.71725200000475","0","73.71725200000475","0","120","","0","0","0","0"
"void at::native::(anonymous namespace)::embedding_backward_feature_kernel<float, float, long>(long const*, float const*, float*, int, long, int)","0.39132799999963025","0","0.39132799999963025","0","10","","0","0","0","0"
"void at_cuda_detail::cub::DeviceRadixSortHistogramKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy800, false, long, unsigned long long>(unsigned long long*, long const*, unsigned long long, int, int)","0.08204800000367686","0","0.08204800000367686","0","10","","0","0","0","0"
"void at_cuda_detail::cub::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy800, unsigned long long>(unsigned long long*)","0.023743000004556963","0","0.023743000004556963","0","10","","0","0","0","0"
"void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy800, false, long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long, int, int>(int*, int*, unsigned long long*, unsigned long long const*, long*, long const*, at::cuda::cub::detail::OpaqueType<8>*, at::cuda::cub::detail::OpaqueType<8> const*, int, int, int)","0.9384019999924349","0","0.9384019999924349","0","80","","0","0","0","0"
"void at_cuda_detail::cub::DeviceCompactInitKernel<at_cuda_detail::cub::ScanTileState<int, true>, long*>(at_cuda_detail::cub::ScanTileState<int, true>, int, long*)","0.041631999995093795","0","0.041631999995093795","0","10","","0","0","0","0"
"void at_cuda_detail::cub::DeviceUniqueByKeySweepKernel<at_cuda_detail::cub::DeviceUniqueByKeyPolicy<long const*>::Policy520, long const*, thrust::counting_iterator<int, thrust::use_default, thrust::use_default, thrust::use_default>, long*, long*, long*, at_cuda_detail::cub::ScanTileState<int, true>, at_cuda_detail::cub::Equality, int>(long const*, thrust::counting_iterator<int, thrust::use_default, thrust::use_default, thrust::use_default>, long*, long*, long*, at_cuda_detail::cub::ScanTileState<int, true>, at_cuda_detail::cub::Equality, int, int)","0.0663040000012843","0","0.0663040000012843","0","10","","0","0","0","0"
"void at::native::(anonymous namespace)::krn_partials_per_segment<long>(long*, long const*, long const*, long)","0.025760000005713664","0","0.025760000005713664","0","10","","0","0","0","0"
"void at_cuda_detail::cub::DeviceScanInitKernel<at_cuda_detail::cub::ScanTileState<long, true> >(at_cuda_detail::cub::ScanTileState<long, true>, int)","0.016800000001210718","0","0.016800000001210718","0","10","","0","0","0","0"
"void at_cuda_detail::cub::DeviceScanKernel<at_cuda_detail::cub::DeviceScanPolicy<long>::Policy600, long const*, long*, at_cuda_detail::cub::ScanTileState<long, true>, at::cuda::cub::(anonymous namespace)::SumOp<long>, at_cuda_detail::cub::detail::InputValue<long, long*>, int, long>(long const*, long*, at_cuda_detail::cub::ScanTileState<long, true>, int, at::cuda::cub::(anonymous namespace)::SumOp<long>, at_cuda_detail::cub::detail::InputValue<long, long*>, int)","0.046879999999539","0","0.046879999999539","0","10","","0","0","0","0"
"void at::native::(anonymous namespace)::compute_num_of_partial_segments<long>(long const*, long const*, long const*, long*)","0.021856999998912215","0","0.021856999998912215","0","10","","0","0","0","0"
"void at::native::(anonymous namespace)::krn_partial_segment_offset<long>(long*, long const*, long const*, long const*, long const*)","0.047135000002221206","0","0.047135000002221206","0","10","","0","0","0","0"
"void at::native::(anonymous namespace)::compute_grad_weight<float, long>(long const*, float const*, long const*, long, long, long const*, long const*, at::AccumulateType<float, true>::type*, long)","2.008317000003648","0","2.008317000003648","0","10","","0","0","0","0"
"void at::native::(anonymous namespace)::sum_and_scatter<float, long>(long const*, float*, long, long const*, long const*, at::AccumulateType<float, true>::type const*, long const*, long const*, long, long)","0.9026850000029663","0","0.9026850000029663","0","10","","0","0","0","0"
"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)","43.11310600000096","0","43.11310600000096","0","20","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)","40.91883299999835","0","40.91883299999835","0","10","","0","0","0","0"
"Memcpy DtoH (Device -> Pinned)","759.7763179999429","0","759.7763179999429","0","2983","","0","0","0","0"
"void at::native::unrolled_elementwise_kernel<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#6}::operator()() const::{lambda(double)#1}, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithCast<1>, at::native::memory::StoreWithCast<1> >(int, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#6}::operator()() const::{lambda(double)#1}, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithCast<1>, at::native::memory::StoreWithCast<1>)","29.968734999911625","0","29.968734999911625","0","1480","","0","0","0","0"
"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<double, at::native::NormTwoOps<double, double, double>, unsigned int, double, 4> >(at::native::ReduceOp<double, at::native::NormTwoOps<double, double, double>, unsigned int, double, 4>)","26.19444199997396","0","26.19444199997396","0","1480","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<double, double>(at::TensorIteratorBase&, double)::{lambda(double)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<double, double>(at::TensorIteratorBase&, double)::{lambda(double)#1}, at::detail::Array<char*, 2>)","3.3701870000129563","0","3.3701870000129563","0","2960","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::sqrt_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#1}::operator()() const::{lambda(double)#1}, at::detail::Array<char*, 2> >(int, at::native::sqrt_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#1}::operator()() const::{lambda(double)#1}, at::detail::Array<char*, 2>)","2.1039500000607223","0","2.1039500000607223","0","1480","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<double>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<double>, at::detail::Array<char*, 2>)","0.017377999992808327","0","0.017377999992808327","0","10","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<double>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<double>, at::detail::Array<char*, 3>)","1.706628999992041","0","1.706628999992041","0","1470","","0","0","0","0"
"aten::item","0.04246300000580959","3035.0222949999998","0","0.17907600000174717","24","","0","0","0","0"
"aten::_local_scalar_dense","0.04246300000580959","3034.8432189999976","0.04246300000580959","0.8198809999935329","24","","0","0","0","0"
"Memcpy HtoD (Pageable -> Device)","1049.7869180000055","0","1049.7869180000055","0","30","","0","0","0","0"
"aten::lift_fresh","0","0.009062000001315027","0","0.009062000001315027","20","","0","0","0","0"
"aten::detach_","0","0.09999199999962002","0","0.06320100000337697","20","","0","0","0","0"
"detach_","0","0.036790999996243044","0","0.036790999996243044","20","","0","0","0","0"
"c10d::allreduce_","0","1.425791000001831","0","0.4835689999985043","10","","0","0","0","0"
"nccl:all_reduce","0","0.551010000000475","0","0","10","","0","0","0","0"
"aten::select","0","0.20980200000153854","0","0.18826799999852664","10","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::sqrt_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::sqrt_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)","0.0126710000007879","0","0.0126710000007879","0","10","","0","0","0","0"
"aten::isinf","0.02451100000576116","0.9208059999991673","0","0.08187000000476838","10","","0.0048828125","-0.0048828125","0","0"
"aten::abs","0.02579200001200661","0.8962250000052154","0.012896000006003305","0.3021310000005178","30","","0.009765625","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::AbsFunctor<float>, at::detail::Array<char*, 2> >(int, at::native::AbsFunctor<float>, at::detail::Array<char*, 2>)","0.012896000006003305","0","0.012896000006003305","0","10","","0","0","0","0"
"aten::eq","0.011614999999757855","0.34714899999299087","0.011614999999757855","0.23537399999517947","10","","0.0048828125","0.0048828125","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, bool, at::native::(anonymous namespace)::CompareEqFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<float, float, bool, at::native::(anonymous namespace)::CompareEqFunctor<float> >, at::detail::Array<char*, 2>)","0.011614999999757855","0","0.011614999999757855","0","10","","0","0","0","0"
"aten::isnan","0.011742999994428828","0.26634699999564326","0","0.04715900000068359","10","","0.0048828125","0","0","0"
"aten::ne","0.011742999994428828","0.2191879999949597","0.011742999994428828","0.14166399999335408","10","","0.0048828125","0.0048828125","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, bool, at::native::(anonymous namespace)::CompareEqFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, bool, at::native::(anonymous namespace)::CompareEqFunctor<float> >, at::detail::Array<char*, 3>)","0.011742999994428828","0","0.011742999994428828","0","10","","0","0","0","0"
"aten::logical_or","0.02713400000613183","0.6981210000065621","0.013567000003065915","0.2187920000089798","20","","0.009765625","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<bool, bool, bool, at::native::logical_or_kernel_cuda(at::TensorIterator&)::{lambda()#2}::operator()() const::{lambda()#9}::operator()() const::{lambda(bool, bool)#1}>, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<bool, bool, bool, at::native::logical_or_kernel_cuda(at::TensorIterator&)::{lambda()#2}::operator()() const::{lambda()#9}::operator()() const::{lambda(bool, bool)#1}>, at::detail::Array<char*, 3>)","0.013567000003065915","0","0.013567000003065915","0","10","","0","0","0","0"
"void at::native::unrolled_elementwise_kernel<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithCast<2>, at::native::memory::StoreWithCast<1> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>, TrivialOffsetCalculator<2, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithCast<2>, at::native::memory::StoreWithCast<1>)","0.03926599999982864","0","0.03926599999982864","0","20","","0","0","0","0"
"aten::logical_not","0.02406599999545142","0.693922000002116","0.01203299999772571","0.18505299999704586","20","","0.009765625","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::logical_not_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(bool)#1}, at::detail::Array<char*, 2> >(int, at::native::logical_not_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(bool)#1}, at::detail::Array<char*, 2>)","0.01203299999772571","0","0.01203299999772571","0","10","","0","0","0","0"
"Memcpy DtoH (Device -> Pageable)","167.18733199999923","0","167.18733199999923","0","11","","0","0","0","0"
"aten::stack","0","0.28382899999455546","0","0.11267899999627844","10","","0","0","0.00003814697265625","0"
"aten::linalg_norm","0","0.21384400000050663","0","0.026502999999327585","10","","0","0","0.00003814697265625","0"
"aten::squeeze","0","0.03789599999948405","0","0.031575999995460735","10","","0","0","0","0"
"aten::div","0","0.43577800000621936","0","0.20020500000566244","30","","0","0","0.00011444091796875","0"
"aten::clamp","0","0.06888899999973364","0","0.0674299999999348","10","","0","0","0.00003814697265625","0.00003814697265625"
"aten::reciprocal","0","0.08193300000252202","0","0.08193300000252202","10","","0","0","0.00003814697265625","0.00003814697265625"
"aten::mul_","0","117.80929999999772","0","117.74619099999289","10","","0","0","0","0"
"Optimizer.step#DeepSpeedCPUAdam.step","0","442.7998879999993","0","442.7360580000004","10","","0","0","0","0"
"aten::unflatten_dense_tensors","0","14.367506999995792","0","4.3109449999351055","10","","0","0","0","0"
"cudaHostAlloc","0","2.4013120000006167","0","2.382259000000544","19","","120.03125","120.03125","0","0"
"aten::random_","0","0.02009000000008382","0","0.02009000000008382","1","","0","0","0","0"
"cudaFree","0","127.89667699999175","0","127.89667699999175","127","","0","0","0","0"
"aten::set_","0","0.03132099999953061","0","0.03132099999953061","2","","0","0","0","0"
"aten::native_dropout","33.79003800002672","113.33995299998112","33.79003800002672","7.263569000026211","225","","6750","0","0","0"
"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)","33.79003800002672","0","33.79003800002672","0","225","","0","0","0","0"
"aten::scalar_tensor","0","0.77713800002262","0","0.77713800002262","216","","0","0","0.00164794921875","0.00164794921875"
"cudaMalloc","0","17.15381300001405","0","17.15381300001405","105","","0","0","0","0"
"autograd::engine::evaluate_function: NativeDropoutBackward0","25.88669400000945","19.20762000002153","0","2.5021570000145585","225","","3834","-1566","0","0"
"NativeDropoutBackward0","25.88669400000945","16.705463000006972","0","1.2291520000062883","225","","5400","0","0","0"
"aten::native_dropout_backward","25.88669400000945","15.476311000000685","25.88669400000945","5.851985999999568","225","","5400","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)","26.001158000007273","0","26.001158000007273","0","225","","0","0","0","0"
"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)","822.5381190000028","0","822.5381190000028","0","108","","0","0","0","0"