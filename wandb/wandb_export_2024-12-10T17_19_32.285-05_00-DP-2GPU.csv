"Name","Device Time Total (ms)","CPU Time Total (ms)","Self Device Time Total (ms)","Self CPU Time Total (ms)","Calls","Input Shapes","Device Memory Usage (MB)","Self Device Memory Usage (MB)","CPU Memory Usage (MB)","Self CPU Memory Usage (MB)"
"ProfilerStep*","5607.553142000016","20090.089912","0","5669.779443999998","15","","-195359.3720703125","-261505.42529296875","0","-0.00000762939453125"
"void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)","1390.9365689998865","0","1390.9365689998865","0","3400","","0","0","0","0"
"enumerate(DataLoader)#_MultiProcessingDataLoaderIter.__next__","0","11.60000699999751","0","10.823126999997388","26","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#2}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#2}, at::detail::Array<char*, 2>)","263.58074700002777","0","263.58074700002777","0","616","","0","0","0","0"
"aten::to","0.5952050000093877","8320.358512000043","0","1.339981000038446","3460","","64.76171875","60.06689453125","0","0"
"aten::_to_copy","0.5952050000093877","8319.018531000003","0","1.8477229999848641","115","","4.69482421875","0","0","0"
"aten::empty_strided","0","24.36656400002623","0","23.334411000027227","2920","","14335.447265625","14335.447265625","0","0"
"aten::copy_","4016.014821999977","8515.448252000013","4016.014821999977","53.36013299992704","1983","","-6836.830078125","-1783.83984375","0.0000152587890625","0.0000152587890625"
"cudaMemcpyAsync","0","132.57375200001465","0","132.57375200001465","406","","-2021.5185546875","-2021.5185546875","0","0"
"cudaStreamSynchronize","0","11337.439492000005","0","11337.294741","211","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)","1099.0852510000068","0","1099.0852510000068","0","3414","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::tanh_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::tanh_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)","265.66468900000933","0","265.66468900000933","0","616","","0","0","0","0"
"cudaPointerGetAttributes","0","0.4019790000046546","0","0.3654440000038071","66","","-13.4912109375","-13.4912109375","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<float>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<float>, at::detail::Array<char*, 2>)","265.7831220000095","0","265.7831220000095","0","632","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)","1154.2397540000054","0","1154.2397540000054","0","2152","","0","0","0","0"
"Memset (Device)","6.895740999995981","0","6.895740999995981","0","5224","","0","0","0","0"
"ampere_sgemm_128x128_nn","907.341071000015","0","907.341071000015","0","616","","0","0","0","0"
"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)","49.742197999973925","0","49.742197999973925","0","1280","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_128x64_8x5_nn_align1>(cutlass_80_simt_sgemm_128x64_8x5_nn_align1::Params)","685.2232699999894","0","685.2232699999894","0","614","","0","0","0","0"
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)","717.6132979999811","0","717.6132979999811","0","614","","0","0","0","0"
"ampere_sgemm_128x64_nn","242.72672500001912","0","242.72672500001912","0","614","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_256x128_8x4_nn_align1>(cutlass_80_simt_sgemm_256x128_8x4_nn_align1::Params)","1578.3994819999969","0","1578.3994819999969","0","646","","0","0","0","0"
"ampere_sgemm_128x128_tn","1537.0007820000094","0","1537.0007820000094","0","52","","0","0","0","0"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})","1819.3066769999666","0","1819.3066769999666","0","1716","","0","0","0","0"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1} const&)::{lambda(int)#1})","0.3058260000043083","0","0.3058260000043083","0","52","","0","0","0","0"
"void at::native::(anonymous namespace)::cunn_SoftMaxForward<4, float, float, float, at::native::(anonymous namespace)::LogSoftMaxForwardEpilogue>(float*, float const*, int)","369.06856099998805","0","369.06856099998805","0","52","","0","0","0","0"
"void at::native::(anonymous namespace)::nll_loss_forward_reduce_cuda_kernel_2d<float, float, long>(float*, float*, float const*, long const*, float const*, bool, long, long, long, long)","9.365239000005925","0","9.365239000005925","0","52","","0","0","0","0"
"Memcpy DtoD (Device -> Device)","406.6820179999978","0","406.6820179999978","0","84","","0","0","0","0"
"Memcpy PtoP (Device -> Device)","2219.9804410000165","0","2219.9804410000165","0","118","","0","0","0","0"
"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4>)","0.08198600000384614","0","0.08198600000384614","0","26","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)","323.125256000001","0","323.125256000001","0","192","","0","0","0","0"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})","0.026208000001963227","0","0.026208000001963227","0","16","","0","0","0","0"
"void at::native::(anonymous namespace)::nll_loss_backward_reduce_cuda_kernel_2d<float, long>(float*, float const*, long const*, float const*, float const*, bool, int, int, long, long)","2.130238999999361","0","2.130238999999361","0","32","","0","0","0","0"
"void at::native::(anonymous namespace)::cunn_SoftMaxBackward<4, float, float, float, at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue>(float*, float const*, float const*, long)","389.21369700000736","0","389.21369700000736","0","32","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_128x256_8x4_nt_align1>(cutlass_80_simt_sgemm_128x256_8x4_nt_align1::Params)","1200.3092399999946","0","1200.3092399999946","0","800","","0","0","0","0"
"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)","92.76102100004012","0","92.76102100004012","0","800","","0","0","0","0"
"void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)","25.925902000024625","0","25.925902000024625","0","800","","0","0","0","0"
"ampere_sgemm_128x64_tn","2045.430078999977","0","2045.430078999977","0","1536","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_128x64_8x5_nt_align1>(cutlass_80_simt_sgemm_128x64_8x5_nt_align1::Params)","589.6975070000108","0","589.6975070000108","0","384","","0","0","0","0"
"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)","123.05883099997253","0","123.05883099997253","0","1568","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::tanh_backward_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::tanh_backward_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)","245.577806999965","0","245.577806999965","0","384","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#1}, at::detail::Array<char*, 2>)","165.49154499998485","0","165.49154499998485","0","384","","0","0","0","0"
"ampere_sgemm_128x128_nt","624.7063840000014","0","624.7063840000014","0","384","","0","0","0","0"
"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)","17.05848099995777","0","17.05848099995777","0","384","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<unsigned char>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<unsigned char>, at::detail::Array<char*, 1>)","9.15208199999138","0","9.15208199999138","0","384","","0","0","0","0"
"fmha_cutlassB_f32_aligned_64x64_k64_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, false, false, 64, 64, 64, false>::Params)","162.30755499999964","0","162.30755499999964","0","48","","0","0","0","0"
"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 3, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)","101.07692600000127","0","101.07692600000127","0","384","","0","0","0","0"
"void at::native::(anonymous namespace)::embedding_backward_feature_kernel<float, float, long>(long const*, float const*, float*, int, long, int)","1.1631350000043166","0","1.1631350000043166","0","32","","0","0","0","0"
"void (anonymous namespace)::elementwise_kernel_with_index<int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}, function_traits<at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>::result_type*)","0.10459699998714496","0","0.10459699998714496","0","82","","0","0","0","0"
"void at_cuda_detail::cub::DeviceRadixSortHistogramKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy800, false, long, unsigned long long>(unsigned long long*, long const*, unsigned long long, int, int)","0.19804900000139605","0","0.19804900000139605","0","32","","0","0","0","0"
"void at_cuda_detail::cub::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy800, unsigned long long>(unsigned long long*)","0.06787300001387485","0","0.06787300001387485","0","32","","0","0","0","0"
"void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy800, false, long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long, int, int>(int*, int*, unsigned long long*, unsigned long long const*, long*, long const*, at::cuda::cub::detail::OpaqueType<8>*, at::cuda::cub::detail::OpaqueType<8> const*, int, int, int)","2.575488000029698","0","2.575488000029698","0","256","","0","0","0","0"
"void at_cuda_detail::cub::DeviceCompactInitKernel<at_cuda_detail::cub::ScanTileState<int, true>, long*>(at_cuda_detail::cub::ScanTileState<int, true>, int, long*)","0.13859500000427943","0","0.13859500000427943","0","32","","0","0","0","0"
"void at_cuda_detail::cub::DeviceUniqueByKeySweepKernel<at_cuda_detail::cub::DeviceUniqueByKeyPolicy<long const*>::Policy520, long const*, thrust::counting_iterator<int, thrust::use_default, thrust::use_default, thrust::use_default>, long*, long*, long*, at_cuda_detail::cub::ScanTileState<int, true>, at_cuda_detail::cub::Equality, int>(long const*, thrust::counting_iterator<int, thrust::use_default, thrust::use_default, thrust::use_default>, long*, long*, long*, at_cuda_detail::cub::ScanTileState<int, true>, at_cuda_detail::cub::Equality, int, int)","0.20032100001594516","0","0.20032100001594516","0","32","","0","0","0","0"
"void at::native::(anonymous namespace)::krn_partials_per_segment<long>(long*, long const*, long const*, long)","0.07305900000315159","0","0.07305900000315159","0","32","","0","0","0","0"
"void at_cuda_detail::cub::DeviceScanInitKernel<at_cuda_detail::cub::ScanTileState<long, true> >(at_cuda_detail::cub::ScanTileState<long, true>, int)","0.048859000004711564","0","0.048859000004711564","0","32","","0","0","0","0"
"void at_cuda_detail::cub::DeviceScanKernel<at_cuda_detail::cub::DeviceScanPolicy<long>::Policy600, long const*, long*, at_cuda_detail::cub::ScanTileState<long, true>, at::cuda::cub::(anonymous namespace)::SumOp<long>, at_cuda_detail::cub::detail::InputValue<long, long*>, int, long>(long const*, long*, at_cuda_detail::cub::ScanTileState<long, true>, int, at::cuda::cub::(anonymous namespace)::SumOp<long>, at_cuda_detail::cub::detail::InputValue<long, long*>, int)","0.12953499999968335","0","0.12953499999968335","0","32","","0","0","0","0"
"void at::native::(anonymous namespace)::compute_num_of_partial_segments<long>(long const*, long const*, long const*, long*)","0.06374199998669793","0","0.06374199998669793","0","32","","0","0","0","0"
"void at::native::(anonymous namespace)::krn_partial_segment_offset<long>(long*, long const*, long const*, long const*, long const*)","0.10454500000271946","0","0.10454500000271946","0","32","","0","0","0","0"
"void at::native::(anonymous namespace)::compute_grad_weight<float, long>(long const*, float const*, long const*, long, long, long const*, long const*, at::AccumulateType<float, true>::type*, long)","3.227677999999607","0","3.227677999999607","0","32","","0","0","0","0"
"void at::native::(anonymous namespace)::sum_and_scatter<float, long>(long const*, float*, long, long const*, long const*, at::AccumulateType<float, true>::type const*, long const*, long const*, long, long)","1.3064640000036452","0","1.3064640000036452","0","32","","0","0","0","0"
"ncclDevKernel_Reduce_Sum_f32_RING_LL(ncclDevComm*, unsigned long, ncclWork*)","1484.7033910000102","0","1484.7033910000102","0","1216","","0","0","0","0"
"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)","98.24140599999518","0","98.24140599999518","0","1841","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::LpNormFunctor<float, (at::native::NormType)1, float, 1, 1, 0>, float*, int>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::LpNormFunctor<float, (at::native::NormType)1, float, 1, 1, 0>, float*, int)","32.10603800000786","0","32.10603800000786","0","112","","0","0","0","0"
"void at::native::lpnorm_cleanup<float, (at::native::NormType)1, float, float>(float const*, at::native::TensorListAddresses, int)","0.0642259999983944","0","0.0642259999983944","0","16","","0","0","0","0"
"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::NormTwoOps<float, float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::NormTwoOps<float, float, float>, unsigned int, float, 4>)","0.052160999996820466","0","0.052160999996820466","0","16","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::reciprocal_kernel_cuda(at::TensorIteratorBase&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::reciprocal_kernel_cuda(at::TensorIteratorBase&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)","0.022621999997529202","0","0.022621999997529202","0","16","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)","0.024957999999751335","0","0.024957999999751335","0","16","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarTensorFunctor<float, 1, 1, 0>, std::multiplies<float>, float*, float>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarTensorFunctor<float, 1, 1, 0>, std::multiplies<float>, float*, float)","67.87760500000475","0","67.87760500000475","0","112","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::multiplies<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::multiplies<float>, float)","137.62111999999544","0","137.62111999999544","0","224","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::TernaryOpScalarFunctor<float, 2, 2, 0>, at::native::LerpFunctor<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::TernaryOpScalarFunctor<float, 2, 2, 0>, at::native::LerpFunctor<float>, float)","100.86786699999007","0","100.86786699999007","0","112","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<3>, at::native::(anonymous namespace)::PointwiseOpScalarFunctor<float, 3, 3, 0>, std::multiplies<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<3>, at::native::(anonymous namespace)::PointwiseOpScalarFunctor<float, 3, 3, 0>, std::multiplies<float>, float)","100.87298800002202","0","100.87298800002202","0","112","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::UnaryOpFunctor<float, 2, 1, 1>, at::native::Sqrt<float> >(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::UnaryOpFunctor<float, 2, 1, 1>, at::native::Sqrt<float>)","68.13101299998118","0","68.13101299998118","0","112","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 1>, at::native::(anonymous namespace)::BinaryOpScalarListFunctor<float, 1, 1, 0>, std::divides<float> >(at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 1>, at::native::(anonymous namespace)::BinaryOpScalarListFunctor<float, 1, 1, 0>, std::divides<float>)","68.22365500001959","0","68.22365500001959","0","112","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::plus<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::plus<float>, float)","68.40224499998928","0","68.40224499998928","0","112","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 3>, at::native::(anonymous namespace)::PointwiseOpScalarListFunctor<float, 3, 3, 0>, std::divides<float> >(at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 3>, at::native::(anonymous namespace)::PointwiseOpScalarListFunctor<float, 3, 3, 0>, std::divides<float>)","128.62487600000622","0","128.62487600000622","0","112","","0","0","0","0"
"ProfilerStep*","19442.840754999997","0","19442.840754999997","0","15","","0","0","0","0"
"Memcpy HtoD (Pinned -> Device)","0.3970920000007609","0","0.3970920000007609","0","50","","0","0","0","0"
"DataParallel.forward","4775.927030000019","1281.5783210000009","0","685.7762259998708","25","","66090.7734375","-3691.66845703125","0","0"
"Scatter","0.19811300000862683","18.612213999995845","0","5.619651000010083","65","","1.56982421875","0","0","0"
"aten::chunk","0","2.1328319999959784","0","0.3255959999933839","50","","0","0","0","0"
"aten::split","0","1.8072360000025947","0","0.628916000009398","50","","0","0","0","0"
"aten::narrow","0","47.67114399991394","0","15.127339999836638","6620","","0","0","0","0"
"aten::slice","0","33.15525800009025","0","27.346375000013854","6680","","-2363.99609375","-2363.99609375","0","0"
"aten::as_strided","0","19.042407000197446","0","19.042407000197446","18355","","-1132.26513671875","-1132.26513671875","-0.00002288818359375","-0.00002288818359375"
"cudaEventRecord","0","9.548882000112208","0","9.548882000112208","6510","","0","0","0","0"
"cudaStreamWaitEvent","0","13.75960999990627","0","13.75960999990627","6510","","0","0","0","0"
"DataParallel.forward","17344.857944000007","0","17344.857944000007","0","50","","0","0","0","0"
"Broadcast","1235.365621000053","111.25754899999208","1208.6743280000492","37.160982000032554","15","","7274.35546875","-5023.34765625","0","0"
"aten::flatten_dense_tensors","97.15039600000053","99.63213399989147","0","21.960142999925882","1840","","18586.94580078125","-18.0205078125","0","0"
"aten::view","0","44.768074999691805","0","44.76309499969182","23470","","-1182.1533203125","-1182.1533203125","0","0"
"aten::empty","0","72.12112900001952","0","66.00006800001906","6847","","151239.6171875","151221.5966796875","0.000041961669921875","0.000041961669921875"
"cudaStreamGetCaptureInfo_v2","0","2.3593840000079944","0","2.3593840000079944","2540","","0","0","0","0"
"cudaLaunchKernelExC","0","21.326460999946693","0","21.317993999946747","2540","","0","0","0","0"
"ncclDevKernel_Broadcast_RING_LL(ncclDevComm*, unsigned long, ncclWork*)","2067.478993000049","0","2067.478993000049","0","1400","","0","0","0","0"
"aten::unflatten_dense_tensors","0","79.54230600003153","0","23.052057000169764","1270","","0","0","0","0"
"aten::cat","191.97376099999983","79.37824900001567","191.97376099999983","52.18374700011324","2160","","31168.75830078125","30985.56494140625","0.0000152587890625","-0.00000762939453125"
"cudaLaunchKernel","32.00369599998742","506.3822510000296","30.31144099998474","410.33600500004866","29798","","-12403.82763671875","-12403.82763671875","-0.0000152587890625","-0.0000152587890625"
"aten::view_as","0","8.029867999953566","0","4.491036999948323","2220","","0","0","0","0"
"cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags","2.462815999995917","5.838620999977575","2.462815999995917","5.825384999978007","2400","","-908.5078125","-908.5078125","0","0"
"cudaStreamIsCapturing","1.6963190000019968","4.646168000049889","1.6963190000019968","4.646168000049889","3231","","90.75537109375","90.75537109375","-0.00000762939453125","-0.00000762939453125"
"cudaFuncSetAttribute","0.24006399999931455","667.9970190000427","0.24006399999931455","667.9970190000427","1739","","-895.677734375","-895.677734375","0","0"
"cudaMemsetAsync","2.5448640000000595","40.82958000000473","2.5448640000000595","40.64682900001481","4907","","-7063.75439453125","-7063.75439453125","-0.0000457763671875","-0.0000457763671875"
"Gather","3482.7212659999677","114.42920000000612","0","35.11298700004059","650","","53663.29345703125","0","0","0"
"aten::split_with_sizes","0","8.427187999940362","0","6.673107999944128","665","","0","0","0","0"
"void at::native::(anonymous namespace)::CatArrayBatchedCopy_contig<at::native::(anonymous namespace)::OpaqueType<1u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<1u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<1u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)","2.2934040000031235","0","2.2934040000031235","0","50","","0","0","0","0"
"void at::native::(anonymous namespace)::indexSelectLargeIndex<float, long, unsigned int, 2, 2, -2, true>(at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<long const, unsigned int>, int, int, unsigned int, unsigned int, long)","4.068197000004467","0","4.068197000004467","0","100","","0","0","0","0"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})","1.021470999993151","0","1.021470999993151","0","50","","0","0","0","0"
"cudaFree","0","1162.5685629999946","0","1162.5685629999946","228","","0","0","0","0"
"aten::mean","0.0789780000038445","2.518813999994658","0.0789780000038445","1.766997000001953","25","","0.01220703125","0.01220703125","0","0"
"aten::ones_like","0.01622299999720417","0.85529499999783","0","0.1366269999941578","15","","0.00732421875","0","0","0"
"aten::empty_like","0","22.553989000025904","0","6.280566000082879","1705","","14708.111328125","-170.3623046875","-0.00000762939453125","0"
"aten::fill_","311.85601799999245","11.736909999965109","311.85601799999245","4.967769999931799","540","","-3698.8017578125","-1352.423828125","0","-0.0000152587890625"
"autograd::engine::evaluate_function: MeanBackward0","0.024576000001979993","2.0886809999938123","0","0.32870899999618997","15","","0.00732421875","0","0","0"
"MeanBackward0","0.024576000001979993","1.7599719999976224","0","0.28862399999948685","15","","0.00732421875","0","0","0"
"aten::expand","0","0.24539999999885914","0","0.20289099999307655","15","","0","0","0","0"
"aten::div","0.024576000001979993","1.2259479999992764","0.024576000001979993","0.8408079999902984","15","","0.00732421875","0.00732421875","0","0"
"autograd::engine::evaluate_function: GatherBackward","0.023551999998744577","5.992455999998026","0","0.44953899999661373","15","","0.00732421875","0","0","0"
"GatherBackward","0.023551999998744577","5.542917000001413","0","1.488879999989178","15","","0.00732421875","0","0","0"
"aten::select","0","0.30000800000841266","0","0.2696630000130972","30","","0","0","0","0"
"autograd::engine::evaluate_function: NllLossBackward0","98.20877400000161","23.451267999997945","0","0.9032269999940181","30","","18826.55859375","1567.99951171875","0","0"
"NllLossBackward0","98.20877400000161","22.548041000003927","0","0.31008500000357164","30","","17258.55908203125","-784.53125","0","0"
"aten::nll_loss_backward","98.20877400000161","22.237956000000356","2.0016309999993536","0.9553949999976903","30","","18043.09033203125","20396.7158203125","0","0"
"aten::zero_","311.83979499999526","14.110973999988287","0","2.7884150000228547","525","","-6107.98193359375","-2409.18017578125","0","0"
"autograd::engine::evaluate_function: LogSoftmaxBackward0","365.25823500000735","26.915808000005317","0","0.4596609999977518","30","","-19527.90576171875","-46285.47412109375","0.00000762939453125","0"
"LogSoftmaxBackward0","365.25823500000735","26.456147000007565","0","0.23825700000906364","30","","26757.568359375","1568.96630859375","0.00000762939453125","0.00000762939453125"
"aten::_log_softmax_backward_data","365.25823500000735","26.2178899999985","365.25823500000735","0.751600000007078","30","","25188.60205078125","25055.96826171875","0","0"
"cudaMalloc","0","91.65128199999616","0","90.12978600000986","211","","-1289.396484375","-1289.396484375","0","0"
"autograd::engine::evaluate_function: ViewBackward0","0","74.00250400002231","0","39.06776400000812","4410","","-9843.1171875","-9990.95361328125","-0.000030517578125","0.0000152587890625"
"ViewBackward0","0","34.934740000014195","0","13.63591499995161","4410","","147.83642578125","717.640625","-0.0000457763671875","-0.00003814697265625"
"aten::reshape","0","21.568659000057494","0","9.86347400018247","4440","","-581.80419921875","-109.70947265625","-0.00000762939453125","-0.0000152587890625"
"autograd::engine::evaluate_function: CloneBackward0","0","0.33823799999593757","0","0.31727799998852424","30","","-48.06396484375","-48.06396484375","0","0"
"CloneBackward0","0","0.020960000007413326","0","0.020960000007413326","30","","0","0","0","0"
"autograd::engine::evaluate_function: SliceBackward0","615.5033990000102","6.6098850000048985","0","0.6300190000107978","60","","-5756.62109375","-46811.49853515625","0","0"
"SliceBackward0","615.5033990000102","5.979865999994101","0","0.2929240000001155","60","","41054.87744140625","785.9990234375","0","0"
"aten::slice_backward","615.5033990000102","5.686941999993985","0","0.836319999983767","60","","40268.87841796875","987.18408203125","0","0"
"aten::zeros","207.04325800000154","5.659925000008661","0","0.7684130000011065","135","","50864.2939453125","1366.44921875","-0.00000762939453125","0"
"autograd::engine::evaluate_function: UnsafeViewBackward0","0","0.6328080000004266","0","0.24457400000141932","30","","-2164.24853515625","-625.26171875","0","0"
"UnsafeViewBackward0","0","0.3882339999990072","0","0.11840000000409782","30","","-1538.98681640625","-1526.98681640625","0","0"
"autograd::engine::evaluate_function: MmBackward0","1233.501513000015","6.865048999990802","0","0.810274999991525","30","","-29201.07958984375","-26024.76025390625","0","0"
"MmBackward0","1233.501513000015","6.054773999999277","0","0.6347050000135787","30","","-3176.3193359375","-2422.5361328125","0","0"
"aten::t","0","27.830587000090162","0","11.606157000079984","3000","","-769.7431640625","-586.904296875","-0.00000762939453125","0.00002288818359375"
"aten::transpose","0","30.379541999998967","0","21.288521999910706","6600","","-2599.6943359375","-1657.349609375","-0.00002288818359375","-0.00000762939453125"
"aten::mm","4869.293858999989","150.52725499998826","4869.293858999989","96.9973129999307","2940","","15916.7314453125","25157.763671875","0.000030517578125","0.000091552734375"
"autograd::engine::evaluate_function: TBackward0","0","1.5546540000108071","0","1.0144720000037923","30","","-281.3017578125","-482.5224609375","0","0"
"TBackward0","0","0.5401820000070148","0","0.3131790000121109","30","","201.220703125","41.9775390625","0","0"
"autograd::engine::evaluate_function: NativeLayerNormBackward0","154.21583900010307","95.3022519999959","0","22.5536850000415","750","","-32678.82763671875","-30437.04248046875","0.00002288818359375","0"
"NativeLayerNormBackward0","111.2824550000648","57.60063999999082","0","6.635681000023615","750","","157.046875","-2786.71923828125","0.00000762939453125","0.00000762939453125"
"aten::native_layer_norm_backward","111.2824550000648","50.9649589999672","111.2824550000648","17.560462999950396","750","","2943.76611328125","-2630.689453125","0","0.0000152587890625"
"autograd::engine::evaluate_function: AddBackward0","0.6818269999991171","17.412792000041577","0","14.975539000069956","1470","","-4809.43017578125","-4820.33203125","0.0000457763671875","0.0000457763671875"
"AddBackward0","0","1.492210999976378","0","1.492210999976378","1470","","-60.046875","-60.046875","0","0"
"autograd::engine::evaluate_function: AddmmBackward0","3752.2032909999266","314.21120700003115","0","42.279462000115075","1440","","-74957.55078125","-75887.9609375","0.0000152587890625","0.0000457763671875"
"AddmmBackward0","3635.7923459999743","192.50191200003167","0","19.791141999933867","1440","","12808.62548828125","-2932.90283203125","0.00003814697265625","0.0000152587890625"
"cudaOccupancyMaxActiveBlocksPerMultiprocessor","0","3.3833010000456123","0","3.3833010000456123","1800","","-246.75830078125","-246.75830078125","0.00000762939453125","0.00000762939453125"
"aten::sum","133.091958999909","88.93587299994869","133.091958999909","62.91237499996275","1830","","-12048.50830078125","-8592.09716796875","-0.00008392333984375","-0.00003814697265625"
"autograd::engine::evaluate_function: MulBackward0","1117.856451999968","78.64157200002322","0","21.65023200001917","1440","","-25830.923828125","-106945.19921875","0.00002288818359375","-0.00003814697265625"
"MulBackward0","884.8981239999725","51.53150599997281","0","6.573088000013027","1440","","81008.38134765625","-1345.24267578125","0.0000457763671875","0.0000152587890625"
"aten::mul","1310.6770689999198","74.73856800000183","1310.6770689999198","49.22098399998364","2895","","116817.748046875","118784.5859375","0.00000762939453125","0.00006866455078125"
"autograd::engine::evaluate_function: TanhBackward0","230.36812399996515","16.28209500001883","0","4.406155000032625","360","","-21053.83544921875","-35248.92822265625","-0.00002288818359375","-0.000030517578125"
"TanhBackward0","230.36812399996515","11.875939999986207","0","1.98903699999745","360","","14195.0927734375","-211.52685546875","0.00000762939453125","0.0000152587890625"
"aten::tanh_backward","230.36812399996515","9.886902999988758","230.36812399996515","6.367340999968117","360","","14406.61962890625","16136.0498046875","-0.00000762939453125","-0.0000152587890625"
"autograd::engine::evaluate_function: PowBackward0","774.9653649999167","54.117751000005754","0","9.482594000026817","360","","-42640.21484375","-54657.92138671875","0","0"
"PowBackward0","548.0661399999406","35.90918399999128","0","3.9185399999984076","360","","13746.84423828125","-34954.35205078125","-0.0000152587890625","-0.00000762939453125"
"aten::pow","155.14432099998487","14.01477799999062","155.14432099998487","10.064880999989109","360","","16506.083984375","16219.77099609375","0.0000152587890625","0.00000762939453125"
"aten::result_type","0","1.7868929999154062","0","1.7868929999154062","13680","","-60.19775390625","-60.19775390625","0","0"
"aten::add_","502.7909370000097","31.729458999939496","502.7909370000097","20.49481899997941","3660","","-4022.07568359375","-4342.30908203125","0.0000457763671875","-0.0000152587890625"
"autograd::engine::evaluate_function: TransposeBackward0","0","6.954074000010267","0","3.2950150000147986","360","","-1301.24951171875","-839.697265625","-0.00000762939453125","0.00000762939453125"
"TransposeBackward0","0","3.659058999995468","0","0.8633820000207052","360","","-461.55224609375","-69.494140625","-0.0000152587890625","0"
"autograd::engine::evaluate_function: ScaledDotProductEfficientAttentionBackward0","1396.776590999913","785.2991960000156","0","10.32231100002164","360","","-21606.0986328125","-22358.77392578125","-0.0000152587890625","-0.0000152587890625"
"ScaledDotProductEfficientAttentionBackward0","1396.776590999913","774.9768849999939","0","4.205050000006799","360","","752.67529296875","-131.8349609375","0","0"
"aten::_scaled_dot_product_efficient_attention_backward","1396.776590999913","770.7718349999872","0","9.900594000005862","360","","884.51025390625","-1337.8056640625","0","0.00000762939453125"
"aten::_efficient_attention_backward","1396.776590999913","750.8539609999908","1337.996952999976","18.208849999862025","360","","3799.24560546875","-10931.8486328125","-0.00003814697265625","-0.00000762939453125"
"aten::contiguous","1.3525559999984689","15.06362699998892","0","0.7390009999959729","360","","-2435.8408203125","34.1455078125","0.00002288818359375","0"
"aten::clone","1.3525559999984689","14.324625999992946","0","1.9286190000057686","360","","-2469.986328125","-412.46435546875","0.00002288818359375","-0.00000762939453125"
"cudaFuncGetAttributes","0","2.01354399999138","0","2.01354399999138","360","","-242.23046875","-242.23046875","0.00000762939453125","0.00000762939453125"
"autograd::engine::evaluate_function: PermuteBackward0","0","20.05665700000408","0","10.640243999999017","1080","","-2034.51416015625","-1283.69921875","0","-0.00000762939453125"
"PermuteBackward0","0","9.416413000005065","0","3.378510000065202","1080","","-750.81494140625","-355.30322265625","0.00000762939453125","0.0000152587890625"
"aten::permute","0","6.037902999939862","0","5.026520999906352","1080","","-395.51171875","-276.83984375","-0.00000762939453125","-0.00000762939453125"
"autograd::engine::evaluate_function: SplitBackward0","94.76573200000148","20.760419999995733","0","4.444687000021106","360","","-970.1630859375","-13212.05908203125","-0.0000152587890625","-0.00002288818359375"
"SplitBackward0","94.76573200000148","16.315732999974628","0","1.6982529999704565","360","","12241.89599609375","-339.90185546875","0.00000762939453125","-0.00000762939453125"
"autograd::engine::evaluate_function: EmbeddingBackward0","84.21668800009158","19.70806000000541","0","1.4030460000124294","60","","-2091.78076171875","-9548.2001953125","-0.00000762939453125","0"
"EmbeddingBackward0","25.67841800008435","17.498448999998857","0","0.2529680000017397","60","","3231.26513671875","47.71875","-0.00000762939453125","0"
"aten::embedding_backward","25.67841800008435","17.245480999997117","0","0.19481799999414942","60","","3183.54638671875","-12","-0.00000762939453125","0"
"aten::embedding_dense_backward","25.67841800008435","17.05066300000297","9.124390000086045","5.2236229999926875","60","","3195.54638671875","-361.31689453125","-0.00000762939453125","-0.00000762939453125"
"aten::arange","0.09970599999418482","2.40390899999463","0.04985299999709241","0.6079370000057388","60","","124.216796875","59.96875","0.0000152587890625","0"
"aten::resize_","0","0.2039240000031423","0","0.2039240000031423","30","","-245.53662109375","-245.53662109375","0.00000762939453125","0.00000762939453125"
"cudaDeviceGetAttribute","0","0.13479199997591787","0","0.13479199997591787","150","","-4.5","-4.5","0","0"
"cudaPeekAtLastError","0","0.10236799999722279","0","0.10236799999722279","510","","-36","-36","0","0"
"aten::add","58.5604140000036","1.2290559999952093","58.5604140000036","0.8478999999833758","45","","4225.16162109375","4345.19921875","0","0"
"autograd::engine::evaluate_function: BroadcastBackward","1443.8101800000006","197.15639499999816","0","8.52033800000092","15","","-7273.267578125","-14405.7646484375","0","0"
"BroadcastBackward","1443.8101800000006","188.63605699999724","0","5.251372000003234","15","","7132.4970703125","0","0","0"
"ReduceAddCoalesced","1443.8101800000006","183.384684999994","1393.7611550000108","74.88382600015565","15","","7132.4970703125","-9847.453125","0","0"
"autograd::engine::evaluate_function: torch::autograd::AccumulateGrad","0","23.18226300002751","0","12.737836000059033","2220","","0","0","0","0"
"torch::autograd::AccumulateGrad","0","10.444426999968476","0","5.515771999907214","2220","","0","0","0","0"
"aten::detach","0","5.36927800006466","0","2.8939870001072996","2369","","0","0","0","0"
"detach","0","2.4752909999573602","0","2.4752909999573602","2369","","0","0","0","0"
"aten::_foreach_norm","30.178616000000854","11.405918999992078","30.160122000006027","9.634492999994894","15","","1.083984375","-3.9111328125","0","0"
"aten::stack","0.057632999997818846","7.770915999996942","0","2.3360839999166783","15","","0.0146484375","0","0","0"
"aten::unsqueeze","0","3.9907740000777414","0","3.194104000055464","2220","","0","0","0","0"
"aten::linalg_vector_norm","0.0489289999967441","0.7215530000068248","0.0489289999967441","0.540077000010293","15","","0.00732421875","0.00732421875","0","0"
"aten::reciprocal","0.0212139999975916","0.3989550000047311","0.0212139999975916","0.25483900000224824","15","","0.00732421875","0.00732421875","0","0"
"aten::clamp","0.023421999999787658","0.47734199999342675","0.023421999999787658","0.31344800000195394","15","","0.00732421875","0.00732421875","0","0"
"aten::_foreach_mul_","192.70068800000007","9.014867999992333","192.70068800000007","6.246168000017991","45","","0","0","0","0"
"Optimizer.step#AdamW.step","630.7389950000036","93.2659410000029","0","36.0017230000277","15","","0","-7198.248046875","0","-0.000057220458984375"
"aten::lift_fresh","0","0.008291999994544313","0","0.008291999994544313","15","","0","0","0","0"
"aten::detach_","0","0.06972799999965355","0","0.05112199999322183","15","","0","0","0","0"
"detach_","0","0.018606000006431714","0","0.018606000006431714","15","","0","0","0","0"
"aten::_foreach_add_","64.13136799998931","9.004905999993673","64.13136799998931","5.65817100010952","30","","0","0","0","0"
"aten::_foreach_lerp_","94.5846089999897","1.5438800000001212","94.5846089999897","0.9018479999986011","15","","0","0","0","0"
"aten::_foreach_addcmul_","94.56623900002218","3.751663000003202","94.56623900002218","2.8173679999934973","15","","0","0","0","0"
"aten::item","0.0207989999987185","3040.3228589999717","0","5.057678000020096","4454","","0","0","0","0"
"aten::_local_scalar_dense","0.0207989999987185","3035.2651809999516","0.0207989999987185","1.5878839999516494","4454","","0","0","0","0"
"aten::_foreach_sqrt","63.864135999981315","21.39729999999865","63.864135999981315","6.078311999984319","15","","7198.248046875","0","0","0"
"aten::_foreach_div_","63.95021700001951","3.72887800000282","63.95021700001951","2.7881990000233055","15","","0","0","0","0"
"aten::_foreach_addcdiv_","120.58219500000612","4.163887000004994","120.58219500000612","3.213397000005003","15","","0","0","0","0"
"cudaDeviceSynchronize","0","1020.2052859999989","0","1020.2052859999989","12","","0","0","0","0"
"Optimizer.step#AdamW.step","631.2857219999977","0","631.2857219999977","0","15","","0","0","0","0"
"cudaHostAlloc","0.06774399999994785","3.5158940000000873","0","1.6487379999998957","19","","67.0205078125","43.08203125","0","0"
"Memcpy DtoH (Device -> Pinned)","0.0207989999987185","0","0.0207989999987185","0","13","","0","0","0","0"
"aten::random_","0","0.020959999999962748","0","0.020959999999962748","1","","0","0","0","0"
"aten::set_","0","1.6111889999974518","0","1.6111889999974518","296","","0","0","0","0"
"Memcpy DtoH (Device -> Pageable)","106.36298499999661","0","106.36298499999661","0","148","","0","0","0","0"
"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)","29.7034729999844","0","29.7034729999844","0","700","","0","0","0","0"
"autograd::engine::evaluate_function: NativeDropoutBackward0","16.957965000003576","37.421879000071435","0","7.9066290000882","700","","3498.38623046875","-3655.52490234375","-0.0000152587890625","-0.00000762939453125"
"NativeDropoutBackward0","16.957965000003576","29.515249999983237","0","2.8125579999852928","700","","7153.9111328125","62.27685546875","-0.00000762939453125","0"
"aten::native_dropout_backward","16.957965000003576","26.702691999997942","16.957965000003576","10.262077999979258","700","","7091.63427734375","-1321.498046875","-0.00000762939453125","-0.00000762939453125"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)","16.957965000003576","0","16.957965000003576","0","700","","0","0","0","0"
"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)","1256.5669119999764","0","1256.5669119999764","0","336","","0","0","0","0"