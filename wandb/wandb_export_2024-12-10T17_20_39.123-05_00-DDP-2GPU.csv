"Name","Device Time Total (ms)","CPU Time Total (ms)","Self Device Time Total (ms)","Self CPU Time Total (ms)","Calls","Input Shapes","Device Memory Usage (MB)","Self Device Memory Usage (MB)","CPU Memory Usage (MB)","Self CPU Memory Usage (MB)"
"ProfilerStep*","8119.909593000025","20600.969302999998","0","6210.689167","10","","2.0634765625","-137544.49853515625","0","-0.00458526611328125"
"enumerate(DataLoader)#_MultiProcessingDataLoaderIter.__next__","0","9.282259999998104","0","8.795937999998408","21","","0","0","0","0"
"aten::to","13.07202200000931","7895.66903500005","0","0.6542390000462764","2190","","2.5","0","0","0"
"aten::_to_copy","13.07202200000931","7895.014796000003","0","0.5708470000021625","40","","2.5","0","0","0"
"aten::empty_strided","0","13.189763999965816","0","11.513230999967858","1730","","7751.87109375","7751.87109375","0","0"
"aten::copy_","793.0588429999563","8597.436086999975","780.3100239999542","15.21836899994081","2088","","0","0","0","0"
"cudaMemcpyAsync","0","688.4701470000207","0","688.4548330000196","1931","","0","0","0","0"
"Memset (Device)","3.102846999954566","0","3.102846999954566","0","1826","","0","0","0","0"
"ampere_sgemm_128x64_nn","214.32816999999653","0","214.32816999999653","0","242","","0","0","0","0"
"cudaStreamSynchronize","12.748819000001998","12195.69324899999","0","12194.426920999993","205","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)","857.1369149999929","0","857.1369149999929","0","1265","","0","0","0","0"
"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)","60.43232600003562","0","60.43232600003562","0","504","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_256x128_8x4_nn_align1>(cutlass_80_simt_sgemm_256x128_8x4_nn_align1::Params)","2054.533756000041","0","2054.533756000041","0","494","","0","0","0","0"
"cudaPointerGetAttributes","0","0.25028999999929374","0","0.25028999999929374","56","","95","95","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)","1095.476560000022","0","1095.476560000022","0","2893","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#2}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#2}, at::detail::Array<char*, 2>)","208.6024299999692","0","208.6024299999692","0","242","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::tanh_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::tanh_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)","208.78812200001144","0","208.78812200001144","0","242","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<float>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<float>, at::detail::Array<char*, 2>)","208.70780499998935","0","208.70780499998935","0","253","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)","861.8163549999442","0","861.8163549999442","0","770","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_128x64_8x5_nn_align1>(cutlass_80_simt_sgemm_128x64_8x5_nn_align1::Params)","830.0936129999856","0","830.0936129999856","0","242","","0","0","0","0"
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)","587.408364999995","0","587.408364999995","0","241","","0","0","0","0"
"cudaEventQuery","12.748819000001998","2.003417999927915","12.748819000001998","2.003417999927915","1153","","19.43798828125","19.43798828125","0","0"
"ampere_sgemm_128x128_tn","1947.430658000003","0","1947.430658000003","0","21","","0","0","0","0"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})","463.69470099998557","0","463.69470099998557","0","164","","0","0","0","0"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1} const&)::{lambda(int)#1})","0.13968099999715924","0","0.13968099999715924","0","21","","0","0","0","0"
"void at::native::(anonymous namespace)::cunn_SoftMaxForward<4, float, float, float, at::native::(anonymous namespace)::LogSoftMaxForwardEpilogue>(float*, float const*, int)","297.67631300000147","0","297.67631300000147","0","21","","0","0","0","0"
"void at::native::(anonymous namespace)::nll_loss_forward_reduce_cuda_kernel_2d<float, float, long>(float*, float*, float const*, long const*, float const*, bool, long, long, long, long)","7.342395000001212","0","7.342395000001212","0","21","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)","219.8453119999932","0","219.8453119999932","0","81","","0","0","0","0"
"void at::native::(anonymous namespace)::nll_loss_backward_reduce_cuda_kernel_2d<float, long>(float*, float const*, long const*, float const*, float const*, bool, int, int, long, long)","2.1715590000034717","0","2.1715590000034717","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::cunn_SoftMaxBackward<4, float, float, float, at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue>(float*, float const*, float const*, long)","268.97595099999415","0","268.97595099999415","0","11","","0","0","0","0"
"Memcpy DtoD (Device -> Device)","220.39743499996553","0","220.39743499996553","0","1879","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_128x256_8x4_nt_align1>(cutlass_80_simt_sgemm_128x256_8x4_nt_align1::Params)","884.230315000002","0","884.230315000002","0","143","","0","0","0","0"
"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)","70.54499199999427","0","70.54499199999427","0","275","","0","0","0","0"
"void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)","79.2133549999987","0","79.2133549999987","0","275","","0","0","0","0"
"ampere_sgemm_128x64_tn","1557.8785700000044","0","1557.8785700000044","0","528","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_128x64_8x5_nt_align1>(cutlass_80_simt_sgemm_128x64_8x5_nt_align1::Params)","888.2198449999718","0","888.2198449999718","0","396","","0","0","0","0"
"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)","123.93662999997085","0","123.93662999997085","0","539","","0","0","0","0"
"ncclDevKernel_AllReduce_Sum_f32_RING_LL(ncclDevComm*, unsigned long, ncclWork*)","2434.6231830000233","0","2434.6231830000233","0","147","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::tanh_backward_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::tanh_backward_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)","172.71127599999315","0","172.71127599999315","0","132","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#1}, at::detail::Array<char*, 2>)","115.05402500000264","0","115.05402500000264","0","132","","0","0","0","0"
"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)","13.171273000008194","0","13.171273000008194","0","132","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<unsigned char>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<unsigned char>, at::detail::Array<char*, 1>)","6.550173999994644","0","6.550173999994644","0","132","","0","0","0","0"
"fmha_cutlassB_f32_aligned_64x64_k64_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, false, false, 64, 64, 64, false>::Params)","610.3837919999974","0","610.3837919999974","0","84","","0","0","0","0"
"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 3, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)","81.27060099998378","0","81.27060099998378","0","132","","0","0","0","0"
"void at::native::(anonymous namespace)::embedding_backward_feature_kernel<float, float, long>(long const*, float const*, float*, int, long, int)","0.42601599999296014","0","0.42601599999296014","0","11","","0","0","0","0"
"void (anonymous namespace)::elementwise_kernel_with_index<int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}, function_traits<at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>::result_type*)","0.05660900000599213","0","0.05660900000599213","0","31","","0","0","0","0"
"void at_cuda_detail::cub::DeviceRadixSortHistogramKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy800, false, long, unsigned long long>(unsigned long long*, long const*, unsigned long long, int, int)","0.09084800000127871","0","0.09084800000127871","0","11","","0","0","0","0"
"void at_cuda_detail::cub::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy800, unsigned long long>(unsigned long long*)","0.025662000000476838","0","0.025662000000476838","0","11","","0","0","0","0"
"void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy800, false, long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long, int, int>(int*, int*, unsigned long long*, unsigned long long const*, long*, long const*, at::cuda::cub::detail::OpaqueType<8>*, at::cuda::cub::detail::OpaqueType<8> const*, int, int, int)","1.0250580000083427","0","1.0250580000083427","0","88","","0","0","0","0"
"void at_cuda_detail::cub::DeviceCompactInitKernel<at_cuda_detail::cub::ScanTileState<int, true>, long*>(at_cuda_detail::cub::ScanTileState<int, true>, int, long*)","0.04729699999804143","0","0.04729699999804143","0","11","","0","0","0","0"
"void at_cuda_detail::cub::DeviceUniqueByKeySweepKernel<at_cuda_detail::cub::DeviceUniqueByKeyPolicy<long const*>::Policy520, long const*, thrust::counting_iterator<int, thrust::use_default, thrust::use_default, thrust::use_default>, long*, long*, long*, at_cuda_detail::cub::ScanTileState<int, true>, at_cuda_detail::cub::Equality, int>(long const*, thrust::counting_iterator<int, thrust::use_default, thrust::use_default, thrust::use_default>, long*, long*, long*, at_cuda_detail::cub::ScanTileState<int, true>, at_cuda_detail::cub::Equality, int, int)","0.07190599999867846","0","0.07190599999867846","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::krn_partials_per_segment<long>(long*, long const*, long const*, long)","0.028064999990980142","0","0.028064999990980142","0","11","","0","0","0","0"
"void at_cuda_detail::cub::DeviceScanInitKernel<at_cuda_detail::cub::ScanTileState<long, true> >(at_cuda_detail::cub::ScanTileState<long, true>, int)","0.018721999998553656","0","0.018721999998553656","0","11","","0","0","0","0"
"void at_cuda_detail::cub::DeviceScanKernel<at_cuda_detail::cub::DeviceScanPolicy<long>::Policy600, long const*, long*, at_cuda_detail::cub::ScanTileState<long, true>, at::cuda::cub::(anonymous namespace)::SumOp<long>, at_cuda_detail::cub::detail::InputValue<long, long*>, int, long>(long const*, long*, at_cuda_detail::cub::ScanTileState<long, true>, int, at::cuda::cub::(anonymous namespace)::SumOp<long>, at_cuda_detail::cub::detail::InputValue<long, long*>, int)","0.050174000000348315","0","0.050174000000348315","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::compute_num_of_partial_segments<long>(long const*, long const*, long const*, long*)","0.024223999997833742","0","0.024223999997833742","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::krn_partial_segment_offset<long>(long*, long const*, long const*, long const*, long const*)","0.05155399999860674","0","0.05155399999860674","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::compute_grad_weight<float, long>(long const*, float const*, long const*, long, long, long const*, long const*, at::AccumulateType<float, true>::type*, long)","2.2064730000013952","0","2.2064730000013952","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::sum_and_scatter<float, long>(long const*, float*, long, long const*, long const*, at::AccumulateType<float, true>::type const*, long const*, long const*, long, long)","0.977155000000028","0","0.977155000000028","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::LpNormFunctor<float, (at::native::NormType)1, float, 1, 1, 0>, float*, int>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::LpNormFunctor<float, (at::native::NormType)1, float, 1, 1, 0>, float*, int)","22.617646000013803","0","22.617646000013803","0","77","","0","0","0","0"
"void at::native::lpnorm_cleanup<float, (at::native::NormType)1, float, float>(float const*, at::native::TensorListAddresses, int)","0.04985699999949429","0","0.04985699999949429","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)","0.5812840000065044","0","0.5812840000065044","0","32","","0","0","0","0"
"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::NormTwoOps<float, float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::NormTwoOps<float, float, float>, unsigned int, float, 4>)","0.045664000007440336","0","0.045664000007440336","0","11","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::reciprocal_kernel_cuda(at::TensorIteratorBase&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::reciprocal_kernel_cuda(at::TensorIteratorBase&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)","0.02031999999913387","0","0.02031999999913387","0","11","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)","0.02169500000041444","0","0.02169500000041444","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarTensorFunctor<float, 1, 1, 0>, std::multiplies<float>, float*, float>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarTensorFunctor<float, 1, 1, 0>, std::multiplies<float>, float*, float)","46.758883999999846","0","46.758883999999846","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::multiplies<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::multiplies<float>, float)","94.6133339999941","0","94.6133339999941","0","154","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::TernaryOpScalarFunctor<float, 2, 2, 0>, at::native::LerpFunctor<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::TernaryOpScalarFunctor<float, 2, 2, 0>, at::native::LerpFunctor<float>, float)","69.27094400000979","0","69.27094400000979","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<3>, at::native::(anonymous namespace)::PointwiseOpScalarFunctor<float, 3, 3, 0>, std::multiplies<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<3>, at::native::(anonymous namespace)::PointwiseOpScalarFunctor<float, 3, 3, 0>, std::multiplies<float>, float)","69.27369399999863","0","69.27369399999863","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::UnaryOpFunctor<float, 2, 1, 1>, at::native::Sqrt<float> >(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::UnaryOpFunctor<float, 2, 1, 1>, at::native::Sqrt<float>)","46.87988200001896","0","46.87988200001896","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 1>, at::native::(anonymous namespace)::BinaryOpScalarListFunctor<float, 1, 1, 0>, std::divides<float> >(at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 1>, at::native::(anonymous namespace)::BinaryOpScalarListFunctor<float, 1, 1, 0>, std::divides<float>)","46.870662999999595","0","46.870662999999595","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::plus<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::plus<float>, float)","47.037199000003746","0","47.037199000003746","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 3>, at::native::(anonymous namespace)::PointwiseOpScalarListFunctor<float, 3, 3, 0>, std::divides<float> >(at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 3>, at::native::(anonymous namespace)::PointwiseOpScalarListFunctor<float, 3, 3, 0>, std::divides<float>)","88.44070799999871","0","88.44070799999871","0","77","","0","0","0","0"
"ProfilerStep*","20197.009990000002","0","20197.009990000002","0","10","","0","0","0","0"
"Memcpy HtoD (Pinned -> Device)","0.32320300000731367","0","0.32320300000731367","0","40","","0","0","0","0"
"DistributedDataParallel.forward","7479.133549999965","489.260244999999","0","128.7301300001006","20","","137523.8583984375","-210554.73828125","0.00457763671875","0.00273895263671875"
"cudaEventSynchronize","0.20902399999648333","0.01830299999995623","0.20902399999648333","0.01830299999995623","8","","0","0","0","0"
"cudaEventElapsedTime","0.009697000000625849","0.011889999999897554","0.009697000000625849","0.011889999999897554","4","","0","0","0","0"
"aten::flatten_dense_tensors","1.503081999998307","3.1186119999985675","0","0.6364009999877308","20","","120.0048828125","0","0","0"
"aten::view","0","18.957147999966402","0","18.955186999966273","6520","","0","0","0","0"
"aten::cat","75.46034599999176","21.01725199998671","75.46034599999176","4.29249999999092","150","","8760.0146484375","8760.0146484375","0","0"
"cudaLaunchKernel","0","761.9455739999983","0","761.824873000016","11334","","0","0","0","0"
"DistributedDataParallel.forward","7596.641477000005","0","7596.641477000005","0","20","","0","0","0","0"
"void at::native::(anonymous namespace)::CatArrayBatchedCopy_contig<at::native::(anonymous namespace)::OpaqueType<1u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<1u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<1u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)","0.9779920000014827","0","0.9779920000014827","0","10","","0","0","0","0"
"c10d::broadcast_","9.79379600000102","4.335311999997357","0","1.0090900000036926","20","","0","0","0","0"
"record_param_comms","2202.0334440000242","689.9983249999867","2202.0275880000245","11.704119000052916","178","","0.001953125","0","0","0"
"cudaStreamIsCapturing","0","1.0527039999089902","0","1.0527039999089902","820","","0","0","0","0"
"cudaEventRecord","0.025600000001490115","1.2102939999912632","0.025600000001490115","1.2102939999912632","794","","0","0","0","0"
"cudaStreamWaitEvent","0","0.8929969999797177","0","0.8929969999797177","616","","0","0","0","0"
"nccl:broadcast","0","2.5471429999931714","0","0","20","","0","0","0","0"
"cudaStreamGetCaptureInfo_v2","0","0.17036999999452382","0","0.17036999999452382","154","","0","0","0","0"
"cudaLaunchKernelExC","0","1.9044379999912344","0","1.9044379999912344","154","","0","0","0","0"
"ncclDevKernel_Broadcast_RING_LL(ncclDevComm*, unsigned long, ncclWork*)","9.79379600000102","0","9.79379600000102","0","20","","0","0","0","0"
"nccl:broadcast","9.79379600000102","0","9.79379600000102","0","20","","0","0","0","0"
"aten::unflatten_dense_tensors","0","2.963651000006823","0","0.7999760000186507","20","","0","0","0","0"
"aten::narrow","0","6.8449560000008205","0","2.6471040000037758","960","","0","0","0","0"
"aten::slice","0","4.764480999998981","0","3.5558299999616576","1040","","0","0","0","0"
"aten::as_strided","0","8.952512999885716","0","8.952512999885716","8650","","0","0","0","0"
"aten::arange","0.10976200001197867","3.317355999985826","0.05488100000598933","0.657939000000013","60","","1.5625","0","0","0"
"aten::empty","0","230.71923300008092","0","32.791087000080736","4379","","102355.8056640625","102331.8056640625","0.0029754638671875","0.0029754638671875"
"aten::resize_","0","0.668376999992528","0","0.5884099999871105","90","","540.78125","540.78125","0","0"
"aten::unsqueeze","0","3.15140100005758","0","2.51294900011376","1500","","0","0","0","0"
"aten::embedding","3.650506999992998","2.659176999997115","0","0.5516209999928251","40","","540","0","0","0"
"aten::reshape","0","7.730378000059863","0","3.2036090000850383","1540","","0","0","0","0"
"aten::index_select","3.650506999992998","1.930298000000068","3.650506999992998","0.7894770000036806","40","","540","0","0","0"
"void at::native::(anonymous namespace)::indexSelectLargeIndex<float, long, unsigned int, 2, 2, -2, true>(at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<long const, unsigned int>, int, int, unsigned int, unsigned int, long)","3.650506999992998","0","3.650506999992998","0","40","","0","0","0","0"
"aten::add","665.4939239999709","28.18648799997312","665.4939239999709","18.68595899998315","1000","","59553.5302734375","59553.5302734375","0","0"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})","1.7216419999966166","0","1.7216419999966166","0","20","","0","0","0","0"
"aten::dropout","15.024877999968826","111.24047500000044","0","0.7833299999953015","500","","3000.7626953125","0","0","0"
"aten::layer_norm","59.97229400003562","38.29019599999988","0","2.277990000028047","500","","12015.625","-15.625","0","0"
"aten::native_layer_norm","59.97229400003562","36.01220599997183","59.97229400003562","15.323132999957423","500","","12031.25","0","0","0"
"aten::addmm","2381.473345000023","62.792577999983685","2381.473345000023","42.12786199996038","960","","51840.2880859375","51769.2880859375","0","0"
"cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags","0","2.2421919999901436","0","2.2421919999901436","1240","","0","0","0","0"
"cudaFuncSetAttribute","0","532.621683000025","0","532.621683000025","740","","0","0","0","0"
"aten::split","0","7.587028999990551","0","2.525733999987715","240","","0","0","0","0"
"aten::permute","0","5.903159000052837","0","4.979889000086812","1080","","0","0","0","0"
"aten::scaled_dot_product_attention","585.226148999995","27.59909999996878","0","4.12678599998122","240","","5805","0","0.00183868408203125","-0.00182342529296875"
"aten::_scaled_dot_product_efficient_attention","585.226148999995","23.472313999987556","0","4.543243999983999","240","","5805","0","0.003662109375","0"
"aten::transpose","0","14.43990899996017","0","10.309145000006188","3420","","0","0","0","0"
"aten::_efficient_attention_forward","585.226148999995","15.579833000016283","585.226148999995","6.028336000045179","240","","5805","0","0.003662109375","0"
"cudaMemsetAsync","0","10.774496000023674","0","10.774496000023674","1680","","0","0","0","0"
"cudaOccupancyMaxActiveBlocksPerMultiprocessor","0","1.414535999991349","0","1.414535999991349","720","","0","0","0","0"
"aten::mul","1856.248070999966","85.82540700001049","1856.248070999966","46.43343300004292","3410","","175681.7333984375","175681.7333984375","0","0"
"aten::pow","311.5558349999717","12.803870000021648","311.5558349999717","7.9058410000199215","360","","34560","34560","0","0"
"aten::result_type","0","1.1584479998459574","0","1.1584479998459574","9240","","0","0","0","0"
"aten::tanh","207.05608400001145","5.449830999973346","207.05608400001145","3.6825089999446647","240","","23040","23040","0","0"
"aten::linear","1861.8168110000029","2.227966000005137","0","0.09939400000264868","20","","31410.625","0","0","0"
"aten::t","0","8.776277000018629","0","3.58739100003941","1020","","0","0","0","0"
"aten::matmul","1861.8168110000029","1.8782640000036919","0","0.2453090000068769","20","","31410.625","0","0","0"
"aten::mm","5533.456582999962","44.581347999999764","5533.456582999962","28.217248999934295","1000","","56556.7822265625","56556.7822265625","0","0"
"aten::_unsafe_view","0","0.08983699999831152","0","0.08983699999831152","20","","0","0","0","0"
"aten::contiguous","290.11643999998574","6.739356999985874","0","0.2823509999854723","160","","31426.201171875","0","0","0"
"aten::clone","290.11643999998574","6.457006000000401","0","0.8002959999870509","160","","31426.201171875","0","0","0"
"aten::empty_like","0","7.998831000025733","0","1.8649280000653816","490","","36828.21875","0","0","0"
"aten::cross_entropy_loss","290.49843100000265","2.2408239999997894","0","0.18272800000791903","20","","15689.990234375","-15689.9755859375","0","0"
"aten::log_softmax","283.50829300000146","1.1631409999954048","0","0.11479899999755434","20","","31379.951171875","0","0","0"
"aten::_log_softmax","283.50829300000146","1.0403210000031395","283.50829300000146","0.5361840000076918","20","","31379.951171875","31379.951171875","0","0"
"aten::nll_loss_nd","6.9901380000012","0.8949549999964657","0","0.0627230000041891","20","","0.0146484375","0","0","0"
"aten::nll_loss","6.9901380000012","0.8322319999922766","0","0.09280999999761116","20","","0.0146484375","-0.0048828125","0","0"
"aten::nll_loss_forward","6.9901380000012","0.7394219999946654","6.9901380000012","0.5200760000030278","20","","0.01953125","0.01953125","0","0"
"cudaFree","0","878.4367599999983","0","878.4247459999981","79","","0","0","0","0"
"aten::ones_like","0.02729599999752827","0.6344449999984354","0","0.05235899998550303","10","","0.0048828125","0","0","0"
"aten::fill_","206.24933199998807","11.64464299999806","206.24933199998807","1.6253139999969863","194","","0","0","0","0"
"autograd::engine::evaluate_function: NllLossBackward0","67.17784300000383","5.996694999995176","0","0.2926969999987632","10","","15689.345703125","-0.6298828125","0","0"
"NllLossBackward0","67.17784300000383","5.703997999996412","0","0.1100359999986831","10","","15689.9755859375","0","0","0"
"aten::nll_loss_backward","67.17784300000383","5.593961999997729","1.9567100000034552","0.3510019999858923","10","","15689.9755859375","15689.9755859375","0","0"
"cudaMalloc","0","216.38443900003145","0","216.38443900003145","72","","0","0","0","0"
"aten::zero_","206.22203599999054","12.173111000009113","0","0.8533960000190418","184","","0","0","0","0"
"autograd::engine::evaluate_function: LogSoftmaxBackward0","245.39736899999411","4.93367399999965","0","0.3023349999948405","10","","-15689.9755859375","-31379.951171875","0","0"
"LogSoftmaxBackward0","245.39736899999411","4.631339000004809","0","0.08176000001165085","10","","15689.9755859375","0","0","0"
"aten::_log_softmax_backward_data","245.39736899999411","4.549578999993159","245.39736899999411","0.2371049999962561","10","","15689.9755859375","15689.9755859375","0","0"
"autograd::engine::evaluate_function: ViewBackward0","0","21.477204000011785","0","9.380623000040417","1470","","0","0","0","0"
"ViewBackward0","0","12.096580999971367","0","4.654646999909775","1470","","0","0","0","0"
"autograd::engine::evaluate_function: CloneBackward0","0","0.07490200000465848","0","0.0681280000086408","10","","0","0","0","0"
"CloneBackward0","0","0.006773999996017664","0","0.006773999996017664","10","","0","0","0","0"
"autograd::engine::evaluate_function: SliceBackward0","416.75258699999193","199.0860800000003","0","0.2124980000006035","20","","15.3369140625","-31379.951171875","0","0"
"SliceBackward0","416.75258699999193","198.87358199999971","0","0.08528700000443495","20","","31395.2880859375","0","0","0"
"aten::slice_backward","416.75258699999193","198.78829499999526","0","0.28966199998511","20","","31395.2880859375","0","0","0"
"aten::zeros","135.0719159999953","207.41353400000673","0","0.2992180000108201","54","","32900.9931640625","0","0","0"
"autograd::engine::evaluate_function: UnsafeViewBackward0","0","0.15028599999751896","0","0.06158000000240281","10","","0","0","0","0"
"UnsafeViewBackward0","0","0.08870599999511615","0","0.03123399998806417","10","","0","0","0","0"
"autograd::engine::evaluate_function: MmBackward0","1064.1388399999946","1.6384700000023005","0","0.16803700000606478","10","","-14232.939453125","-15945.3125","0","0"
"MmBackward0","1064.1388399999946","1.4704329999962356","0","0.1587060000007041","10","","1712.373046875","0","0","0"
"autograd::engine::evaluate_function: TBackward0","0","0.14818999999621882","0","0.06848300000140443","10","","0","0","0","0"
"TBackward0","0","0.0797069999948144","0","0.017545999991940335","10","","0","0","0","0"
"autograd::engine::evaluate_function: NativeLayerNormBackward0","184.9277949999962","26.26320800001244","0","5.907513000002364","250","","-11774.4482421875","-17775.9130859375","0","0"
"NativeLayerNormBackward0","136.10796299999325","16.14774300001422","0","1.93677599999425","250","","6001.46484375","0","0","0"
"aten::native_layer_norm_backward","136.10796299999325","14.21096700001997","136.10796299999325","4.822406999997562","250","","6001.46484375","0","0","0"
"autograd::engine::evaluate_function: torch::autograd::AccumulateGrad","2218.988751000047","80.50063500004612","0","21.649853000065313","1480","","0","0","0","0"
"torch::autograd::AccumulateGrad","0","11.458877999999094","0","4.314792999982368","1480","","0","0","0","0"
"aten::detach","0","7.696890000014566","0","2.7209639999787325","1629","","0","0","0","0"
"detach","0","4.975926000035834","0","4.975926000035834","1629","","0","0","0","0"
"torch::distributed::reducer::mul_out","26.78929500002158","31.073683999935863","0","2.8426229999111965","1480","","0","0","0","0"
"autograd::engine::evaluate_function: AddBackward0","0.3123219999962021","4.109892000051215","0","3.2971120000577065","490","","30","0","0","0"
"AddBackward0","0","0.5230469999958295","0","0.5230469999958295","490","","0","0","0","0"
"autograd::engine::evaluate_function: AddmmBackward0","2720.4986809999345","89.41060699999286","0","11.430632999993861","480","","-16307.0517578125","-39744","0","0"
"AddmmBackward0","2607.5009319999645","56.158962000001225","0","5.857856999980519","480","","23433.7841796875","0","0","0"
"aten::sum","125.28754699997371","24.31697599999164","125.28754699997371","16.765163000026487","610","","78.1640625","78.1640625","0","0"
"c10d::allreduce_","2192.1994560000253","16.31822000004584","0","4.452973000053084","130","","0","0","0","0"
"nccl:all_reduce","0","8.933768000006443","0","0","134","","0","0","0","0"
"autograd::engine::evaluate_function: MulBackward0","770.493684999954","21.953695999962044","0","5.440578999959631","480","","-11520.8642578125","-69120.8642578125","-0.00274658203125","-0.00274658203125"
"MulBackward0","614.1933749999455","14.987195000000066","0","1.985117000009166","480","","57600","0","0","0"
"autograd::engine::evaluate_function: TanhBackward0","157.0701969999932","4.431499000009615","0","1.0691990000053775","120","","-11520","-23040","0","0"
"TanhBackward0","157.0701969999932","3.3623000000042373","0","0.5847640000111424","120","","11520","0","0","0"
"aten::tanh_backward","157.0701969999932","2.7775359999930953","157.0701969999932","1.7338839999956543","120","","11520","11520","0","0"
"autograd::engine::evaluate_function: PowBackward0","521.2848090000083","13.49349499999336","0","2.14552799998573","120","","-23040","-34560","0","0"
"PowBackward0","367.43365800001214","9.371857000003336","0","1.0719009999877307","120","","11520","-23040","0","0"
"aten::add_","358.9712930000075","9.201120000006398","358.9712930000075","5.908867000001716","1960","","0","0","0","0"
"autograd::engine::evaluate_function: TransposeBackward0","0","1.8757929999970366","0","0.7207309999915306","120","","0","0","0","0"
"TransposeBackward0","0","1.155062000005506","0","0.2609760000174865","120","","0","0","0","0"
"autograd::engine::evaluate_function: ScaledDotProductEfficientAttentionBackward0","969.5034239999754","565.6529469999983","0","2.376691999982344","120","","2835","-5805","-0.0018310546875","-0.0018310546875"
"ScaledDotProductEfficientAttentionBackward0","969.5034239999754","563.2762550000159","0","1.2073380000249017","120","","8640","0","0","0"
"aten::_scaled_dot_product_efficient_attention_backward","969.5034239999754","562.0689169999911","0","2.8586909999966155","120","","8640","0","0","0"
"aten::_efficient_attention_backward","969.5034239999754","556.0093549999903","918.374541","5.334792000020621","120","","8640","-5853.0771484375","0","0"
"cudaFuncGetAttributes","0","0.6304429999964778","0","0.6304429999964778","120","","0","0","0","0"
"autograd::engine::evaluate_function: PermuteBackward0","0","5.123437000013655","0","2.1183800000241026","360","","0","0","0","0"
"PermuteBackward0","0","3.0050569999895522","0","1.0559349999830592","360","","0","0","0","0"
"autograd::engine::evaluate_function: SplitBackward0","73.90596599998372","5.866949000001885","0","1.144517999999458","120","","0","-8640","0","0"
"SplitBackward0","73.90596599998372","4.722431000002427","0","0.5137620000177995","120","","8640","0","0","0"
"autograd::engine::evaluate_function: EmbeddingBackward0","29.679410999960265","5.795295000006212","0","0.36824300000979565","20","","-240.078125","-3214.82421875","0","0"
"EmbeddingBackward0","10.333898999961326","5.2108389999980576","0","0.08474200000311248","20","","1502.373046875","0","0","0"
"aten::embedding_backward","10.333898999961326","5.126096999994945","0","0.07624899999727495","20","","1502.373046875","0","0","0"
"aten::embedding_dense_backward","10.333898999961326","5.04984799999767","4.75630999996583","1.553031000001356","20","","1502.373046875","-268.4423828125","0","0"
"cudaDeviceGetAttribute","0","0.03264499999419786","0","0.03264499999419786","50","","0","0","0","0"
"cudaPeekAtLastError","0","0.02670399998128414","0","0.02670399998128414","170","","0","0","0","0"
"torch.distributed.ddp.reducer::copy_bucket_to_grad","58.31200299998163","522.6386759999643","0","2.902787999985274","1480","","0","0","0","0"
"aten::_foreach_norm","20.6279440000169","73.37096599999909","20.608487000013238","5.756986999993212","10","","0.72265625","-2.607421875","0","0"
"aten::stack","0.051298000009730456","20.09181099999952","0","1.7385559999388642","10","","0.009765625","0","0","0"
"aten::linalg_vector_norm","0.04169600000744685","10.486948000002652","0.04169600000744685","0.3200639999965206","10","","0.0048828125","0.0048828125","0","0"
"aten::reciprocal","0.018559999999124558","10.423799999998883","0.018559999999124558","0.16202499999757855","10","","0.0048828125","0.0048828125","0","0"
"aten::clamp","0.01977500000037253","0.5930130000002682","0.01977500000037253","0.1976339999961201","10","","0.0048828125","0.0048828125","0","0"
"aten::_foreach_mul_","128.60548499999427","174.022084999986","128.60548499999427","4.198086000066017","30","","0","0","0","0"
"Optimizer.step#AdamW.step","420.42649700002374","452.35839400000265","0","23.216573999960442","10","","0","-4748.603515625","0","-0.00003814697265625"
"aten::lift_fresh","0","0.004699999997392297","0","0.004699999997392297","10","","0","0","0","0"
"aten::detach_","0","0.035097999995807184","0","0.021372999995946884","10","","0","0","0","0"
"detach_","0","0.013724999999860302","0","0.013724999999860302","10","","0","0","0","0"
"aten::_foreach_add_","42.76729500000365","56.76443300000182","42.76729500000365","3.6091400000303984","20","","0","0","0","0"
"aten::_foreach_lerp_","62.98644100000989","43.78149200000544","62.98644100000989","0.6095269999988377","10","","0","0","0","0"
"aten::_foreach_addcmul_","62.97498299999861","51.02969499999518","62.97498299999861","1.8906579999872484","10","","0","0","0","0"
"aten::item","0.025089999998919667","3633.945534000041","0","3.070613999936031","2974","","0","0","0","0"
"aten::_local_scalar_dense","0.025089999998919667","3630.874920000105","0.025089999998919667","1.0516970001109875","2974","","0","0","0","0"
"aten::_foreach_sqrt","42.60866600001883","47.871268000001784","42.60866600001883","3.751848999993177","10","","4748.603515625","0","0","0"
"aten::_foreach_div_","42.62456899999967","58.681178000003335","42.62456899999967","1.6668500000087079","10","","0","0","0","0"
"aten::_foreach_addcdiv_","80.39888699999871","47.245054","80.39888699999871","2.1956810000084808","10","","0","0","0","0"
"nccl:all_reduce","2192.2337920000236","0","2192.2337920000236","0","134","","0","0","0","0"
"Optimizer.step#AdamW.step","420.8206960000014","0","420.8206960000014","0","10","","0","0","0","0"
"c10d::barrier","0.04019199999794364","1.1081959999995306","0","0.15446699999924748","4","","0.001953125","0","0","0"
"cudaDeviceSynchronize","0","955.4424699999997","0","955.3099960000338","7","","0","0","0","0"
"cudaHostAlloc","0","2.4281910000024363","0","2.3703920000027865","19","","-47.90625","-47.9375","0","0"
"Memcpy DtoH (Device -> Pinned)","0.025089999998919667","0","0.025089999998919667","0","13","","0","0","0","0"
"aten::random_","0","0.011908999999985098","0","0.011908999999985098","1","","0","0","0","0"
"aten::set_","0","1.366563999991864","0","1.366563999991864","296","","0","0","0","0"
"Memcpy DtoH (Device -> Pageable)","143.85144099999778","0","143.85144099999778","0","148","","0","0","0","0"
"aten::native_dropout","15.024877999968826","110.45714500000514","15.024877999968826","2.590692000042647","100","","3000.7626953125","0","0","0"
"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)","15.024877999968826","0","15.024877999968826","0","100","","0","0","0","0"
"aten::scalar_tensor","0","0.29702200001105666","0","0.29702200001105666","96","","0","0","0.000732421875","0.000732421875"
"autograd::engine::evaluate_function: NativeDropoutBackward0","11.923181000012905","4.797645000003278","0","0.8045249999873341","100","","1703.2373046875","-696.7626953125","0","0"
"NativeDropoutBackward0","11.923181000012905","3.9931200000159444","0","0.39371899999678134","100","","2400","0","0","0"
"aten::native_dropout_backward","11.923181000012905","3.5994010000191627","11.923181000012905","1.2763159999921918","100","","2400","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)","11.923181000012905","0","11.923181000012905","0","100","","0","0","0","0"
"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)","394.5719590000026","0","394.5719590000026","0","48","","0","0","0","0"