"Name","Device Time Total (ms)","CPU Time Total (ms)","Self Device Time Total (ms)","Self CPU Time Total (ms)","Calls","Input Shapes","Device Memory Usage (MB)","Self Device Memory Usage (MB)","CPU Memory Usage (MB)","Self CPU Memory Usage (MB)"
"ProfilerStep*","7850.783537999997","19698.535031999996","0","6287.012560000017","10","","1.0380859375","-137518.45947265625","0","-0.0045928955078125"
"enumerate(DataLoader)#_MultiProcessingDataLoaderIter.__next__","0","12.14515299999819","0","11.64871499999904","21","","0","0","0","0"
"Memset (Device)","2.548845000108995","0","2.548845000108995","0","1826","","0","0","0","0"
"ampere_sgemm_128x64_nn","211.40608400002156","0","211.40608400002156","0","242","","0","0","0","0"
"aten::to","19.300964999994846","7286.931545999972","0","0.6559669999745674","2190","","2.5","0","0","0"
"aten::_to_copy","19.300964999994846","7286.275578999997","0","0.8176639999881153","40","","2.5","0","0","0"
"aten::empty_strided","0","17.46061499997183","0","15.718077999963906","1730","","7752.748046875","7752.748046875","0","0"
"aten::copy_","742.0645669998995","7903.356934999979","723.0930449999033","14.824890999904252","2088","","0","0","0","0"
"cudaMemcpyAsync","0","604.7003070000674","0","604.6889960000666","1931","","0","0","0","0"
"cudaStreamSynchronize","18.971521999996156","11363.376107000011","0","11361.665744999973","205","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)","853.9259530000123","0","853.9259530000123","0","1265","","0","0","0","0"
"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)","59.91687300000129","0","59.91687300000129","0","504","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_256x128_8x4_nn_align1>(cutlass_80_simt_sgemm_256x128_8x4_nn_align1::Params)","1968.076373000012","0","1968.076373000012","0","494","","0","0","0","0"
"cudaPointerGetAttributes","0.8668799999989569","0.2925039999989349","0.8668799999989569","0.28947200000114026","56","","24.0625","24.0625","-0.0000152587890625","-0.0000152587890625"
"void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)","1089.7741229999913","0","1089.7741229999913","0","2893","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#2}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#2}, at::detail::Array<char*, 2>)","208.6446070000119","0","208.6446070000119","0","242","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::tanh_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::tanh_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)","208.93619000000396","0","208.93619000000396","0","242","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<float>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<float>, at::detail::Array<char*, 2>)","208.58442199998407","0","208.58442199998407","0","253","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)","856.2550259999903","0","856.2550259999903","0","770","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_128x64_8x5_nn_align1>(cutlass_80_simt_sgemm_128x64_8x5_nn_align1::Params)","817.8856930000078","0","817.8856930000078","0","242","","0","0","0","0"
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)","580.3780110000248","0","580.3780110000248","0","241","","0","0","0","0"
"ampere_sgemm_128x128_tn","1772.4632959999988","0","1772.4632959999988","0","21","","0","0","0","0"
"cudaEventQuery","18.1046419999972","2.4463000000499595","18.1046419999972","2.4452860000495273","1072","","-101.99951171875","-101.99951171875","0.00000762939453125","0.00000762939453125"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})","465.86327699999174","0","465.86327699999174","0","164","","0","0","0","0"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1} const&)::{lambda(int)#1})","0.1315510000004724","0","0.1315510000004724","0","21","","0","0","0","0"
"void at::native::(anonymous namespace)::cunn_SoftMaxForward<4, float, float, float, at::native::(anonymous namespace)::LogSoftMaxForwardEpilogue>(float*, float const*, int)","298.15356400000076","0","298.15356400000076","0","21","","0","0","0","0"
"void at::native::(anonymous namespace)::nll_loss_forward_reduce_cuda_kernel_2d<float, float, long>(float*, float*, float const*, long const*, float const*, bool, long, long, long, long)","7.292030999998591","0","7.292030999998591","0","21","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)","220.5321359999946","0","220.5321359999946","0","81","","0","0","0","0"
"void at::native::(anonymous namespace)::nll_loss_backward_reduce_cuda_kernel_2d<float, long>(float*, float const*, long const*, float const*, float const*, bool, int, int, long, long)","2.138207999997714","0","2.138207999997714","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::cunn_SoftMaxBackward<4, float, float, float, at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue>(float*, float const*, float const*, long)","268.08365699999916","0","268.08365699999916","0","11","","0","0","0","0"
"Memcpy DtoD (Device -> Device)","203.82015099991872","0","203.82015099991872","0","1879","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_128x256_8x4_nt_align1>(cutlass_80_simt_sgemm_128x256_8x4_nt_align1::Params)","807.5529740000127","0","807.5529740000127","0","143","","0","0","0","0"
"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)","69.5040590000124","0","69.5040590000124","0","275","","0","0","0","0"
"void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)","78.62217599998554","0","78.62217599998554","0","275","","0","0","0","0"
"ampere_sgemm_128x64_tn","1403.6000890000014","0","1403.6000890000014","0","528","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_128x64_8x5_nt_align1>(cutlass_80_simt_sgemm_128x64_8x5_nt_align1::Params)","819.5971590000003","0","819.5971590000003","0","396","","0","0","0","0"
"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)","122.18145200004021","0","122.18145200004021","0","539","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::tanh_backward_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::tanh_backward_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)","170.7731800000189","0","170.7731800000189","0","132","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#1}, at::detail::Array<char*, 2>)","113.49704399999516","0","113.49704399999516","0","132","","0","0","0","0"
"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)","11.998592000007863","0","11.998592000007863","0","132","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<unsigned char>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<unsigned char>, at::detail::Array<char*, 1>)","5.997827999991772","0","5.997827999991772","0","132","","0","0","0","0"
"fmha_cutlassB_f32_aligned_64x64_k64_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, false, false, 64, 64, 64, false>::Params)","559.6628360000038","0","559.6628360000038","0","84","","0","0","0","0"
"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 3, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)","81.02044000001379","0","81.02044000001379","0","132","","0","0","0","0"
"void at::native::(anonymous namespace)::embedding_backward_feature_kernel<float, float, long>(long const*, float const*, float*, int, long, int)","0.41139100000425244","0","0.41139100000425244","0","11","","0","0","0","0"
"void (anonymous namespace)::elementwise_kernel_with_index<int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}, function_traits<at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>::result_type*)","0.06125100000132806","0","0.06125100000132806","0","31","","0","0","0","0"
"void at_cuda_detail::cub::DeviceRadixSortHistogramKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy800, false, long, unsigned long long>(unsigned long long*, long const*, unsigned long long, int, int)","0.0845769999929471","0","0.0845769999929471","0","11","","0","0","0","0"
"void at_cuda_detail::cub::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy800, unsigned long long>(unsigned long long*)","0.024350999997463076","0","0.024350999997463076","0","11","","0","0","0","0"
"void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy800, false, long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long, int, int>(int*, int*, unsigned long long*, unsigned long long const*, long*, long const*, at::cuda::cub::detail::OpaqueType<8>*, at::cuda::cub::detail::OpaqueType<8> const*, int, int, int)","0.9696030000046594","0","0.9696030000046594","0","88","","0","0","0","0"
"void at_cuda_detail::cub::DeviceCompactInitKernel<at_cuda_detail::cub::ScanTileState<int, true>, long*>(at_cuda_detail::cub::ScanTileState<int, true>, int, long*)","0.04816099999996368","0","0.04816099999996368","0","11","","0","0","0","0"
"void at_cuda_detail::cub::DeviceUniqueByKeySweepKernel<at_cuda_detail::cub::DeviceUniqueByKeyPolicy<long const*>::Policy520, long const*, thrust::counting_iterator<int, thrust::use_default, thrust::use_default, thrust::use_default>, long*, long*, long*, at_cuda_detail::cub::ScanTileState<int, true>, at_cuda_detail::cub::Equality, int>(long const*, thrust::counting_iterator<int, thrust::use_default, thrust::use_default, thrust::use_default>, long*, long*, long*, at_cuda_detail::cub::ScanTileState<int, true>, at_cuda_detail::cub::Equality, int, int)","0.07158400000375696","0","0.07158400000375696","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::krn_partials_per_segment<long>(long*, long const*, long const*, long)","0.026623000003397464","0","0.026623000003397464","0","11","","0","0","0","0"
"void at_cuda_detail::cub::DeviceScanInitKernel<at_cuda_detail::cub::ScanTileState<long, true> >(at_cuda_detail::cub::ScanTileState<long, true>, int)","0.01775999999931082","0","0.01775999999931082","0","11","","0","0","0","0"
"void at_cuda_detail::cub::DeviceScanKernel<at_cuda_detail::cub::DeviceScanPolicy<long>::Policy600, long const*, long*, at_cuda_detail::cub::ScanTileState<long, true>, at::cuda::cub::(anonymous namespace)::SumOp<long>, at_cuda_detail::cub::detail::InputValue<long, long*>, int, long>(long const*, long*, at_cuda_detail::cub::ScanTileState<long, true>, int, at::cuda::cub::(anonymous namespace)::SumOp<long>, at_cuda_detail::cub::detail::InputValue<long, long*>, int)","0.04889599999843631","0","0.04889599999843631","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::compute_num_of_partial_segments<long>(long const*, long const*, long const*, long*)","0.023199999999953435","0","0.023199999999953435","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::krn_partial_segment_offset<long>(long*, long const*, long const*, long const*, long const*)","0.048639000004855916","0","0.048639000004855916","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::compute_grad_weight<float, long>(long const*, float const*, long const*, long, long, long const*, long const*, at::AccumulateType<float, true>::type*, long)","2.1611529999974883","0","2.1611529999974883","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::sum_and_scatter<float, long>(long const*, float*, long, long const*, long const*, at::AccumulateType<float, true>::type const*, long const*, long const*, long, long)","0.943328000000678","0","0.943328000000678","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::LpNormFunctor<float, (at::native::NormType)1, float, 1, 1, 0>, float*, int>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::LpNormFunctor<float, (at::native::NormType)1, float, 1, 1, 0>, float*, int)","22.64908900000283","0","22.64908900000283","0","77","","0","0","0","0"
"void at::native::lpnorm_cleanup<float, (at::native::NormType)1, float, float>(float const*, at::native::TensorListAddresses, int)","0.053279000004287806","0","0.053279000004287806","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)","0.08691199999535457","0","0.08691199999535457","0","32","","0","0","0","0"
"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::NormTwoOps<float, float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::NormTwoOps<float, float, float>, unsigned int, float, 4>)","0.051040000005741604","0","0.051040000005741604","0","11","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::reciprocal_kernel_cuda(at::TensorIteratorBase&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::reciprocal_kernel_cuda(at::TensorIteratorBase&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)","0.022812999995774588","0","0.022812999995774588","0","11","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)","0.024447000004234724","0","0.024447000004234724","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarTensorFunctor<float, 1, 1, 0>, std::multiplies<float>, float*, float>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarTensorFunctor<float, 1, 1, 0>, std::multiplies<float>, float*, float)","46.71971900000633","0","46.71971900000633","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::multiplies<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::multiplies<float>, float)","95.00665799999109","0","95.00665799999109","0","154","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::TernaryOpScalarFunctor<float, 2, 2, 0>, at::native::LerpFunctor<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::TernaryOpScalarFunctor<float, 2, 2, 0>, at::native::LerpFunctor<float>, float)","69.44130499999493","0","69.44130499999493","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<3>, at::native::(anonymous namespace)::PointwiseOpScalarFunctor<float, 3, 3, 0>, std::multiplies<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<3>, at::native::(anonymous namespace)::PointwiseOpScalarFunctor<float, 3, 3, 0>, std::multiplies<float>, float)","69.380002000008","0","69.380002000008","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::UnaryOpFunctor<float, 2, 1, 1>, at::native::Sqrt<float> >(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::UnaryOpFunctor<float, 2, 1, 1>, at::native::Sqrt<float>)","46.91619599999359","0","46.91619599999359","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 1>, at::native::(anonymous namespace)::BinaryOpScalarListFunctor<float, 1, 1, 0>, std::divides<float> >(at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 1>, at::native::(anonymous namespace)::BinaryOpScalarListFunctor<float, 1, 1, 0>, std::divides<float>)","47.03247199999192","0","47.03247199999192","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::plus<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::plus<float>, float)","47.06345199999073","0","47.06345199999073","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 3>, at::native::(anonymous namespace)::PointwiseOpScalarListFunctor<float, 3, 3, 0>, std::divides<float> >(at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 3>, at::native::(anonymous namespace)::PointwiseOpScalarListFunctor<float, 3, 3, 0>, std::divides<float>)","88.54335899999843","0","88.54335899999843","0","77","","0","0","0","0"
"ProfilerStep*","19271.577260000002","0","19271.577260000002","0","10","","0","0","0","0"
"Memcpy HtoD (Pinned -> Device)","0.32944299999868965","0","0.32944299999868965","0","40","","0","0","0","0"
"DistributedDataParallel.forward","7246.724424000032","492.1393750000028","0","135.6785139999625","20","","137522.2314453125","-210384.97802734375","0.00457763671875","0.0027618408203125"
"cudaEventSynchronize","0.20140799999982117","0.016771000000298953","0.20140799999982117","0.016771000000298953","8","","0","0","0","0"
"cudaEventElapsedTime","0","0.00855600000009872","0","0.00855600000009872","4","","0","0","0","0"
"aten::flatten_dense_tensors","1.0180469999983908","3.180676000001491","0","0.6135799999750452","20","","120.0048828125","0","0","0"
"aten::view","0","18.96908900005405","0","18.96908900005405","6520","","0","0","0","0"
"aten::cat","74.72453800000902","20.82319999999204","74.72453800000902","4.5411439999904255","150","","8760.0146484375","8760.0146484375","0","0"
"cudaLaunchKernel","0","747.7343660000749","0","747.6413880000669","11334","","0","0","0","0"
"DistributedDataParallel.forward","7363.300035","0","7363.300035","0","20","","0","0","0","0"
"void at::native::(anonymous namespace)::CatArrayBatchedCopy_contig<at::native::(anonymous namespace)::OpaqueType<1u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<1u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<1u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)","0.9925759999997681","0","0.9925759999997681","0","10","","0","0","0","0"
"c10d::broadcast_","0","2.713864999999059","0","0.924445999999647","20","","0","0","0","0"
"record_param_comms","0.006143000001087784","640.5003489999892","0","9.317022999985841","178","","0.001953125","0","0","0"
"cudaStreamIsCapturing","0","1.112108999956865","0","1.112108999956865","828","","0","0","0","0"
"cudaEventRecord","0","0.9892200000149897","0","0.9892200000149897","486","","0","0","0","0"
"cudaStreamWaitEvent","0","0.6699929999992018","0","0.6699929999992018","308","","0","0","0","0"
"nccl:broadcast","0","1.0182939999968512","0","0","20","","0","0","0","0"
"aten::unflatten_dense_tensors","0","3.258542999999947","0","0.8521699999952689","20","","0","0","0","0"
"aten::narrow","0","7.352763999998221","0","2.8012049999504818","960","","0","0","0","0"
"aten::slice","0","5.143925000036135","0","3.8622920000241137","1040","","0","0","0","0"
"aten::as_strided","0","9.389124999959254","0","9.389124999959254","8650","","0","0","0","0"
"aten::arange","0.11789400000264869","3.9455050000055927","0.05894700000132434","0.7510319999997737","60","","1.5625","0","0","0"
"aten::empty","0","204.19837099989994","0","33.48177399989637","4379","","102355.8291015625","102355.7666015625","0.00296783447265625","0.00296783447265625"
"aten::resize_","0","0.7661809999921825","0","0.6488009999918286","90","","540.78125","540.78125","0","0"
"aten::unsqueeze","0","3.273282999961055","0","2.5864050000262213","1500","","0","0","0","0"
"aten::embedding","3.5872000000005353","3.263677999995649","0","0.7295919999963371","40","","540","0","0","0"
"aten::reshape","0","8.921313999980223","0","4.387591999947326","1540","","0","0","0","0"
"aten::index_select","3.5872000000005353","2.278398000008543","3.5872000000005353","1.0103800000116463","40","","540","0","0","0"
"void at::native::(anonymous namespace)::indexSelectLargeIndex<float, long, unsigned int, 2, 2, -2, true>(at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<long const, unsigned int>, int, int, unsigned int, unsigned int, long)","3.5872000000005353","0","3.5872000000005353","0","40","","0","0","0","0"
"aten::add","663.8703079999783","29.696645000007933","663.8703079999783","19.71803299996501","1000","","59552.3779296875","59552.3779296875","0","0"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})","1.8407089999930468","0","1.8407089999930468","0","20","","0","0","0","0"
"aten::dropout","15.072865999981762","99.77902299999387","0","0.777475999995484","500","","3000.2880859375","0","0","0"
"aten::layer_norm","59.44138500000129","37.89013600001344","0","2.461520999974338","500","","12015.65625","-15.59375","0","0"
"aten::native_layer_norm","59.44138500000129","35.42861500003911","59.44138500000129","15.982590999996988","500","","12031.25","0","0","0"
"aten::addmm","2343.980478000056","66.2001680000195","2343.980478000056","42.04165400002792","960","","51840","51790","0","0"
"cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags","0","2.372309999999241","0","2.372309999999241","1240","","0","0","0","0"
"cudaFuncSetAttribute","0","518.2878209999986","0","518.2878209999986","740","","0","0","0","0"
"aten::split","0","8.023454999997513","0","2.628878000013763","240","","0","0","0","0"
"aten::permute","0","6.36146800003387","0","5.334694000020274","1080","","0","0","0","0"
"aten::scaled_dot_product_attention","578.0665550000249","28.919586000018054","0","4.493931000014301","240","","5805.2880859375","0","0.0018310546875","-0.0018310546875"
"aten::_scaled_dot_product_efficient_attention","578.0665550000249","24.420207000002847","0","4.830094999997062","240","","5805.2880859375","0","0.003662109375","0"
"aten::transpose","0","15.010075999911642","0","10.963003999885753","3420","","0","0","0","0"
"aten::_efficient_attention_forward","578.0665550000249","15.887642000015243","578.0665550000249","6.338982000054908","240","","5805.2880859375","0","0.003662109375","0.00000762939453125"
"cudaMemsetAsync","0","12.477657000002568","0","12.477657000002568","1680","","0","0","0","0"
"cudaOccupancyMaxActiveBlocksPerMultiprocessor","0","1.4109639999972423","0","1.4109639999972423","720","","0","0","0","0"
"aten::mul","1845.6816509999812","88.62363499994797","1845.6816509999812","47.94796599997417","3410","","175680.0048828125","175680.0048828125","0","0"
"aten::pow","310.08795800000684","12.850582999978215","310.08795800000684","8.405087999950744","360","","34560","34560","0","0"
"aten::result_type","0","1.0683870000428288","0","1.0683870000428288","9240","","0","0","0","0"
"aten::tanh","207.20223800000397","5.982451000006171","207.20223800000397","3.9895620000177296","240","","23040","23040","0","0"
"aten::linear","1686.601009999999","2.452779000004055","0","0.12285600000142585","20","","31410.625","0","0","0"
"aten::t","0","8.929064000065788","0","3.7608690000738716","1020","","0","0","0","0"
"aten::matmul","1686.601009999999","2.064059000004316","0","0.3139299999981886","20","","31410.625","0","0","0"
"aten::mm","5021.750549000039","45.071042999965485","5021.750549000039","28.346683999987086","1000","","56555.7314453125","56555.7314453125","0","0"
"aten::_unsafe_view","0","0.13522300000244286","0","0.13522300000244286","20","","0","0","0","0"
"aten::contiguous","290.2669729999967","6.93449200000288","0","0.33160400001436935","160","","31426.201171875","0","0","0"
"aten::clone","290.2669729999967","6.602887999988511","0","0.828693999981042","160","","31426.201171875","0","0","0"
"aten::empty_like","0","8.377240000008955","0","1.9253090000224766","490","","36827.744140625","0","0","0"
"aten::cross_entropy_loss","290.9023979999993","2.555223000000231","0","0.22635200000053737","20","","15689.990234375","-15689.9755859375","0","0"
"aten::log_softmax","283.95478300000076","1.292597999995458","0","0.12904199999407864","20","","31379.951171875","0","0","0"
"aten::_log_softmax","283.95478300000076","1.155239000000991","283.95478300000076","0.6198740000003018","20","","31379.951171875","31379.951171875","0","0"
"aten::nll_loss_nd","6.947614999998594","1.0362730000042357","0","0.08956800000648946","20","","0.0146484375","0","0","0"
"aten::nll_loss","6.947614999998594","0.9467049999977462","0","0.12103199999418575","20","","0.0146484375","-0.0048828125","0","0"
"aten::nll_loss_forward","6.947614999998594","0.8256730000035605","6.947614999998594","0.5869249999981839","20","","0.01953125","0.01953125","0","0"
"cudaFree","0","781.4642209999944","0","781.4503679999943","80","","0","0","0","0"
"aten::ones_like","0.027294999997131527","0.7541470000005793","0","0.07166199999838137","10","","0.0048828125","0","0","0"
"aten::fill_","206.43566399998636","10.833504000010434","206.43566399998636","1.7698289999950212","194","","0","0","0","0"
"autograd::engine::evaluate_function: NllLossBackward0","66.80527399999438","4.952680999998934","0","0.3649050000028219","10","","15689.345703125","-0.6298828125","0","0"
"NllLossBackward0","66.80527399999438","4.587775999996112","0","0.14255099999601953","10","","15689.9755859375","0","0","0"
"aten::nll_loss_backward","66.80527399999438","4.445225000000093","1.9521279999976977","0.439115000000922","10","","15689.9755859375","15689.9755859375","0","0"
"cudaMalloc","0","187.8380230000161","0","187.8380230000161","80","","0","0","0","0"
"aten::zero_","206.40836899998925","11.330792999991449","0","0.8950839999818708","184","","0","0","0","0"
"autograd::engine::evaluate_function: LogSoftmaxBackward0","244.2534539999992","4.913057000002358","0","0.3705400000042282","10","","-15689.9755859375","-31379.951171875","0","0"
"LogSoftmaxBackward0","244.2534539999992","4.54251699999813","0","0.08822399999643676","10","","15689.9755859375","0","0","0"
"aten::_log_softmax_backward_data","244.2534539999992","4.454293000001693","244.2534539999992","0.2275520000020042","10","","15689.9755859375","15689.9755859375","0","0"
"autograd::engine::evaluate_function: ViewBackward0","0","23.628582999949344","0","9.754747999909334","1470","","0","0","0","0"
"ViewBackward0","0","13.87383500004001","0","5.295861000061268","1470","","0","0","0","0"
"autograd::engine::evaluate_function: CloneBackward0","0","0.0784030000034254","0","0.0688280000037048","10","","0","0","0","0"
"CloneBackward0","0","0.009574999999720604","0","0.009574999999720604","10","","0","0","0","0"
"autograd::engine::evaluate_function: SliceBackward0","419.2656339999931","172.40900200000104","0","0.20623399999947287","20","","15.3369140625","-31379.951171875","0","0"
"SliceBackward0","419.2656339999931","172.20276800000156","0","0.10400800000247545","20","","31395.2880859375","0","0","0"
"aten::slice_backward","419.2656339999931","172.0987599999991","0","0.5925150000012945","20","","31395.2880859375","0","0","0"
"aten::zeros","136.09262800000096","179.42983199999878","0","0.3637470000118483","54","","32900.9931640625","0","0","0"
"autograd::engine::evaluate_function: UnsafeViewBackward0","0","0.1948599999998696","0","0.08865099999774248","10","","0","0","0","0"
"UnsafeViewBackward0","0","0.10620900000212714","0","0.03984100000257604","10","","0","0","0","0"
"autograd::engine::evaluate_function: MmBackward0","976.1800840000037","1.802585999999661","0","0.18355499999853783","10","","-14232.939453125","-15945.3125","0","0"
"MmBackward0","976.1800840000037","1.6190310000011232","0","0.1889090000160504","10","","1712.373046875","0","0","0"
"autograd::engine::evaluate_function: TBackward0","0","0.15844699999806472","0","0.08018299999926239","10","","0","0","0","0"
"TBackward0","0","0.07826399999880232","0","0.01974599999189377","10","","0","0","0","0"
"autograd::engine::evaluate_function: NativeLayerNormBackward0","184.0657580000025","27.684231000010854","0","6.178622000003466","250","","-11774.16015625","-17775.625","0","0"
"NativeLayerNormBackward0","134.64412599999736","17.117567999994616","0","2.133610999991186","250","","6001.46484375","0","0","0"
"aten::native_layer_norm_backward","134.64412599999736","14.983957000003429","134.64412599999736","5.111182000039145","250","","6001.46484375","0","0","0"
"autograd::engine::evaluate_function: torch::autograd::AccumulateGrad","26.02470999997086","78.86662499989895","0","22.585653999793344","1480","","0","0","0","0"
"torch::autograd::AccumulateGrad","0","11.907193000035127","0","4.809987000016263","1480","","0","0","0","0"
"aten::detach","0","7.656281000027433","0","2.714410000027856","1629","","0","0","0","0"
"detach","0","4.941870999999577","0","4.941870999999577","1629","","0","0","0","0"
"torch::distributed::reducer::mul_out","26.02470999997086","31.850495000048774","0","2.940745000054361","1480","","0","0","0","0"
"autograd::engine::evaluate_function: AddBackward0","0.3035199999969918","4.234055999950739","0","3.40393599994597","490","","30.75","0","0","0"
"AddBackward0","0","0.5330029999993275","0","0.5330029999993275","490","","0","0","0","0"
"autograd::engine::evaluate_function: AddmmBackward0","2470.3830090001275","91.07670900000888","0","11.808377999995137","480","","-16308.1025390625","-39744","0","0"
"AddmmBackward0","2358.969455000037","56.812490000003486","0","6.080469999963883","480","","23432.7333984375","0","0","0"
"aten::sum","122.65102500009537","25.09370400001621","122.65102500009537","17.34043299999763","610","","78.9140625","78.9140625","0","0"
"c10d::allreduce_","0","12.523283000021708","0","4.195683000033721","130","","0","0","0","0"
"nccl:all_reduce","0","5.217341999995988","0","0","134","","0","0","0","0"
"autograd::engine::evaluate_function: MulBackward0","763.396882000027","23.012331000024453","0","5.698345000028144","480","","-11520","-69120","-0.00274658203125","-0.00274658203125"
"MulBackward0","608.2820390000209","15.726976000004681","0","2.047180000030203","480","","57600","0","0","0"
"autograd::engine::evaluate_function: TanhBackward0","155.2907830000189","5.107378999995766","0","1.1220299999800045","120","","-11520","-23040","0","0"
"TanhBackward0","155.2907830000189","3.985349000015762","0","0.711832000022754","120","","11520","0","0","0"
"aten::tanh_backward","155.2907830000189","3.273516999993008","155.2907830000189","2.1777469999946186","120","","11520","11520","0","0"
"autograd::engine::evaluate_function: PowBackward0","516.1823309999928","14.285580999977887","0","2.2879799999827517","120","","-23040","-34560","0","0"
"PowBackward0","363.2140509999932","9.87389599999413","0","1.1583620000153314","120","","11520","-23040","0","0"
"aten::add_","357.50475500001085","9.580524000047706","357.50475500001085","6.001955000042916","1960","","0","0","0","0"
"autograd::engine::evaluate_function: TransposeBackward0","0","1.9478420000101906","0","0.7682619999975432","120","","0","0","0","0"
"TransposeBackward0","0","1.1795800000126473","0","0.27561800003657116","120","","0","0","0","0"
"autograd::engine::evaluate_function: ScaledDotProductEfficientAttentionBackward0","888.5544639999733","553.5629400000041","0","2.387106000010623","120","","2834.7119140625","-5805.2880859375","-0.0018310546875","-0.0018310546875"
"ScaledDotProductEfficientAttentionBackward0","888.5544639999733","551.1758339999935","0","1.319266999997897","120","","8640","0","0","0"
"aten::_scaled_dot_product_efficient_attention_backward","888.5544639999733","549.8565669999956","0","2.880402000048896","120","","8640","0","0","0"
"aten::_efficient_attention_backward","888.5544639999733","543.6594339999878","839.2710419999801","7.030816000040388","120","","8640","-5852.8125","0","0"
"cudaFuncGetAttributes","0","0.5899850000026636","0","0.5899850000026636","120","","0","0","0","0"
"autograd::engine::evaluate_function: PermuteBackward0","0","5.393155000004917","0","2.2618639999970327","360","","0","0","0","0"
"PermuteBackward0","0","3.1312910000078844","0","1.1005479999913368","360","","0","0","0","0"
"autograd::engine::evaluate_function: SplitBackward0","73.65074600001401","6.023919000003021","0","1.1803860000020359","120","","0","-8640","0","0"
"SplitBackward0","73.65074600001401","4.843533000000986","0","0.5689460000046529","120","","8640","0","0","0"
"autograd::engine::evaluate_function: EmbeddingBackward0","29.454334000030766","6.173935000000987","0","0.38492299999762325","20","","-240.828125","-3215.57421875","0","0"
"EmbeddingBackward0","10.133405000030994","5.554129000002751","0","0.11214700000546872","20","","1502.373046875","0","0","0"
"aten::embedding_backward","10.133405000030994","5.4419819999972825","0","0.06498500000149943","20","","1502.373046875","0","0","0"
"aten::embedding_dense_backward","10.133405000030994","5.376996999995783","4.579197000027401","1.6902529999627731","20","","1502.373046875","-268.4423828125","0","0"
"cudaDeviceGetAttribute","0","0.04015500000584871","0","0.04015500000584871","50","","0","0","0","0"
"cudaPeekAtLastError","0","0.03148600000492297","0","0.03148600000492297","170","","0","0","0","0"
"torch.distributed.ddp.reducer::copy_bucket_to_grad","43.174139999939364","497.2713660000204","0","3.4058550000409595","1480","","0","0","0","0"
"aten::_foreach_norm","20.657184000008506","71.14562999999569","20.635808000007177","6.086943999992683","10","","0.72265625","-2.607421875","0","0"
"aten::stack","0.0557449999966193","19.55724199999799","0","1.6911080000330694","10","","0.009765625","0","0","0"
"aten::linalg_vector_norm","0.04614400000567548","10.151238000003854","0.04614400000567548","0.4188740000084508","10","","0.0048828125","0.0048828125","0","0"
"aten::reciprocal","0.02066899999580346","10.294394999999552","0.02066899999580346","0.17937800000212156","10","","0.0048828125","0.0048828125","0","0"
"aten::clamp","0.02211100000422448","0.591035999996122","0.02211100000422448","0.22075599999935366","10","","0.0048828125","0.0048828125","0","0"
"aten::_foreach_mul_","128.85354699999723","172.89661100000188","128.85354699999723","4.339778999981936","30","","0","0","0","0"
"Optimizer.step#AdamW.step","421.2715799999691","457.4105740000021","0","24.84221700008842","10","","0","-4749.955078125","0","-0.00003814697265625"
"aten::lift_fresh","0","0.0064450000044889745","0","0.0064450000044889745","10","","0","0","0","0"
"aten::detach_","0","0.03923099999828264","0","0.021912999995751307","10","","0","0","0","0"
"detach_","0","0.017318000002531336","0","0.017318000002531336","10","","0","0","0","0"
"aten::_foreach_add_","42.778331999990854","58.1092780000004","42.778331999990854","3.4664229999554808","20","","0","0","0","0"
"aten::_foreach_lerp_","63.121147999994925","44.04990600000415","63.121147999994925","0.6306750000040047","10","","0","0","0","0"
"aten::_foreach_addcmul_","63.08489700000803","51.57374700000091","63.08489700000803","1.9024740000439342","10","","0","0","0","0"
"aten::item","0.025248999996110796","3456.1432399999167","0","3.0509729998945256","2974","","0","0","0","0"
"aten::_local_scalar_dense","0.025248999996110796","3453.0922670000223","0.025248999996110796","1.1180890000211074","2974","","0","0","0","0"
"aten::_foreach_sqrt","42.64845299999393","50.2943919999965","42.64845299999393","4.190813000023365","10","","4749.955078125","0","0","0"
"aten::_foreach_div_","42.759672999992034","59.647220000001134","42.759672999992034","1.7188089999754448","10","","0","0","0","0"
"aten::_foreach_addcdiv_","80.49740999999852","46.499527999995976","80.49740999999852","2.290622999988962","10","","0","0","0","0"
"Optimizer.step#AdamW.step","421.7558850000012","0","421.7558850000012","0","10","","0","0","0","0"
"c10d::barrier","0.006143000001087784","1.2402760000005364","0","0.26953799999970945","4","","0.001953125","0","0","0"
"cudaDeviceSynchronize","0","875.5813600000022","0","875.4197629999882","7","","0","0","0","0"
"cudaHostAlloc","0","2.4915419999985025","0","2.4572299999985843","19","","-94.00048828125","-94.00048828125","0","0"
"Memcpy DtoH (Device -> Pinned)","0.025248999996110796","0","0.025248999996110796","0","13","","0","0","0","0"
"aten::random_","0","0.0444660000000149","0","0.0444660000000149","1","","0","0","0","0"
"aten::set_","0","1.3696619999986142","0","1.3696619999986142","296","","0","0","0","0"
"Memcpy DtoH (Device -> Pageable)","100.11622899999283","0","100.11622899999283","0","148","","0","0","0","0"
"aten::native_dropout","15.072865999981762","99.0015469999984","15.072865999981762","2.8432849999815226","100","","3000.2880859375","0","0","0"
"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)","15.072865999981762","0","15.072865999981762","0","100","","0","0","0","0"
"aten::scalar_tensor","0","0.30504400000162424","0","0.30504400000162424","96","","0","0","0.000732421875","0.000732421875"
"autograd::engine::evaluate_function: NativeDropoutBackward0","11.538077000003309","5.051083000004292","0","0.9100619999729097","100","","1704","-696","0","0"
"NativeDropoutBackward0","11.538077000003309","4.141021000031381","0","0.43266300002485514","100","","2400","0","0","0"
"aten::native_dropout_backward","11.538077000003309","3.708358000006527","11.538077000003309","1.284778000028804","100","","2400","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)","11.538077000003309","0","11.538077000003309","0","100","","0","0","0","0"
"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)","359.1305259999763","0","359.1305259999763","0","48","","0","0","0","0"