"Name","Device Time Total (ms)","CPU Time Total (ms)","Self Device Time Total (ms)","Self CPU Time Total (ms)","Calls","Input Shapes","Device Memory Usage (MB)","Self Device Memory Usage (MB)","CPU Memory Usage (MB)","Self CPU Memory Usage (MB)"
"ProfilerStep*","8169.501244999859","21749.228048","0","6855.884893999997","10","","2.0634765625","-137525.060546875","0","-0.00458526611328125"
"enumerate(DataLoader)#_MultiProcessingDataLoaderIter.__next__","0","12.235140000008196","0","11.72399300000459","21","","0","0","0","0"
"aten::to","83.00364399998519","8236.47473199995","0","0.5700969999539666","2190","","2.5","0","0","0"
"aten::_to_copy","83.00364399998519","8235.904634999995","0","0.5094070000008214","40","","2.5","0","0","0"
"aten::empty_strided","0","15.32366400005296","0","13.093534000057726","1730","","7751.87109375","7751.87109375","0","0"
"aten::copy_","823.6310499999702","8872.289062999927","740.9514389999724","16.599495999916574","2088","","0","0","0","0"
"cudaMemcpyAsync","0","622.5736760000211","0","622.5611900000216","1931","","0","0","0","0"
"cudaStreamSynchronize","82.6796109999977","12764.466701999994","0","12763.319473999962","205","","0","0","0","0"
"Memset (Device)","4.39751799998824","0","4.39751799998824","0","1826","","0","0","0","0"
"ampere_sgemm_128x64_nn","214.14819599997017","0","214.14819599997017","0","242","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)","857.2022809999526","0","857.2022809999526","0","1265","","0","0","0","0"
"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)","60.35042899996997","0","60.35042899996997","0","504","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_256x128_8x4_nn_align1>(cutlass_80_simt_sgemm_256x128_8x4_nn_align1::Params)","2001.8861539999796","0","2001.8861539999796","0","494","","0","0","0","0"
"cudaPointerGetAttributes","0","0.24773900000728144","0","0.24411900000810102","56","","-120","-120","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)","1096.0076229999993","0","1096.0076229999993","0","2893","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#2}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#2}, at::detail::Array<char*, 2>)","208.63628900002206","0","208.63628900002206","0","242","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::tanh_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::tanh_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)","208.90950499998883","0","208.90950499998883","0","242","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<float>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<float>, at::detail::Array<char*, 2>)","208.7483209999912","0","208.7483209999912","0","253","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)","861.3045849999876","0","861.3045849999876","0","770","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_128x64_8x5_nn_align1>(cutlass_80_simt_sgemm_128x64_8x5_nn_align1::Params)","826.9423569999929","0","826.9423569999929","0","242","","0","0","0","0"
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)","587.2126300000189","0","587.2126300000189","0","241","","0","0","0","0"
"cudaEventQuery","82.6796109999977","1.8808180000189896","82.6796109999977","1.8808180000189896","1225","","-96","-96","0","0"
"ampere_sgemm_128x128_tn","1855.7415139999966","0","1855.7415139999966","0","21","","0","0","0","0"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})","464.1399669999992","0","464.1399669999992","0","164","","0","0","0","0"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1} const&)::{lambda(int)#1})","0.1327680000065302","0","0.1327680000065302","0","21","","0","0","0","0"
"void at::native::(anonymous namespace)::cunn_SoftMaxForward<4, float, float, float, at::native::(anonymous namespace)::LogSoftMaxForwardEpilogue>(float*, float const*, int)","298.21533899999537","0","298.21533899999537","0","21","","0","0","0","0"
"void at::native::(anonymous namespace)::nll_loss_forward_reduce_cuda_kernel_2d<float, float, long>(float*, float*, float const*, long const*, float const*, bool, long, long, long, long)","7.19783400000236","0","7.19783400000236","0","21","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)","219.99961200000868","0","219.99961200000868","0","81","","0","0","0","0"
"void at::native::(anonymous namespace)::nll_loss_backward_reduce_cuda_kernel_2d<float, long>(float*, float const*, long const*, float const*, float const*, bool, int, int, long, long)","2.127043999997346","0","2.127043999997346","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::cunn_SoftMaxBackward<4, float, float, float, at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue>(float*, float const*, float const*, long)","269.87599499999686","0","269.87599499999686","0","11","","0","0","0","0"
"Memcpy DtoD (Device -> Device)","216.6674229999827","0","216.6674229999827","0","1879","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_128x256_8x4_nt_align1>(cutlass_80_simt_sgemm_128x256_8x4_nt_align1::Params)","908.2465889999994","0","908.2465889999994","0","143","","0","0","0","0"
"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)","71.73282499999245","0","71.73282499999245","0","275","","0","0","0","0"
"void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)","80.12339900001959","0","80.12339900001959","0","275","","0","0","0","0"
"ampere_sgemm_128x64_tn","1506.123437000007","0","1506.123437000007","0","528","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_128x64_8x5_nt_align1>(cutlass_80_simt_sgemm_128x64_8x5_nt_align1::Params)","891.4009049999988","0","891.4009049999988","0","396","","0","0","0","0"
"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)","126.46207700002299","0","126.46207700002299","0","539","","0","0","0","0"
"ncclDevKernel_AllReduce_Sum_f32_RING_LL(ncclDevComm*, unsigned long, ncclWork*)","5654.916719000005","0","5654.916719000005","0","147","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::tanh_backward_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::tanh_backward_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)","173.0262179999905","0","173.0262179999905","0","132","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#1}, at::detail::Array<char*, 2>)","113.8947010000131","0","113.8947010000131","0","132","","0","0","0","0"
"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)","13.014859999998182","0","13.014859999998182","0","132","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<unsigned char>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<unsigned char>, at::detail::Array<char*, 1>)","6.5612299999733805","0","6.5612299999733805","0","132","","0","0","0","0"
"fmha_cutlassB_f32_aligned_64x64_k64_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, false, false, 64, 64, 64, false>::Params)","608.5420900000017","0","608.5420900000017","0","84","","0","0","0","0"
"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 3, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)","82.32371899999654","0","82.32371899999654","0","132","","0","0","0","0"
"void at::native::(anonymous namespace)::embedding_backward_feature_kernel<float, float, long>(long const*, float const*, float*, int, long, int)","0.882370999999228","0","0.882370999999228","0","11","","0","0","0","0"
"void (anonymous namespace)::elementwise_kernel_with_index<int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}, function_traits<at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>::result_type*)","0.15081400000001305","0","0.15081400000001305","0","31","","0","0","0","0"
"void at_cuda_detail::cub::DeviceRadixSortHistogramKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy800, false, long, unsigned long long>(unsigned long long*, long const*, unsigned long long, int, int)","0.12675199999893083","0","0.12675199999893083","0","11","","0","0","0","0"
"void at_cuda_detail::cub::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy800, unsigned long long>(unsigned long long*)","0.0625269999995362","0","0.0625269999995362","0","11","","0","0","0","0"
"void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy800, false, long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long, int, int>(int*, int*, unsigned long long*, unsigned long long const*, long*, long const*, at::cuda::cub::detail::OpaqueType<8>*, at::cuda::cub::detail::OpaqueType<8> const*, int, int, int)","1.2488990000111517","0","1.2488990000111517","0","88","","0","0","0","0"
"void at_cuda_detail::cub::DeviceCompactInitKernel<at_cuda_detail::cub::ScanTileState<int, true>, long*>(at_cuda_detail::cub::ScanTileState<int, true>, int, long*)","0.08470400000363588","0","0.08470400000363588","0","11","","0","0","0","0"
"void at_cuda_detail::cub::DeviceUniqueByKeySweepKernel<at_cuda_detail::cub::DeviceUniqueByKeyPolicy<long const*>::Policy520, long const*, thrust::counting_iterator<int, thrust::use_default, thrust::use_default, thrust::use_default>, long*, long*, long*, at_cuda_detail::cub::ScanTileState<int, true>, at_cuda_detail::cub::Equality, int>(long const*, thrust::counting_iterator<int, thrust::use_default, thrust::use_default, thrust::use_default>, long*, long*, long*, at_cuda_detail::cub::ScanTileState<int, true>, at_cuda_detail::cub::Equality, int, int)","0.11574200000229758","0","0.11574200000229758","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::krn_partials_per_segment<long>(long*, long const*, long const*, long)","0.06720200000284239","0","0.06720200000284239","0","11","","0","0","0","0"
"void at_cuda_detail::cub::DeviceScanInitKernel<at_cuda_detail::cub::ScanTileState<long, true> >(at_cuda_detail::cub::ScanTileState<long, true>, int)","0.057023999997181815","0","0.057023999997181815","0","11","","0","0","0","0"
"void at_cuda_detail::cub::DeviceScanKernel<at_cuda_detail::cub::DeviceScanPolicy<long>::Policy600, long const*, long*, at_cuda_detail::cub::ScanTileState<long, true>, at::cuda::cub::(anonymous namespace)::SumOp<long>, at_cuda_detail::cub::detail::InputValue<long, long*>, int, long>(long const*, long*, at_cuda_detail::cub::ScanTileState<long, true>, int, at::cuda::cub::(anonymous namespace)::SumOp<long>, at_cuda_detail::cub::detail::InputValue<long, long*>, int)","0.08963299999712035","0","0.08963299999712035","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::compute_num_of_partial_segments<long>(long const*, long const*, long const*, long*)","0.06876900000148453","0","0.06876900000148453","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::krn_partial_segment_offset<long>(long*, long const*, long const*, long const*, long const*)","0.09078400000825058","0","0.09078400000825058","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::compute_grad_weight<float, long>(long const*, float const*, long const*, long, long, long const*, long const*, at::AccumulateType<float, true>::type*, long)","2.2407390000005254","0","2.2407390000005254","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::sum_and_scatter<float, long>(long const*, float*, long, long const*, long const*, at::AccumulateType<float, true>::type const*, long const*, long const*, long, long)","0.9754899999987101","0","0.9754899999987101","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::LpNormFunctor<float, (at::native::NormType)1, float, 1, 1, 0>, float*, int>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::LpNormFunctor<float, (at::native::NormType)1, float, 1, 1, 0>, float*, int)","22.55836499998835","0","22.55836499998835","0","77","","0","0","0","0"
"void at::native::lpnorm_cleanup<float, (at::native::NormType)1, float, float>(float const*, at::native::TensorListAddresses, int)","0.04188799999444746","0","0.04188799999444746","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)","1.0921980000014881","0","1.0921980000014881","0","32","","0","0","0","0"
"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::NormTwoOps<float, float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::NormTwoOps<float, float, float>, unsigned int, float, 4>)","0.03391999999829568","0","0.03391999999829568","0","11","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::reciprocal_kernel_cuda(at::TensorIteratorBase&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::reciprocal_kernel_cuda(at::TensorIteratorBase&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)","0.015038999997777865","0","0.015038999997777865","0","11","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)","0.016544999993755482","0","0.016544999993755482","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarTensorFunctor<float, 1, 1, 0>, std::multiplies<float>, float*, float>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarTensorFunctor<float, 1, 1, 0>, std::multiplies<float>, float*, float)","46.569304999999936","0","46.569304999999936","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::multiplies<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::multiplies<float>, float)","94.87432800001208","0","94.87432800001208","0","154","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::TernaryOpScalarFunctor<float, 2, 2, 0>, at::native::LerpFunctor<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::TernaryOpScalarFunctor<float, 2, 2, 0>, at::native::LerpFunctor<float>, float)","69.31391500000562","0","69.31391500000562","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<3>, at::native::(anonymous namespace)::PointwiseOpScalarFunctor<float, 3, 3, 0>, std::multiplies<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<3>, at::native::(anonymous namespace)::PointwiseOpScalarFunctor<float, 3, 3, 0>, std::multiplies<float>, float)","69.28111399999214","0","69.28111399999214","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::UnaryOpFunctor<float, 2, 1, 1>, at::native::Sqrt<float> >(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::UnaryOpFunctor<float, 2, 1, 1>, at::native::Sqrt<float>)","46.80079800000228","0","46.80079800000228","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 1>, at::native::(anonymous namespace)::BinaryOpScalarListFunctor<float, 1, 1, 0>, std::divides<float> >(at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 1>, at::native::(anonymous namespace)::BinaryOpScalarListFunctor<float, 1, 1, 0>, std::divides<float>)","46.87523000000033","0","46.87523000000033","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::plus<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::plus<float>, float)","47.02226300001086","0","47.02226300001086","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 3>, at::native::(anonymous namespace)::PointwiseOpScalarListFunctor<float, 3, 3, 0>, std::divides<float> >(at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 3>, at::native::(anonymous namespace)::PointwiseOpScalarListFunctor<float, 3, 3, 0>, std::divides<float>)","88.42683099999884","0","88.42683099999884","0","77","","0","0","0","0"
"ProfilerStep*","21336.755532000003","0","21336.755532000003","0","10","","0","0","0","0"
"Memcpy HtoD (Pinned -> Device)","0.32403299998748114","0","0.32403299998748114","0","40","","0","0","0","0"
"DistributedDataParallel.forward","7387.961704999864","492.2799910000032","0","126.58894700005429","20","","137523.8583984375","-210386.70703125","0.00457763671875","0.00273895263671875"
"cudaEventSynchronize","0.13151999999955297","0.017469999999855646","0.13151999999955297","0.017469999999855646","8","","0","0","0","0"
"cudaEventElapsedTime","0.003392000000923872","0.012127999999909662","0.003392000000923872","0.012127999999909662","4","","0","0","0","0"
"aten::flatten_dense_tensors","2.0211859999998705","2.92858299999882","0","0.6759830000112997","20","","120.0048828125","0","0","0"
"aten::view","0","19.157037000008625","0","19.157037000008625","6520","","0","0","0","0"
"aten::cat","76.93612999999954","21.196324999997277","76.93612999999954","4.312804999977234","150","","8760.0146484375","8748.0146484375","0","0"
"cudaLaunchKernel","0","760.067894000274","0","759.9654820002708","11334","","0","0","0","0"
"DistributedDataParallel.forward","7494.74694","0","7494.74694","0","20","","0","0","0","0"
"void at::native::(anonymous namespace)::CatArrayBatchedCopy_contig<at::native::(anonymous namespace)::OpaqueType<1u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<1u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<1u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)","0.9727040000015404","0","0.9727040000015404","0","10","","0","0","0","0"
"c10d::broadcast_","14.807313000002177","3.9402310000017753","0","1.1052830000069225","20","","0","0","0","0"
"record_param_comms","5272.846869000006","955.9212809999914","5272.841012000007","11.84328199995251","178","","0.001953125","0","0","0"
"cudaStreamIsCapturing","0","1.060869000051869","0","1.060869000051869","820","","0","0","0","0"
"cudaEventRecord","0.06112000000104308","1.1216100000290898","0.06112000000104308","1.1216100000290898","794","","0","0","0","0"
"cudaStreamWaitEvent","0","0.9182089999938616","0","0.9182089999938616","616","","0","0","0","0"
"nccl:broadcast","0","1.9439590000051539","0","0","20","","0","0","0","0"
"cudaStreamGetCaptureInfo_v2","0","0.18085100002388935","0","0.18085100002388935","154","","0","0","0","0"
"cudaLaunchKernelExC","0","1.9160589999975637","0","1.9160589999975637","154","","0","0","0","0"
"ncclDevKernel_Broadcast_RING_LL(ncclDevComm*, unsigned long, ncclWork*)","14.807313000002177","0","14.807313000002177","0","20","","0","0","0","0"
"nccl:broadcast","14.807313000002177","0","14.807313000002177","0","20","","0","0","0","0"
"aten::unflatten_dense_tensors","0","3.2688910000012257","0","0.9091199999685632","20","","0","0","0","0"
"aten::narrow","0","7.039280000007129","0","2.7298250000129918","960","","0","0","0","0"
"aten::slice","0","4.816328999990597","0","3.6083729999355274","1040","","0","0","0","0"
"aten::as_strided","0","9.143710999964853","0","9.143710999964853","8650","","0","0","0","0"
"aten::arange","0.2981080000000075","3.1039380000036907","0.14905400000000374","0.6328680000114255","60","","1.5625","0","0","0"
"aten::empty","0","202.7175679999235","0","34.42086499991489","4379","","102355.8056640625","102355.8056640625","0.00296783447265625","0.00296783447265625"
"aten::resize_","0","0.7071619999973336","0","0.6293879999935161","90","","540.78125","540.78125","0","0"
"aten::unsqueeze","0","3.202100000019884","0","2.5915220000381813","1500","","0","0","0","0"
"aten::embedding","3.772451000001631","2.971648000004701","0","0.5790250000153901","40","","540","0","0","0"
"aten::reshape","0","9.464639000010328","0","4.579165999969933","1540","","0","0","0","0"
"aten::index_select","3.772451000001631","2.2187139999963112","3.772451000001631","0.9235829999995185","40","","540","0","0","0"
"aten::add","665.6125459999329","30.03117399998207","665.6125459999329","19.20265699996159","1000","","59553.5302734375","59553.5302734375","0","0"
"aten::dropout","15.040879999987782","106.12284600001271","0","0.7849230000234675","500","","3000.7626953125","0","0","0"
"void at::native::(anonymous namespace)::indexSelectLargeIndex<float, long, unsigned int, 2, 2, -2, true>(at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<long const, unsigned int>, int, int, unsigned int, unsigned int, long)","3.772451000001631","0","3.772451000001631","0","40","","0","0","0","0"
"aten::layer_norm","59.88758099996997","38.204701000010594","0","2.387273000018555","500","","12015.65625","-15.59375","0","0"
"aten::native_layer_norm","59.88758099996997","35.81742799999204","59.88758099996997","15.757217000025557","500","","12031.25","0","0","0"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})","1.7679999999990688","0","1.7679999999990688","0","20","","0","0","0","0"
"aten::addmm","2376.071639999931","69.36370299998659","2376.071639999931","42.6505080000069","960","","51840.2880859375","51816.2880859375","0","0"
"cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags","0","2.328334000002127","0","2.328334000002127","1240","","0","0","0","0"
"cudaFuncSetAttribute","0","520.8030379999734","0","520.8030379999734","740","","0","0","0","0"
"aten::split","0","7.535594000010867","0","2.4488280000223313","240","","0","0","0","0"
"aten::permute","0","6.121979999983334","0","5.247644000011147","1080","","0","0","0","0"
"aten::scaled_dot_product_attention","584.9277950000189","27.797666999967536","0","4.120503999977489","240","","5805","0","0.0018310546875","-0.0018310546875"
"aten::_scaled_dot_product_efficient_attention","584.9277950000189","23.675692999989376","0","4.524905999954208","240","","5805","0","0.003662109375","0"
"aten::transpose","0","14.603117999980809","0","10.578645999976201","3420","","0","0","0","0"
"aten::_efficient_attention_forward","584.9277950000189","15.717915000000852","584.9277950000189","6.213945999996271","240","","5805","0","0.003662109375","0.00000762939453125"
"cudaMemsetAsync","0","11.450644000038738","0","11.450644000038738","1680","","0","0","0","0"
"cudaOccupancyMaxActiveBlocksPerMultiprocessor","0","1.3795559999722755","0","1.3795559999722755","720","","0","0","0","0"
"aten::mul","1856.2257059999881","91.62062600005675","1856.2257059999881","49.81673900002171","3410","","175681.7333984375","175585.7333984375","0","0"
"aten::pow","310.49036600003495","12.496698000031756","310.49036600003495","8.088539000018617","360","","34560","34560","0","0"
"aten::result_type","0","1.1584279999809806","0","1.1584279999809806","9240","","0","0","0","0"
"aten::tanh","207.18659099998885","5.779565999996965","207.18659099998885","3.9262219999890076","240","","23040","23040","0","0"
"aten::linear","1770.5090429999966","2.094110000000801","0","0.10356100000161678","20","","31410.625","0","0","0"
"aten::t","0","8.69289499995322","0","3.667643999963766","1020","","0","0","0","0"
"aten::matmul","1770.5090429999966","1.7553600000038276","0","0.21434100000490436","20","","31410.625","0","0","0"
"aten::mm","5366.417870000009","45.98474800001795","5366.417870000009","29.031387999949047","1000","","56556.7822265625","56556.7822265625","0","0"
"aten::_unsafe_view","0","0.07998399999912363","0","0.07998399999912363","20","","0","0","0","0"
"aten::contiguous","290.45510400000427","6.915520000025048","0","0.30509100000397305","160","","31426.201171875","0","0","0"
"aten::clone","290.45510400000427","6.610429000021075","0","0.8290270000312012","160","","31426.201171875","0","0","0"
"aten::empty_like","0","9.292348000045168","0","1.8190330000796822","490","","36828.21875","0","0","0"
"aten::cross_entropy_loss","290.8752009999978","2.1576039999898056","0","0.16154699998593425","20","","15689.990234375","-15689.9755859375","0","0"
"aten::log_softmax","284.0178469999954","1.0903760000020266","0","0.11048799999488983","20","","31379.951171875","0","0","0"
"aten::_log_softmax","284.0178469999954","0.9723820000061533","284.0178469999954","0.49512500001234","20","","31379.951171875","31379.951171875","0","0"
"aten::nll_loss_nd","6.8573540000023785","0.9056810000018449","0","0.059165999997057954","20","","0.0146484375","0","0","0"
"aten::nll_loss","6.8573540000023785","0.846515000004787","0","0.0842380000052508","20","","0.0146484375","-0.0048828125","0","0"
"aten::nll_loss_forward","6.8573540000023785","0.7622769999995362","6.8573540000023785","0.5504019999934826","20","","0.01953125","0.01953125","0","0"
"cudaFree","0","852.9841080000039","0","852.9745310000044","79","","0","0","0","0"
"aten::ones_like","0.02582400000630878","0.616087000000989","0","0.052103999990969894","10","","0.0048828125","0","0","0"
"aten::fill_","206.40669999998204","11.670722000003327","206.40669999998204","1.6841699999806006","194","","0","0","0","0"
"autograd::engine::evaluate_function: NllLossBackward0","67.0858759999997","5.347873999994946","0","0.28410399999073704","10","","15689.345703125","-0.6298828125","0","0"
"NllLossBackward0","67.0858759999997","5.06377000000421","0","0.09364100001123733","10","","15689.9755859375","0","0","0"
"aten::nll_loss_backward","67.0858759999997","4.970128999992972","1.9202919999973382","0.39798600000143053","10","","15689.9755859375","15689.9755859375","0","0"
"cudaMalloc","0","193.52249200001197","0","193.52249200001197","72","","0","0","0","0"
"aten::zero_","206.38087599997573","12.218260000031442","0","0.8616250000323634","184","","0","0","0","0"
"autograd::engine::evaluate_function: LogSoftmaxBackward0","246.30306599999685","4.802730999996653","0","0.3096439999951981","10","","-15689.9755859375","-31379.951171875","0","0"
"LogSoftmaxBackward0","246.30306599999685","4.493087000001455","0","0.07633499999972991","10","","15689.9755859375","0","0","0"
"aten::_log_softmax_backward_data","246.30306599999685","4.416752000001725","246.30306599999685","0.21088999999919905","10","","15689.9755859375","15689.9755859375","0","0"
"autograd::engine::evaluate_function: ViewBackward0","0","24.093030999986222","0","10.10883300006087","1470","","0","0","0","0"
"ViewBackward0","0","13.984197999925353","0","4.826202999915229","1470","","0","0","0","0"
"autograd::engine::evaluate_function: CloneBackward0","0","0.07986000000243075","0","0.07300200000195764","10","","0","0","0","0"
"CloneBackward0","0","0.0068580000004731115","0","0.0068580000004731115","10","","0","0","0","0"
"autograd::engine::evaluate_function: SliceBackward0","416.46423699999855","169.26497399999784","0","0.21557100000116042","20","","15.3369140625","-31379.951171875","0","0"
"SliceBackward0","416.46423699999855","169.0494029999967","0","0.07809299998916686","20","","31395.2880859375","0","0","0"
"aten::slice_backward","416.46423699999855","168.97131000000752","0","0.23792900001863018","20","","31395.2880859375","0","0","0"
"aten::zeros","135.29739099999983","177.6252089999935","0","0.3309289999715984","54","","32900.9931640625","0","0","0"
"autograd::engine::evaluate_function: UnsafeViewBackward0","0","0.17090900000184775","0","0.06726400000136346","10","","0","0","0","0"
"UnsafeViewBackward0","0","0.1036450000004843","0","0.03211100000143051","10","","0","0","0","0"
"autograd::engine::evaluate_function: MmBackward0","1002.5217610000078","1.6802129999985917","0","0.17801299999910405","10","","-14232.939453125","-15945.3125","0","0"
"MmBackward0","1002.5217610000078","1.5021999999994877","0","0.15762799999816343","10","","1712.373046875","0","0","0"
"autograd::engine::evaluate_function: TBackward0","0","0.14586099999700672","0","0.06726399999763817","10","","0","0","0","0"
"TBackward0","0","0.07859699999936856","0","0.016938000003108755","10","","0","0","0","0"
"autograd::engine::evaluate_function: NativeLayerNormBackward0","187.91502100001276","27.86761299998965","0","6.144928999972297","250","","-11774.4482421875","-17775.9130859375","0","0"
"NativeLayerNormBackward0","138.11112000001245","17.37369200000749","0","1.9270130000037606","250","","6001.46484375","0","0","0"
"aten::native_layer_norm_backward","138.11112000001245","15.446679000003728","138.11112000001245","5.268939999980386","250","","6001.46484375","0","0","0"
"autograd::engine::evaluate_function: torch::autograd::AccumulateGrad","5180.429665000018","84.13095800000733","0","22.306887999954633","1480","","0","0","0","0"
"torch::autograd::AccumulateGrad","0","11.90128400003654","0","4.547655000068247","1480","","0","0","0","0"
"aten::detach","0","7.89432499997993","0","2.9018429999924265","1629","","0","0","0","0"
"detach","0","4.992481999987503","0","4.992481999987503","1629","","0","0","0","0"
"torch::distributed::reducer::mul_out","30.049627000010805","33.36651900000451","0","2.9326529999580235","1480","","0","0","0","0"
"autograd::engine::evaluate_function: AddBackward0","0.45967800000077114","4.296813000045251","0","3.496117000051774","490","","30","0","0","0"
"AddBackward0","0","0.5110669999888633","0","0.5110669999888633","490","","0","0","0","0"
"autograd::engine::evaluate_function: AddmmBackward0","2708.7051590000196","92.29849500000337","0","11.734652000012108","480","","-16307.0517578125","-39744","0","0"
"AddmmBackward0","2593.3870660000052","57.55465399999428","0","5.870934000014793","480","","23433.7841796875","0","0","0"
"aten::sum","127.56686900001299","25.878246000010755","127.56686900001299","17.888140999993077","610","","78.1640625","78.1640625","0","0"
"c10d::allreduce_","5150.380038000007","16.556267000011633","0","4.079781000012299","130","","0","0","0","0"
"nccl:all_reduce","0","9.264563999994193","0","0","134","","0","0","0","0"
"autograd::engine::evaluate_function: MulBackward0","768.4417139999864","23.457426999970338","0","5.727434999931837","480","","-11520.8642578125","-69120.8642578125","-0.00274658203125","-0.00274658203125"
"MulBackward0","612.7773489999834","16.043020000041928","0","1.999309000015026","480","","57600","0","0","0"
"autograd::engine::evaluate_function: TanhBackward0","157.2679259999909","4.617108000009088","0","1.111166000000434","120","","-11520","-23040","0","0"
"TanhBackward0","157.2679259999909","3.5059420000086536","0","0.6318300000110175","120","","11520","0","0","0"
"aten::tanh_backward","157.2679259999909","2.8741119999976363","157.2679259999909","1.82589599999832","120","","11520","11520","0","0"
"autograd::engine::evaluate_function: PowBackward0","518.0143839999952","14.565360000004526","0","2.2805859999945386","120","","-23040","-34560","0","0"
"PowBackward0","364.53860699998864","10.119598000005354","0","1.129060999980662","120","","11520","-23040","0","0"
"aten::add_","358.94404300000986","9.574611999992747","358.94404300000986","6.062060999959707","1960","","0","0","0","0"
"autograd::engine::evaluate_function: TransposeBackward0","0","1.9536430000029503","0","0.7615710000081454","120","","0","0","0","0"
"TransposeBackward0","0","1.192071999994805","0","0.28854099999903704","120","","0","0","0","0"
"autograd::engine::evaluate_function: ScaledDotProductEfficientAttentionBackward0","953.108552999952","554.8146869999995","0","2.31989099998842","120","","2835","-5805","-0.0018310546875","-0.0018310546875"
"ScaledDotProductEfficientAttentionBackward0","953.108552999952","552.494796000011","0","1.2238410000130535","120","","8640","0","0","0"
"aten::_scaled_dot_product_efficient_attention_backward","953.108552999952","551.270954999998","0","2.739841000044253","120","","8640","0","0","0"
"aten::_efficient_attention_backward","953.108552999952","545.1774790000038","901.648603999993","5.313071999993641","120","","8640","-5853.0771484375","0","0"
"cudaFuncGetAttributes","0","0.6133579999774229","0","0.6133579999774229","120","","0","0","0","0"
"autograd::engine::evaluate_function: PermuteBackward0","0","5.34922099997825","0","2.2933739999721294","360","","0","0","0","0"
"PermuteBackward0","0","3.055847000006121","0","1.116394999996759","360","","0","0","0","0"
"autograd::engine::evaluate_function: SplitBackward0","74.87525999999652","6.100816000008025","0","1.2121510000019333","120","","0","-8640","0","0"
"SplitBackward0","74.87525999999652","4.888665000006091","0","0.5274060000076425","120","","8640","0","0","0"
"autograd::engine::evaluate_function: EmbeddingBackward0","31.34686200002674","6.043412000005366","0","0.3781240000075195","20","","-240.078125","-3214.82421875","0","0"
"EmbeddingBackward0","11.906901000021957","5.424992999998852","0","0.08891199999954552","20","","1502.373046875","0","0","0"
"aten::embedding_backward","11.906901000021957","5.336080999999307","0","0.05117400000407361","20","","1502.373046875","0","0","0"
"aten::embedding_dense_backward","11.906901000021957","5.284906999995234","6.098477000021376","1.6391599999808242","20","","1502.373046875","-268.4423828125","0","0"
"cudaDeviceGetAttribute","0","0.03361000000289641","0","0.03361000000289641","50","","0","0","0","0"
"cudaPeekAtLastError","0","0.029977000006008895","0","0.029977000006008895","170","","0","0","0","0"
"torch.distributed.ddp.reducer::copy_bucket_to_grad","55.62417899999814","507.5359169999945","0","3.0565650000560565","1480","","0","0","0","0"
"aten::_foreach_norm","20.559513999982737","73.35858200000366","20.5440569999828","5.921411000006599","10","","0.72265625","-2.607421875","0","0"
"aten::stack","0.039684000003151594","20.253607000000773","0","1.6951329999782612","10","","0.009765625","0","0","0"
"aten::linalg_vector_norm","0.03068799999821931","10.580917999998666","0.03068799999821931","0.3184419999984093","10","","0.0048828125","0.0048828125","0","0"
"aten::reciprocal","0.013630999997723848","10.513827000000049","0.013630999997723848","0.15105300000519492","10","","0.0048828125","0.0048828125","0","0"
"aten::clamp","0.014944999993778765","0.6093719999974128","0.014944999993778765","0.20573100000061095","10","","0.0048828125","0.0048828125","0","0"
"aten::_foreach_mul_","128.59977600001218","175.66036899999855","128.59977600001218","4.2791569999263155","30","","0","0","0","0"
"Optimizer.step#AdamW.step","420.5689790000222","454.82283900000226","0","22.532021999979158","10","","0","-4748.603515625","0","-0.00003814697265625"
"aten::lift_fresh","0","0.0047580000022426246","0","0.0047580000022426246","10","","0","0","0","0"
"aten::detach_","0","0.03209700000565499","0","0.020222000004956497","10","","0","0","0","0"
"detach_","0","0.011875000000698492","0","0.011875000000698492","10","","0","0","0","0"
"aten::_foreach_add_","42.74865700001083","56.60010599999758","42.74865700001083","3.3861840000282974","20","","0","0","0","0"
"aten::_foreach_lerp_","63.017970000005796","44.388406000001126","63.017970000005796","0.6056900000076275","10","","0","0","0","0"
"aten::_foreach_addcmul_","62.975951999992134","51.3436090000011","62.975951999992134","1.9337310000571888","10","","0","0","0","0"
"aten::item","0.024511000007390975","3597.2818950000146","0","3.0702369998998473","2974","","0","0","0","0"
"aten::_local_scalar_dense","0.024511000007390975","3594.2116580001143","0.024511000007390975","0.9220840001080651","2974","","0","0","0","0"
"aten::_foreach_sqrt","42.54556100000208","48.64028800000111","42.54556100000208","3.992812999937683","10","","4748.603515625","0","0","0"
"aten::_foreach_div_","42.63125500000035","59.040878999999954","42.63125500000035","1.7113070000028239","10","","0","0","0","0"
"aten::_foreach_addcdiv_","80.38858099999884","47.37448800000362","80.38858099999884","2.222240000023041","10","","0","0","0","0"
"nccl:all_reduce","5258.033699000005","0","5258.033699000005","0","134","","0","0","0","0"
"Optimizer.step#AdamW.step","420.949132999998","0","420.949132999998","0","10","","0","0","0","0"
"c10d::barrier","107.65951799999736","1.0275559999998658","0","0.17055800000019372","4","","0.001953125","0","0","0"
"cudaDeviceSynchronize","0","990.6282269999981","0","990.5094860000127","7","","0","0","0","0"
"cudaHostAlloc","0","2.586784999998286","0","2.577470999997109","19","","132","132","0.00000762939453125","0.00000762939453125"
"Memcpy DtoH (Device -> Pinned)","0.024511000007390975","0","0.024511000007390975","0","13","","0","0","0","0"
"aten::random_","0","0.009177000001072884","0","0.009177000001072884","1","","0","0","0","0"
"aten::set_","0","1.4061490000206978","0","1.4061490000206978","296","","0","0","0","0"
"Memcpy DtoH (Device -> Pageable)","107.23394199999608","0","107.23394199999608","0","148","","0","0","0","0"
"aten::native_dropout","15.040879999987782","105.33792299998925","15.040879999987782","2.692622999895364","100","","3000.7626953125","0","0","0"
"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)","15.040879999987782","0","15.040879999987782","0","100","","0","0","0","0"
"aten::scalar_tensor","0","0.28545400001481175","0","0.28545400001481175","96","","0","0","0.000732421875","0.000732421875"
"autograd::engine::evaluate_function: NativeDropoutBackward0","12.328877999987453","4.800757000025362","0","0.839056000020355","100","","1703.2373046875","-696.7626953125","0","0"
"NativeDropoutBackward0","12.328877999987453","3.961701000005007","0","0.3652879999950528","100","","2400","0","0","0"
"aten::native_dropout_backward","12.328877999987453","3.596413000009954","12.328877999987453","1.291466999989003","100","","2400","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)","12.328877999987453","0","12.328877999987453","0","100","","0","0","0","0"
"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)","381.12276599999143","0","381.12276599999143","0","48","","0","0","0","0"