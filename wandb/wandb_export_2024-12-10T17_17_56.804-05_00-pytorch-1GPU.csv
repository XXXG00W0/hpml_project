"Name","Device Time Total (ms)","CPU Time Total (ms)","Self Device Time Total (ms)","Self CPU Time Total (ms)","Calls","Input Shapes","Device Memory Usage (MB)","Self Device Memory Usage (MB)","CPU Memory Usage (MB)","Self CPU Memory Usage (MB)"
"ProfilerStep*","10226.443398000049","25612.431311000004","0","5973.601563999917","15","","0.2373046875","-445242.248046875","0","-0.0027618408203125"
"enumerate(DataLoader)#_MultiProcessingDataLoaderIter.__next__","0","13.629213000006162","0","13.147483000006181","26","","0","0","0","0"
"aten::to","0.40534999999357385","13610.524844000041","0","0.9965630000429228","3205","","3.125","0","0","0"
"aten::_to_copy","0.40534999999357385","13609.528280999999","0","1.0697130000058095","50","","3.125","0","0","0"
"aten::empty_strided","0","22.784004000090118","0","21.13165100009","2985","","17630.92333984375","17630.92333984375","0","0"
"aten::copy_","879.463599999981","13717.834647999998","879.463599999981","6.277173000011127","458","","0","0","0","0"
"cudaMemcpyAsync","0","104.49862200000402","0","104.49862200000402","226","","0","0","0","0"
"cudaStreamSynchronize","0","17151.836067000004","0","17151.71333600001","211","","0","0","0","0"
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)","801.5874460000033","0","801.5874460000033","0","310","","0","0","0","0"
"cudaPointerGetAttributes","0.20665699999779463","0.30985399999158836","0.20665699999779463","0.30637399999207265","66","","-191","-191","0","0"
"Memset (Device)","3.4885320000122317","0","3.4885320000122317","0","2614","","0","0","0","0"
"ampere_sgemm_128x64_nn","272.5495519999971","0","272.5495519999971","0","310","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)","1165.5363970000853","0","1165.5363970000853","0","1714","","0","0","0","0"
"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)","76.15219399999506","0","76.15219399999506","0","645","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_256x128_8x4_nn_align1>(cutlass_80_simt_sgemm_256x128_8x4_nn_align1::Params)","2715.587525999984","0","2715.587525999984","0","635","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)","1429.8434910000303","0","1429.8434910000303","0","1714","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#2}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#2}, at::detail::Array<char*, 2>)","267.5891450000032","0","267.5891450000032","0","310","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::tanh_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::tanh_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)","267.68473100000676","0","267.68473100000676","0","310","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<float>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<float>, at::detail::Array<char*, 2>)","267.3212340000393","0","267.3212340000393","0","326","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)","1178.7639830000057","0","1178.7639830000057","0","1078","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_128x64_8x5_nn_align1>(cutlass_80_simt_sgemm_128x64_8x5_nn_align1::Params)","1057.734360000009","0","1057.734360000009","0","310","","0","0","0","0"
"ampere_sgemm_128x128_tn","2427.888229999998","0","2427.888229999998","0","26","","0","0","0","0"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})","606.1610619999815","0","606.1610619999815","0","234","","0","0","0","0"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1} const&)::{lambda(int)#1})","0.17004800000262912","0","0.17004800000262912","0","26","","0","0","0","0"
"void at::native::(anonymous namespace)::cunn_SoftMaxForward<4, float, float, float, at::native::(anonymous namespace)::LogSoftMaxForwardEpilogue>(float*, float const*, int)","368.78602100000313","0","368.78602100000313","0","26","","0","0","0","0"
"void at::native::(anonymous namespace)::nll_loss_forward_reduce_cuda_kernel_2d<float, float, long>(float*, float*, float const*, long const*, float const*, bool, long, long, long, long)","9.206752000001842","0","9.206752000001842","0","26","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)","318.2747439999867","0","318.2747439999867","0","112","","0","0","0","0"
"void at::native::(anonymous namespace)::nll_loss_backward_reduce_cuda_kernel_2d<float, long>(float*, float const*, long const*, float const*, float const*, bool, int, int, long, long)","3.1945649999949963","0","3.1945649999949963","0","16","","0","0","0","0"
"void at::native::(anonymous namespace)::cunn_SoftMaxBackward<4, float, float, float, at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue>(float*, float const*, float const*, long)","394.0777820000009","0","394.0777820000009","0","16","","0","0","0","0"
"Memcpy DtoD (Device -> Device)","224.66235100000335","0","224.66235100000335","0","16","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_128x256_8x4_nt_align1>(cutlass_80_simt_sgemm_128x256_8x4_nt_align1::Params)","1206.0771590000002","0","1206.0771590000002","0","208","","0","0","0","0"
"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)","90.0698260000042","0","90.0698260000042","0","400","","0","0","0","0"
"void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)","109.15537600000721","0","109.15537600000721","0","400","","0","0","0","0"
"ampere_sgemm_128x64_tn","2085.863325000078","0","2085.863325000078","0","768","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_128x64_8x5_nt_align1>(cutlass_80_simt_sgemm_128x64_8x5_nt_align1::Params)","1214.0188110000124","0","1214.0188110000124","0","576","","0","0","0","0"
"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)","178.2657139999476","0","178.2657139999476","0","784","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::tanh_backward_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::tanh_backward_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)","247.83516599998106","0","247.83516599998106","0","192","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#1}, at::detail::Array<char*, 2>)","163.2914700000229","0","163.2914700000229","0","192","","0","0","0","0"
"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)","19.049882999997354","0","19.049882999997354","0","192","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<unsigned char>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<unsigned char>, at::detail::Array<char*, 1>)","8.876766999980667","0","8.876766999980667","0","192","","0","0","0","0"
"fmha_cutlassB_f32_aligned_64x64_k64_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, false, false, 64, 64, 64, false>::Params)","157.73375699999985","0","157.73375699999985","0","24","","0","0","0","0"
"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 3, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)","118.18996400000422","0","118.18996400000422","0","192","","0","0","0","0"
"void at::native::(anonymous namespace)::embedding_backward_feature_kernel<float, float, long>(long const*, float const*, float*, int, long, int)","0.6168979999887524","0","0.6168979999887524","0","16","","0","0","0","0"
"void (anonymous namespace)::elementwise_kernel_with_index<int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}, function_traits<at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>::result_type*)","0.07977600001532119","0","0.07977600001532119","0","41","","0","0","0","0"
"void at_cuda_detail::cub::DeviceRadixSortHistogramKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy800, false, long, unsigned long long>(unsigned long long*, long const*, unsigned long long, int, int)","0.12694399999827147","0","0.12694399999827147","0","16","","0","0","0","0"
"void at_cuda_detail::cub::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy800, unsigned long long>(unsigned long long*)","0.03708900000259746","0","0.03708900000259746","0","16","","0","0","0","0"
"void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy800, false, long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long, int, int>(int*, int*, unsigned long long*, unsigned long long const*, long*, long const*, at::cuda::cub::detail::OpaqueType<8>*, at::cuda::cub::detail::OpaqueType<8> const*, int, int, int)","1.4733420000039041","0","1.4733420000039041","0","128","","0","0","0","0"
"void at_cuda_detail::cub::DeviceCompactInitKernel<at_cuda_detail::cub::ScanTileState<int, true>, long*>(at_cuda_detail::cub::ScanTileState<int, true>, int, long*)","0.07001599999866448","0","0.07001599999866448","0","16","","0","0","0","0"
"void at_cuda_detail::cub::DeviceUniqueByKeySweepKernel<at_cuda_detail::cub::DeviceUniqueByKeyPolicy<long const*>::Policy520, long const*, thrust::counting_iterator<int, thrust::use_default, thrust::use_default, thrust::use_default>, long*, long*, long*, at_cuda_detail::cub::ScanTileState<int, true>, at_cuda_detail::cub::Equality, int>(long const*, thrust::counting_iterator<int, thrust::use_default, thrust::use_default, thrust::use_default>, long*, long*, long*, at_cuda_detail::cub::ScanTileState<int, true>, at_cuda_detail::cub::Equality, int, int)","0.10357899999886286","0","0.10357899999886286","0","16","","0","0","0","0"
"void at::native::(anonymous namespace)::krn_partials_per_segment<long>(long*, long const*, long const*, long)","0.039646999994758514","0","0.039646999994758514","0","16","","0","0","0","0"
"void at_cuda_detail::cub::DeviceScanInitKernel<at_cuda_detail::cub::ScanTileState<long, true> >(at_cuda_detail::cub::ScanTileState<long, true>, int)","0.026240000008256173","0","0.026240000008256173","0","16","","0","0","0","0"
"void at_cuda_detail::cub::DeviceScanKernel<at_cuda_detail::cub::DeviceScanPolicy<long>::Policy600, long const*, long*, at_cuda_detail::cub::ScanTileState<long, true>, at::cuda::cub::(anonymous namespace)::SumOp<long>, at_cuda_detail::cub::detail::InputValue<long, long*>, int, long>(long const*, long*, at_cuda_detail::cub::ScanTileState<long, true>, int, at::cuda::cub::(anonymous namespace)::SumOp<long>, at_cuda_detail::cub::detail::InputValue<long, long*>, int)","0.07270200000936165","0","0.07270200000936165","0","16","","0","0","0","0"
"void at::native::(anonymous namespace)::compute_num_of_partial_segments<long>(long const*, long const*, long const*, long*)","0.03388899999565911","0","0.03388899999565911","0","16","","0","0","0","0"
"void at::native::(anonymous namespace)::krn_partial_segment_offset<long>(long*, long const*, long const*, long const*, long const*)","0.07417700000596232","0","0.07417700000596232","0","16","","0","0","0","0"
"void at::native::(anonymous namespace)::compute_grad_weight<float, long>(long const*, float const*, long const*, long, long, long const*, long const*, at::AccumulateType<float, true>::type*, long)","3.1898649999895134","0","3.1898649999895134","0","16","","0","0","0","0"
"void at::native::(anonymous namespace)::sum_and_scatter<float, long>(long const*, float*, long, long const*, long const*, at::AccumulateType<float, true>::type const*, long const*, long const*, long, long)","1.4199060000043828","0","1.4199060000043828","0","16","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::LpNormFunctor<float, (at::native::NormType)1, float, 1, 1, 0>, float*, int>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::LpNormFunctor<float, (at::native::NormType)1, float, 1, 1, 0>, float*, int)","32.758733000007574","0","32.758733000007574","0","112","","0","0","0","0"
"void at::native::lpnorm_cleanup<float, (at::native::NormType)1, float, float>(float const*, at::native::TensorListAddresses, int)","0.08028899999638088","0","0.08028899999638088","0","16","","0","0","0","0"
"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)","0.09266799999761861","0","0.09266799999761861","0","32","","0","0","0","0"
"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::NormTwoOps<float, float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::NormTwoOps<float, float, float>, unsigned int, float, 4>)","0.07763299999246374","0","0.07763299999246374","0","16","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::reciprocal_kernel_cuda(at::TensorIteratorBase&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::reciprocal_kernel_cuda(at::TensorIteratorBase&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)","0.03375800000212621","0","0.03375800000212621","0","16","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)","0.036094000002602114","0","0.036094000002602114","0","16","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarTensorFunctor<float, 1, 1, 0>, std::multiplies<float>, float*, float>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarTensorFunctor<float, 1, 1, 0>, std::multiplies<float>, float*, float)","68.10699100000109","0","68.10699100000109","0","112","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::multiplies<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::multiplies<float>, float)","138.3218409999991","0","138.3218409999991","0","224","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::TernaryOpScalarFunctor<float, 2, 2, 0>, at::native::LerpFunctor<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::TernaryOpScalarFunctor<float, 2, 2, 0>, at::native::LerpFunctor<float>, float)","101.1877949999792","0","101.1877949999792","0","112","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<3>, at::native::(anonymous namespace)::PointwiseOpScalarFunctor<float, 3, 3, 0>, std::multiplies<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<3>, at::native::(anonymous namespace)::PointwiseOpScalarFunctor<float, 3, 3, 0>, std::multiplies<float>, float)","100.92306399998337","0","100.92306399998337","0","112","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::UnaryOpFunctor<float, 2, 1, 1>, at::native::Sqrt<float> >(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::UnaryOpFunctor<float, 2, 1, 1>, at::native::Sqrt<float>)","68.3452919999829","0","68.3452919999829","0","112","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 1>, at::native::(anonymous namespace)::BinaryOpScalarListFunctor<float, 1, 1, 0>, std::divides<float> >(at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 1>, at::native::(anonymous namespace)::BinaryOpScalarListFunctor<float, 1, 1, 0>, std::divides<float>)","68.44871899999713","0","68.44871899999713","0","112","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::plus<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::plus<float>, float)","68.51512099999073","0","68.51512099999073","0","112","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 3>, at::native::(anonymous namespace)::PointwiseOpScalarListFunctor<float, 3, 3, 0>, std::divides<float> >(at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 3>, at::native::(anonymous namespace)::PointwiseOpScalarListFunctor<float, 3, 3, 0>, std::divides<float>)","128.76637199998763","0","128.76637199998763","0","112","","0","0","0","0"
"ProfilerStep*","24999.75899","0","24999.75899","0","15","","0","0","0","0"
"Memcpy HtoD (Pinned -> Device)","0.40534999999357385","0","0.40534999999357385","0","50","","0","0","0","0"
"aten::view","0","23.868854000023568","0","23.868854000023568","8045","","0","0","0","0"
"aten::arange","0.15609600003063678","5.312430000004126","0.07804800001531839","1.1383210000207182","80","","2.265625","0","0","0"
"aten::empty","0","92.21269099991419","0","43.27186499990942","5776","","146041.50830078125","146041.50830078125","0.002071380615234375","0.002071380615234375"
"aten::resize_","0","0.840641999986954","0","0.840641999986954","115","","676.1328125","676.1328125","0","0"
"cudaLaunchKernel","0.20665699999779463","215.6083199998047","0","215.5877529998063","14075","","0","0","0","0"
"aten::unsqueeze","0","4.792403000044869","0","3.685722999935737","2245","","0","0","0","0"
"aten::as_strided","0","9.896242000001715","0","9.896242000001715","9710","","0","0","0","0"
"aten::embedding","4.454953999989666","3.934185000001453","0","0.9029580000110436","50","","675","0","0","0"
"aten::reshape","0","10.625125999975717","0","4.866231000008062","2295","","0","0","0","0"
"aten::index_select","4.454953999989666","2.7703779999983964","4.454953999989666","1.215962000000989","50","","675","-3","0","0"
"void at::native::(anonymous namespace)::indexSelectLargeIndex<float, long, unsigned int, 2, 2, -2, true>(at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<long const, unsigned int>, int, int, unsigned int, unsigned int, long)","4.454953999989666","0","4.454953999989666","0","50","","0","0","0","0"
"aten::add","840.6538770000756","35.794374999979276","840.4472200000778","23.37369199995999","1255","","74808.56689453125","74808.56689453125","0","0"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})","2.204809000001056","0","2.204809000001056","0","25","","0","0","0","0"
"aten::dropout","53.05132700003125","115.11323800000712","0","1.7228580000044311","625","","10501.525390625","0","0","0"
"aten::layer_norm","73.76031499999506","46.52532899999595","0","2.999775999981677","625","","15023.46875","-15.59375","0","0"
"aten::native_layer_norm","73.76031499999506","43.52555300001428","73.76031499999506","19.789516999992543","625","","15039.0625","0","0","0"
"aten::addmm","2959.173354000003","81.46615100004361","2959.173354000003","55.09327500016196","1200","","64800.2880859375","64774.2880859375","0","0"
"cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags","0","4.555623999958392","0","4.555623999958392","1680","","0","0","0","0"
"cudaFuncSetAttribute","0","530.8817099999756","0","530.8817099999756","990","","0","0","0","0"
"aten::split","0","10.466061999993398","0","3.5297379999598486","300","","0","0","0","0"
"aten::narrow","0","6.934976000033319","0","2.596044000060065","900","","0","0","0","0"
"aten::slice","0","5.158993999959669","0","3.7345689999817404","1005","","0","0","0","0"
"aten::permute","0","8.366822999977506","0","6.941703000041423","1440","","0","0","0","0"
"aten::scaled_dot_product_attention","779.3535570000033","37.391415000004464","0","5.502938000036637","300","","7267.974609375","0","0.00275421142578125","-0.00182342529296875"
"aten::_scaled_dot_product_efficient_attention","779.3535570000033","31.888476999967825","0","6.068453999954741","300","","7267.974609375","0","0.00457763671875","0"
"aten::transpose","0","20.687326000034343","0","14.93456900005159","4825","","0","0","0","0"
"aten::_efficient_attention_forward","779.3535570000033","21.08377400004072","779.3535570000033","8.315188000070396","300","","7267.974609375","0","0.00457763671875","0.00000762939453125"
"cudaStreamIsCapturing","0","1.7831269999912474","0","1.7831269999912474","1605","","0","0","0","0"
"cudaMemsetAsync","0","14.740795000038808","0","14.740795000038808","2460","","0","0","0","0"
"cudaOccupancyMaxActiveBlocksPerMultiprocessor","0","1.9168509999667294","0","1.9168509999667294","1020","","0","0","0","0"
"aten::mul","2481.357909000036","65.77919500001101","2481.357909000036","41.59739300001529","2655","","240480.29541015625","240480.29541015625","0","0"
"aten::pow","412.02679900002596","16.037147000005934","412.02679900002596","10.714193000012077","480","","46080","46080","0","0"
"aten::result_type","0","1.7101669997742865","0","1.7101669997742865","13800","","0","0","0","0"
"aten::tanh","259.0562900000068","7.333599000017158","259.0562900000068","4.992259000038961","300","","28800","28800","0","0"
"aten::linear","2333.570155999998","2.7988119999987537","0","0.14184399999585004","25","","39263.28125","0","0","0"
"aten::t","0","13.132425000042423","0","5.655698000020347","1525","","0","0","0","0"
"aten::matmul","2333.570155999998","2.341264000002295","0","0.33271599998977036","25","","39263.28125","0","0","0"
"aten::mm","7496.235572000091","66.42256600002992","7496.235572000091","42.4825170000582","1495","","76962.5205078125","76962.5205078125","0","0"
"aten::_unsafe_view","0","0.11619899999303743","0","0.11619899999303743","25","","0","0","0","0"
"aten::contiguous","362.993821999982","9.722042999994242","0","0.49784500000206755","230","","39294.00146484375","0","0","0"
"aten::clone","362.993821999982","9.224197999992175","0","1.1534329999773762","230","","39294.00146484375","0","0","0"
"aten::empty_like","0","18.212455000040354","0","5.0294750000301285","1325","","58197.4091796875","0","0","0"
"aten::cross_entropy_loss","363.484154000005","2.9689220000072383","0","0.2173070000060834","25","","23534.98291015625","-15689.9755859375","0","0"
"aten::log_softmax","354.61612300000314","1.4494109999979847","0","0.17814700000546874","25","","39224.93896484375","0","0","0"
"aten::_log_softmax","354.61612300000314","1.260700999992434","354.61612300000314","0.6842709999838844","25","","39224.93896484375","39224.93896484375","0","0"
"aten::nll_loss_nd","8.868031000001821","1.3022040000031703","0","0.10498100000037812","25","","0.01953125","0","0","0"
"aten::nll_loss","8.868031000001821","1.1972230000027921","0","0.18369399999524466","25","","0.01953125","-0.0048828125","0","0"
"aten::nll_loss_forward","8.868031000001821","1.0135290000075474","8.868031000001821","0.7201190000015777","25","","0.0244140625","0.0244140625","0","0"
"cudaFree","0","1203.3882750000023","0","1203.3882750000023","94","","0","0","0","0"
"aten::ones_like","0.04048200000310317","1.3551189999950584","0","0.17371400000178255","15","","0.00732421875","0","0","0"
"aten::fill_","307.07788199996764","5.42915399998147","307.07788199996764","2.45047199999704","285","","0","0","0","0"
"autograd::engine::evaluate_function: NllLossBackward0","100.5930439999858","8.051159000001382","0","0.6424930000035092","15","","23534.0185546875","-0.94482421875","0","0"
"NllLossBackward0","100.5930439999858","7.408665999997873","0","0.26968499999679624","15","","23534.96337890625","0","0","0"
"aten::nll_loss_backward","100.5930439999858","7.138981000001077","2.986947999994969","0.6404399999992456","15","","23534.96337890625","23534.96337890625","0","0"
"cudaMalloc","0","289.20572900000377","0","289.20572900000377","86","","0","0","0","0"
"aten::zero_","307.0373999999645","6.040549000043189","0","1.2696440000561997","270","","0","0","0","0"
"autograd::engine::evaluate_function: LogSoftmaxBackward0","370.4664160000009","225.64103500000456","0","0.534439000008395","15","","-23534.96337890625","-47069.9267578125","0","0"
"LogSoftmaxBackward0","370.4664160000009","225.1065959999962","0","0.13018299999414013","15","","23534.96337890625","0","0","0"
"aten::_log_softmax_backward_data","370.4664160000009","224.97641300000203","370.4664160000009","0.36225600000168195","15","","23534.96337890625","23534.96337890625","0","0"
"autograd::engine::evaluate_function: ViewBackward0","0","28.955819999967936","0","12.930087000009836","2205","","0","0","0","0"
"ViewBackward0","0","16.025732999958098","0","5.832095999984537","2205","","0","0","0","0"
"autograd::engine::evaluate_function: CloneBackward0","0","0.0935509999974165","0","0.08265299999318086","15","","0","0","0","0"
"CloneBackward0","0","0.010898000004235655","0","0.010898000004235655","15","","0","0","0","0"
"autograd::engine::evaluate_function: SliceBackward0","617.9899579999997","51.53466099999426","0","0.3187129999988247","30","","23.00537109375","-47069.9267578125","0","0"
"SliceBackward0","617.9899579999997","51.215947999995436","0","0.15691499999188818","30","","47092.93212890625","0","0","0"
"aten::slice_backward","617.9899579999997","51.059033000003545","0","0.47129400000721217","30","","47092.93212890625","0","0","0"
"aten::zeros","201.09546699999274","51.357110000010344","0","0.4727629999818746","75","","49351.48681640625","0","0","0"
"autograd::engine::evaluate_function: UnsafeViewBackward0","0","0.2697200000064913","0","0.08698000000580214","15","","0","0","0","0"
"UnsafeViewBackward0","0","0.18274000000068918","0","0.09448000000580214","15","","0","0","0","0"
"autograd::engine::evaluate_function: MmBackward0","1551.1747280000063","2.8287299999946263","0","0.2523609999953769","15","","-21349.4091796875","-23917.96875","0","0"
"MmBackward0","1551.1747280000063","2.576368999999249","0","0.25955899998731913","15","","2568.5595703125","0","0","0"
"autograd::engine::evaluate_function: TBackward0","0","0.23495000000181607","0","0.09917100000102073","15","","0","0","0","0"
"TBackward0","0","0.13577900000079535","0","0.02690500000002794","15","","0","0","0","0"
"autograd::engine::evaluate_function: NativeLayerNormBackward0","260.1854760000312","40.00374500001827","0","8.467954000067897","375","","-17661.240234375","-26663.4375","0","0"
"NativeLayerNormBackward0","186.77735400001077","24.76921999998274","0","2.961246000017971","375","","9002.197265625","0","0","0"
"aten::native_layer_norm_backward","186.77735400001077","21.807973999964773","186.77735400001077","7.440540000044741","375","","9002.197265625","0","0","0"
"autograd::engine::evaluate_function: torch::autograd::AccumulateGrad","0","27.649019000051542","0","12.943206000063103","2220","","0","0","0","0"
"torch::autograd::AccumulateGrad","0","14.70581299998844","0","5.889262999947183","2220","","0","0","0","0"
"aten::detach","0","9.358209000041242","0","3.9125189999989236","2369","","0","0","0","0"
"detach","0","5.445690000042319","0","5.445690000042319","2369","","0","0","0","0"
"autograd::engine::evaluate_function: AddBackward0","0.4903070000000298","5.945199999999487","0","4.721676000023261","735","","45.75","0","0","0"
"AddBackward0","0","0.7798739999833051","0","0.7798739999833051","735","","0","0","0","0"
"autograd::engine::evaluate_function: AddmmBackward0","3779.0442070000613","133.2219699999958","0","16.767641000069446","720","","-29088.57421875","-64224","0","0"
"AddmmBackward0","3611.4906880000876","83.91669399993354","0","8.852945999884513","720","","35130.6796875","0","0","0"
"aten::sum","185.97860099997115","36.45457399996882","185.97860099997115","25.380379999978","915","","117.99609375","117.99609375","0","0"
"autograd::engine::evaluate_function: MulBackward0","1129.1589159999833","31.636867999961133","0","7.309475999988615","720","","-17280.2880859375","-103680.2880859375","-0.004119873046875","-0.004119873046875"
"MulBackward0","899.1686129999704","22.084433999978703","0","2.897796999940183","720","","86400","0","0","0"
"autograd::engine::evaluate_function: TanhBackward0","232.27301099998107","6.586216000006534","0","1.4762620000047608","180","","-17280","-34560","0","0"
"TanhBackward0","232.27301099998107","5.109954000001773","0","0.9310910000076983","180","","17280","0","0","0"
"aten::tanh_backward","232.27301099998107","4.178862999994075","232.27301099998107","2.5266039999697822","180","","17280","17280","0","0"
"autograd::engine::evaluate_function: PowBackward0","767.2042150000606","20.140802000014343","0","3.0910050000366756","180","","-34560","-51840","0","0"
"PowBackward0","540.0788440000459","14.065308999982662","0","1.6905330000105314","180","","17280","-34560","0","0"
"aten::add_","530.523796000048","14.234209999991348","530.523796000048","9.230095000000205","2940","","0","0","0","0"
"autograd::engine::evaluate_function: TransposeBackward0","0","2.75005300000147","0","1.0168610000072513","180","","0","0","0","0"
"TransposeBackward0","0","1.7331919999942182","0","0.36713400000799445","180","","0","0","0","0"
"autograd::engine::evaluate_function: ScaledDotProductEfficientAttentionBackward0","1428.990080999975","582.3459230000286","0","3.535758000043221","180","","4252.6015625","-8707.974609375","-0.00274658203125","-0.00274658203125"
"ScaledDotProductEfficientAttentionBackward0","1428.990080999975","578.8101649999853","0","1.835722000007052","180","","12960.576171875","0","0","0"
"aten::_scaled_dot_product_efficient_attention_backward","1428.990080999975","576.9744429999784","0","4.433884999960894","180","","12960.576171875","0","0","0"
"aten::_efficient_attention_backward","1428.990080999975","567.9070139999825","1355.9170529999747","9.52729200003529","180","","12960.576171875","-8779.771484375","0","0"
"cudaFuncGetAttributes","0","0.9359770000001881","0","0.9359770000001881","180","","0","0","0","0"
"autograd::engine::evaluate_function: PermuteBackward0","0","7.660379999995698","0","3.265970000025816","540","","0","0","0","0"
"PermuteBackward0","0","4.394409999969881","0","1.4422459999872372","540","","0","0","0","0"
"autograd::engine::evaluate_function: SplitBackward0","110.82702900000429","8.833698000020348","0","1.649284000053769","180","","-0.576171875","-12960.576171875","0","0"
"SplitBackward0","110.82702900000429","7.184413999966578","0","0.8745299999576528","180","","12960","0","0","0"
"aten::cat","110.91422500000195","7.763731999997515","110.91422500000195","5.071059999983758","195","","12960.0146484375","12960.0146484375","0","0"
"autograd::engine::evaluate_function: EmbeddingBackward0","44.37109499996528","8.74757599999872","0","0.5657029999908991","30","","-360.8671875","-4822.986328125","0","0"
"EmbeddingBackward0","15.36953399996413","7.805022000002674","0","0.13555100000882522","30","","2253.5595703125","0","0","0"
"aten::embedding_backward","15.36953399996413","7.66947099999385","0","0.14852200000407173","30","","2253.5595703125","0","0","0"
"aten::embedding_dense_backward","15.36953399996413","7.520948999989778","7.071746999970172","2.2707999999991153","30","","2253.5595703125","-402.66357421875","0","0"
"cudaDeviceGetAttribute","0","0.054492999993031845","0","0.054492999993031845","75","","0","0","0","0"
"cudaPeekAtLastError","0","0.06739100000285543","0","0.06739100000285543","255","","0","0","0","0"
"aten::_foreach_norm","30.826854000012855","10.326448000005445","30.78477300000377","8.492599999993574","15","","1.083984375","-3.9111328125","0","0"
"aten::stack","0.08719599999766797","8.586432999998564","0","2.6514959999674463","15","","0.0146484375","0","0","0"
"aten::linalg_vector_norm","0.07302499999245629","0.6872069999936502","0.07302499999245629","0.5210839999907184","15","","0.00732421875","0.00732421875","0","0"
"aten::reciprocal","0.0318060000021942","0.4042160000011791","0.0318060000021942","0.24586300000641495","15","","0.00732421875","0.00732421875","0","0"
"aten::clamp","0.03398200000263751","0.4455670000014361","0.03398200000263751","0.30710000000311993","15","","0.00732421875","0.00732421875","0","0"
"aten::_foreach_mul_","193.45538500000023","8.58192300000228","193.45538500000023","5.982639999971027","45","","0","0","0","0"
"Optimizer.step#AdamW.step","632.3085899999197","89.0007810000123","0","35.996734000193655","15","","0","-7126.265625","0","-0.000057220458984375"
"aten::lift_fresh","0","0.009241999992635102","0","0.009241999992635102","15","","0","0","0","0"
"aten::detach_","0","0.05270299999974668","0","0.03207399999187328","15","","0","0","0","0"
"detach_","0","0.0206290000078734","0","0.0206290000078734","15","","0","0","0","0"
"aten::_foreach_add_","64.24275599999073","8.361130000007805","64.24275599999073","5.251132000006968","30","","0","0","0","0"
"aten::_foreach_lerp_","94.83913599997899","1.5261370000052266","94.83913599997899","0.8623299999998417","15","","0","0","0","0"
"aten::_foreach_addcmul_","94.61917399998335","3.7528810000026134","94.61917399998335","2.8752360001099295","15","","0","0","0","0"
"aten::item","0.025057000000029802","3552.9042569997955","0","4.257445999714313","4454","","0","0","0","0"
"aten::_local_scalar_dense","0.025057000000029802","3548.6468110000806","0.025057000000029802","1.5089690000806004","4454","","0","0","0","0"
"aten::_foreach_sqrt","64.07295999998273","19.68567000000295","64.07295999998273","5.560975999937859","15","","7126.265625","0","0","0"
"aten::_foreach_div_","64.17795399999711","3.3828400000033434","64.17795399999711","2.4591650000712835","15","","0","0","0","0"
"aten::_foreach_addcdiv_","120.71908399998769","3.9665220000003463","120.71908399998769","3.0274580000343265","15","","0","0","0","0"
"cudaDeviceSynchronize","0","1695.6392780000017","0","1695.6392780000017","7","","0","0","0","0"
"Optimizer.step#AdamW.step","633.0972099999981","0","633.0972099999981","0","15","","0","0","0","0"
"cudaHostAlloc","0","2.3375119999996388","0","2.3177520000003278","19","","-235","-235","0.0000152587890625","0"
"Memcpy DtoH (Device -> Pinned)","0.025057000000029802","0","0.025057000000029802","0","13","","0","0","0","0"
"aten::random_","0","0.034807999999728056","0","0.034807999999728056","1","","0","0","0","0"
"aten::set_","0","1.480428000004962","0","1.480428000004962","296","","0","0","0","0"
"Memcpy DtoH (Device -> Pageable)","90.85832500000019","0","90.85832500000019","0","148","","0","0","0","0"
"aten::native_dropout","53.05132700003125","113.39038000000268","53.05132700003125","9.855536999978126","350","","10501.525390625","0","0","0"
"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)","53.05132700003125","0","53.05132700003125","0","350","","0","0","0","0"
"aten::scalar_tensor","0","1.318868999991566","0","1.318868999991566","336","","0","0","0.0025634765625","0.0025634765625"
"autograd::engine::evaluate_function: NativeDropoutBackward0","41.25690600000136","17.513807000001893","0","2.815577000044286","350","","5962.94921875","-2437.05078125","0","0"
"NativeDropoutBackward0","41.25690600000136","14.698229999957606","0","1.2659669999703764","350","","8400","0","0","0"
"aten::native_dropout_backward","41.25690600000136","13.43226299998723","41.25690600000136","6.080452999955043","350","","8400","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)","41.25690600000136","0","41.25690600000136","0","350","","0","0","0","0"
"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)","1278.506448999975","0","1278.506448999975","0","168","","0","0","0","0"