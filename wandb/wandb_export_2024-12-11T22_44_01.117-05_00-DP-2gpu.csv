"Name","Device Time Total (ms)","CPU Time Total (ms)","Self Device Time Total (ms)","Self CPU Time Total (ms)","Calls","Input Shapes","Device Memory Usage (MB)","Self Device Memory Usage (MB)","CPU Memory Usage (MB)","Self CPU Memory Usage (MB)"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#2}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#2}, at::detail::Array<char*, 2>)","212.8048370000194","0","212.8048370000194","0","497","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)","816.1306270000649","0","816.1306270000649","0","2570","","0","0","0","0"
"ProfilerStep*","4255.319195999965","17066.545671000003","0","6160.679743000024","10","","-137554.9013671875","-190431.1875","0","-0.00000762939453125"
"void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)","1045.330269999993","0","1045.330269999993","0","2558","","0","0","0","0"
"enumerate(DataLoader)#_MultiProcessingDataLoaderIter.__next__","0","10.384725000001431","0","9.640421000001894","21","","0","0","0","0"
"aten::to","0.47388700000883544","5373.6904110000205","0","1.0463050000163494","2320","","-61.1201171875","-64.875","0","0"
"aten::_to_copy","0.47388700000883544","5372.644106000004","0","1.6067780000111087","90","","3.7548828125","0","0","0"
"aten::empty_strided","0","18.793467000052374","0","17.757644000051584","1960","","9548.1455078125","9548.1455078125","0","0"
"aten::copy_","3098.343941999986","5552.842498999982","3098.343941999986","39.76683999996586","1558","","242.634765625","451.08642578125","0.00000762939453125","0.00000762939453125"
"cudaMemcpyAsync","0","131.677180000002","0","131.677180000002","351","","147.23681640625","147.23681640625","0","0"
"cudaStreamSynchronize","0","8396.740040999994","0","8396.659396999992","201","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::tanh_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::tanh_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)","214.9030770000107","0","214.9030770000107","0","498","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<float>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<float>, at::detail::Array<char*, 2>)","214.92761700001816","0","214.92761700001816","0","509","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)","841.2702180000233","0","841.2702180000233","0","1554","","0","0","0","0"
"Memset (Device)","4.870272000033722","0","4.870272000033722","0","3666","","0","0","0","0"
"ampere_sgemm_128x128_nn","750.9066710000031","0","750.9066710000031","0","498","","0","0","0","0"
"cudaPointerGetAttributes","0","0.33881700000384624","0","0.3009570000016483","56","","-16.5146484375","-16.5146484375","0","0"
"void at::native::(anonymous namespace)::vectorized_layer_norm_kernel<float, float>(int, float, float const*, float const*, float const*, float*, float*, float*)","40.4848359999975","0","40.4848359999975","0","1034","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_128x64_8x5_nn_align1>(cutlass_80_simt_sgemm_128x64_8x5_nn_align1::Params)","566.2933460000091","0","566.2933460000091","0","496","","0","0","0","0"
"fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEffAttention::AttentionKernel<float, cutlass::arch::Sm80, true, 64, 64, 64, true, true>::Params)","558.8095659999883","0","558.8095659999883","0","496","","0","0","0","0"
"ampere_sgemm_128x64_nn","200.71166300000746","0","200.71166300000746","0","496","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_256x128_8x4_nn_align1>(cutlass_80_simt_sgemm_256x128_8x4_nn_align1::Params)","1216.8208499999798","0","1216.8208499999798","0","518","","0","0","0","0"
"ampere_sgemm_128x128_tn","1298.823011999998","0","1298.823011999998","0","42","","0","0","0","0"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1} const&)::{lambda(int)#1})","1407.4846919999866","0","1407.4846919999866","0","1336","","0","0","0","0"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1} const&)::{lambda(int)#1})","0.25085200000084296","0","0.25085200000084296","0","42","","0","0","0","0"
"void at::native::(anonymous namespace)::cunn_SoftMaxForward<4, float, float, float, at::native::(anonymous namespace)::LogSoftMaxForwardEpilogue>(float*, float const*, int)","297.8627349999987","0","297.8627349999987","0","42","","0","0","0","0"
"void at::native::(anonymous namespace)::nll_loss_forward_reduce_cuda_kernel_2d<float, float, long>(float*, float*, float const*, long const*, float const*, bool, long, long, long, long)","7.929948000005519","0","7.929948000005519","0","42","","0","0","0","0"
"Memcpy DtoD (Device -> Device)","301.4362400000043","0","301.4362400000043","0","64","","0","0","0","0"
"Memcpy PtoP (Device -> Device)","1746.6065810000068","0","1746.6065810000068","0","93","","0","0","0","0"
"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::MeanOps<float, float, float, float>, unsigned int, float, 4>)","0.06589000000030501","0","0.06589000000030501","0","21","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)","222.29785200001538","0","222.29785200001538","0","132","","0","0","0","0"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BUnaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})","0.018590999996871686","0","0.018590999996871686","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::nll_loss_backward_reduce_cuda_kernel_2d<float, long>(float*, float const*, long const*, float const*, float const*, bool, int, int, long, long)","1.468032000000705","0","1.468032000000705","0","22","","0","0","0","0"
"void at::native::(anonymous namespace)::cunn_SoftMaxBackward<4, float, float, float, at::native::(anonymous namespace)::LogSoftMaxBackwardEpilogue>(float*, float const*, float const*, long)","268.89758499999704","0","268.89758499999704","0","22","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_128x256_8x4_nt_align1>(cutlass_80_simt_sgemm_128x256_8x4_nt_align1::Params)","843.790341999989","0","843.790341999989","0","550","","0","0","0","0"
"void at::native::(anonymous namespace)::layer_norm_grad_input_kernel_vectorized<float, float>(float const*, float const*, float const*, float const*, float const*, float*, int)","63.7657530000087","0","63.7657530000087","0","550","","0","0","0","0"
"void at::native::(anonymous namespace)::GammaBetaBackwardCUDAKernel_32x32<float, float>(long, long, float const*, float const*, float const*, float const*, float*, float*)","18.32772099998669","0","18.32772099998669","0","550","","0","0","0","0"
"ampere_sgemm_128x64_tn","1445.3176960000094","0","1445.3176960000094","0","1056","","0","0","0","0"
"void cutlass::Kernel<cutlass_80_simt_sgemm_128x64_8x5_nt_align1>(cutlass_80_simt_sgemm_128x64_8x5_nt_align1::Params)","417.05966399999613","0","417.05966399999613","0","264","","0","0","0","0"
"void at::native::reduce_kernel<128, 4, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)","85.52473299999204","0","85.52473299999204","0","1078","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::tanh_backward_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3> >(int, at::native::tanh_backward_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float, float)#1}, at::detail::Array<char*, 3>)","168.50945299999265","0","168.50945299999265","0","264","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::pow_tensor_scalar_kernel_impl<float, float>(at::TensorIteratorBase&, float)::{lambda(float)#1}, at::detail::Array<char*, 2>)","113.63374500002206","0","113.63374500002206","0","264","","0","0","0","0"
"ampere_sgemm_128x128_nt","441.3361289999895","0","441.3361289999895","0","264","","0","0","0","0"
"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)","12.051710000006132","0","12.051710000006132","0","264","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<unsigned char>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<unsigned char>, at::detail::Array<char*, 1>)","6.446389999993844","0","6.446389999993844","0","264","","0","0","0","0"
"fmha_cutlassB_f32_aligned_64x64_k64_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, false, false, 64, 64, 64, false>::Params)","583.6880130000056","0","583.6880130000056","0","168","","0","0","0","0"
"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 3, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)","69.45584799999918","0","69.45584799999918","0","264","","0","0","0","0"
"void at::native::(anonymous namespace)::embedding_backward_feature_kernel<float, float, long>(long const*, float const*, float*, int, long, int)","0.8154220000037458","0","0.8154220000037458","0","22","","0","0","0","0"
"void (anonymous namespace)::elementwise_kernel_with_index<int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}, function_traits<at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>::result_type*)","0.0791030000000028","0","0.0791030000000028","0","62","","0","0","0","0"
"void at_cuda_detail::cub::DeviceRadixSortHistogramKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy800, false, long, unsigned long long>(unsigned long long*, long const*, unsigned long long, int, int)","0.14204599999950734","0","0.14204599999950734","0","22","","0","0","0","0"
"void at_cuda_detail::cub::DeviceRadixSortExclusiveSumKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy800, unsigned long long>(unsigned long long*)","0.04828500000422355","0","0.04828500000422355","0","22","","0","0","0","0"
"void at_cuda_detail::cub::DeviceRadixSortOnesweepKernel<at_cuda_detail::cub::DeviceRadixSortPolicy<long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long>::Policy800, false, long, at::cuda::cub::detail::OpaqueType<8>, unsigned long long, int, int>(int*, int*, unsigned long long*, unsigned long long const*, long*, long const*, at::cuda::cub::detail::OpaqueType<8>*, at::cuda::cub::detail::OpaqueType<8> const*, int, int, int)","1.8434869999963557","0","1.8434869999963557","0","176","","0","0","0","0"
"void at_cuda_detail::cub::DeviceCompactInitKernel<at_cuda_detail::cub::ScanTileState<int, true>, long*>(at_cuda_detail::cub::ScanTileState<int, true>, int, long*)","0.09382299999718088","0","0.09382299999718088","0","22","","0","0","0","0"
"void at_cuda_detail::cub::DeviceUniqueByKeySweepKernel<at_cuda_detail::cub::DeviceUniqueByKeyPolicy<long const*>::Policy520, long const*, thrust::counting_iterator<int, thrust::use_default, thrust::use_default, thrust::use_default>, long*, long*, long*, at_cuda_detail::cub::ScanTileState<int, true>, at_cuda_detail::cub::Equality, int>(long const*, thrust::counting_iterator<int, thrust::use_default, thrust::use_default, thrust::use_default>, long*, long*, long*, at_cuda_detail::cub::ScanTileState<int, true>, at_cuda_detail::cub::Equality, int, int)","0.13059299999347423","0","0.13059299999347423","0","22","","0","0","0","0"
"void at::native::(anonymous namespace)::krn_partials_per_segment<long>(long*, long const*, long const*, long)","0.05199799999629613","0","0.05199799999629613","0","22","","0","0","0","0"
"void at_cuda_detail::cub::DeviceScanInitKernel<at_cuda_detail::cub::ScanTileState<long, true> >(at_cuda_detail::cub::ScanTileState<long, true>, int)","0.03526500000280794","0","0.03526500000280794","0","22","","0","0","0","0"
"void at_cuda_detail::cub::DeviceScanKernel<at_cuda_detail::cub::DeviceScanPolicy<long>::Policy600, long const*, long*, at_cuda_detail::cub::ScanTileState<long, true>, at::cuda::cub::(anonymous namespace)::SumOp<long>, at_cuda_detail::cub::detail::InputValue<long, long*>, int, long>(long const*, long*, at_cuda_detail::cub::ScanTileState<long, true>, int, at::cuda::cub::(anonymous namespace)::SumOp<long>, at_cuda_detail::cub::detail::InputValue<long, long*>, int)","0.0907170000023907","0","0.0907170000023907","0","22","","0","0","0","0"
"void at::native::(anonymous namespace)::compute_num_of_partial_segments<long>(long const*, long const*, long const*, long*)","0.04630299999867566","0","0.04630299999867566","0","22","","0","0","0","0"
"void at::native::(anonymous namespace)::krn_partial_segment_offset<long>(long*, long const*, long const*, long const*, long const*)","0.0742740000007907","0","0.0742740000007907","0","22","","0","0","0","0"
"void at::native::(anonymous namespace)::compute_grad_weight<float, long>(long const*, float const*, long const*, long, long, long const*, long const*, at::AccumulateType<float, true>::type*, long)","2.2432320000056643","0","2.2432320000056643","0","22","","0","0","0","0"
"void at::native::(anonymous namespace)::sum_and_scatter<float, long>(long const*, float*, long, long const*, long const*, at::AccumulateType<float, true>::type const*, long const*, long const*, long, long)","0.9233940000000875","0","0.9233940000000875","0","22","","0","0","0","0"
"ncclDevKernel_Reduce_Sum_f32_RING_LL(ncclDevComm*, unsigned long, ncclWork*)","1045.6893100000336","0","1045.6893100000336","0","836","","0","0","0","0"
"void at::native::(anonymous namespace)::CatArrayBatchedCopy_aligned16_contig<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<4u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<4u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)","72.88371499997122","0","72.88371499997122","0","1336","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::LpNormFunctor<float, (at::native::NormType)1, float, 1, 1, 0>, float*, int>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::LpNormFunctor<float, (at::native::NormType)1, float, 1, 1, 0>, float*, int)","22.071359000007504","0","22.071359000007504","0","77","","0","0","0","0"
"void at::native::lpnorm_cleanup<float, (at::native::NormType)1, float, float>(float const*, at::native::TensorListAddresses, int)","0.04425500000291504","0","0.04425500000291504","0","11","","0","0","0","0"
"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::NormTwoOps<float, float, float>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::NormTwoOps<float, float, float>, unsigned int, float, 4>)","0.036127000001375566","0","0.036127000001375566","0","11","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::reciprocal_kernel_cuda(at::TensorIteratorBase&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::reciprocal_kernel_cuda(at::TensorIteratorBase&)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)","0.01583900000003632","0","0.01583900000003632","0","11","","0","0","0","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::(anonymous namespace)::launch_clamp_scalar(at::TensorIteratorBase&, c10::Scalar, c10::Scalar, at::native::detail::ClampLimits)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)","0.017537000002572314","0","0.017537000002572314","0","11","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarTensorFunctor<float, 1, 1, 0>, std::multiplies<float>, float*, float>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarTensorFunctor<float, 1, 1, 0>, std::multiplies<float>, float*, float)","46.601284000003126","0","46.601284000003126","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::multiplies<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::multiplies<float>, float)","94.71305399999838","0","94.71305399999838","0","154","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::TernaryOpScalarFunctor<float, 2, 2, 0>, at::native::LerpFunctor<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::TernaryOpScalarFunctor<float, 2, 2, 0>, at::native::LerpFunctor<float>, float)","69.31439900000277","0","69.31439900000277","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<3>, at::native::(anonymous namespace)::PointwiseOpScalarFunctor<float, 3, 3, 0>, std::multiplies<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<3>, at::native::(anonymous namespace)::PointwiseOpScalarFunctor<float, 3, 3, 0>, std::multiplies<float>, float)","69.28902800000121","0","69.28902800000121","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::UnaryOpFunctor<float, 2, 1, 1>, at::native::Sqrt<float> >(at::native::(anonymous namespace)::TensorListMetadata<2>, at::native::(anonymous namespace)::UnaryOpFunctor<float, 2, 1, 1>, at::native::Sqrt<float>)","46.84589299998979","0","46.84589299998979","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 1>, at::native::(anonymous namespace)::BinaryOpScalarListFunctor<float, 1, 1, 0>, std::divides<float> >(at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 1>, at::native::(anonymous namespace)::BinaryOpScalarListFunctor<float, 1, 1, 0>, std::divides<float>)","46.91881700000155","0","46.91881700000155","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::plus<float>, float>(at::native::(anonymous namespace)::TensorListMetadata<1>, at::native::(anonymous namespace)::BinaryOpScalarFunctor<float, 1, 1, 0>, std::plus<float>, float)","47.060284999996306","0","47.060284999996306","0","77","","0","0","0","0"
"void at::native::(anonymous namespace)::multi_tensor_apply_kernel<at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 3>, at::native::(anonymous namespace)::PointwiseOpScalarListFunctor<float, 3, 3, 0>, std::divides<float> >(at::native::(anonymous namespace)::TensorListScalarListMetadata<float, 3>, at::native::(anonymous namespace)::PointwiseOpScalarListFunctor<float, 3, 3, 0>, std::divides<float>)","88.40492600000545","0","88.40492600000545","0","77","","0","0","0","0"
"ProfilerStep*","16624.768705","0","16624.768705","0","10","","0","0","0","0"
"Memcpy HtoD (Pinned -> Device)","0.31830500000156464","0","0.31830500000156464","0","40","","0","0","0","0"
"DataParallel.forward","3664.836090999955","1052.8274100000065","0","541.7864800000403","20","","52873.0146484375","-3623.11328125","0","0"
"Scatter","0.15558200000727085","15.068736000000033","0","4.292031000000308","50","","1.2548828125","0","0","0"
"aten::chunk","0","1.781459999997285","0","0.29056099998916035","40","","0","0","0","0"
"aten::split","0","1.4908990000081248","0","0.5089980000162031","40","","0","0","0","0"
"aten::narrow","0","37.85124800002412","0","11.861063000046066","5000","","0","0","0","0"
"aten::slice","0","26.2443879999771","0","21.620426999954738","5040","","-3113.99658203125","-2329.49755859375","0","0"
"aten::as_strided","0","13.782503000013763","0","13.782503000013763","13000","","-2314.2236328125","-2314.2236328125","0.00002288818359375","0.00002288818359375"
"cudaEventRecord","0","8.387538999971003","0","8.387538999971003","4900","","0","0","0","0"
"cudaStreamWaitEvent","0","10.337700000008219","0","10.337700000008219","4900","","0","0","0","0"
"DataParallel.forward","14008.726293000002","0","14008.726293000002","0","40","","0","0","0","0"
"Broadcast","938.1138339999624","88.22496099999978","920.1008079999846","26.79185499999742","10","","4849.5703125","-3351.568359375","0","0"
"aten::flatten_dense_tensors","71.32262899997562","74.03702899996587","0","17.478311999938917","1320","","13572.8212890625","0","0","0"
"aten::view","0","32.87209900002228","0","32.84882200002251","16800","","-2902.48046875","-2902.48046875","0","0"
"aten::empty","0","57.584261999954585","0","51.467545999954574","4577","","103874.0771484375","103874.0771484375","0.00005340576171875","0.00005340576171875"
"cudaStreamGetCaptureInfo_v2","0","1.7318120000372874","0","1.7318120000372874","1880","","0","0","0","0"
"cudaLaunchKernelExC","0","16.84703899999836","0","16.84703899999836","1880","","0","0","0","0"
"ncclDevKernel_Broadcast_RING_LL(ncclDevComm*, unsigned long, ncclWork*)","1889.1260079999738","0","1889.1260079999738","0","1120","","0","0","0","0"
"aten::unflatten_dense_tensors","0","63.4875709999958","0","18.515907999942428","940","","0","0","0","0"
"aten::cat","134.49943899997615","55.15280300001591","134.49943899997615","37.3202060000617","1530","","20927.48876953125","21587.15234375","0","0.00000762939453125"
"cudaLaunchKernel","0","408.474764999948","0","315.3564909999394","20980","","-5450.2529296875","-5450.2529296875","0","0"
"aten::view_as","0","6.2278069999959556","0","3.2964479999934557","1480","","0","0","0","0"
"cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags","0","4.7095659999975465","0","4.704730999997468","1756","","732.88427734375","732.88427734375","0","0"
"cudaStreamIsCapturing","0","2.191056999966968","0","2.191056999966968","1381","","-72.015625","-72.015625","0.00000762939453125","0.00000762939453125"
"cudaFuncSetAttribute","0","668.1304509999801","0","668.0853009999797","1239","","-149.48828125","-149.48828125","0","0"
"cudaMemsetAsync","0","26.59581599995156","0","26.509116999946883","3349","","-4945.2470703125","-4945.2470703125","-0.00006866455078125","-0.00006866455078125"
"Gather","2706.6409859999826","96.88699199999357","0","30.151723000011522","520","","42930.634765625","0","0","0"
"aten::split_with_sizes","0","7.732105000010226","0","6.196614999984507","530","","0","0","0","0"
"cudaFree","0","846.3771129999968","0","846.3771129999968","222","","0","0","0","0"
"void at::native::(anonymous namespace)::CatArrayBatchedCopy_contig<at::native::(anonymous namespace)::OpaqueType<1u>, unsigned int, 1, 128, 1>(at::native::(anonymous namespace)::OpaqueType<1u>*, at::native::(anonymous namespace)::CatArrInputTensorMetadata<at::native::(anonymous namespace)::OpaqueType<1u>, unsigned int, 128, 1>, at::native::(anonymous namespace)::TensorSizeStride<unsigned int, 4u>, int, unsigned int)","1.8242570000054548","0","1.8242570000054548","0","40","","0","0","0","0"
"void at::native::(anonymous namespace)::indexSelectLargeIndex<float, long, unsigned int, 2, 2, -2, true>(at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<long const, unsigned int>, int, int, unsigned int, unsigned int, long)","3.253852999994182","0","3.253852999994182","0","80","","0","0","0","0"
"void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})","0.8423960000039078","0","0.8423960000039078","0","40","","0","0","0","0"
"aten::mean","0.06278600000031292","1.97376500000339","0.06278600000031292","1.3720080000015442","20","","0.009765625","0.009765625","0","0"
"aten::ones_like","0.010945000002160669","0.5662849999971222","0","0.07358299999730661","10","","0.0048828125","0","0","0"
"aten::empty_like","0","11.718247999956366","0","3.3166609999060164","870","","6342.11669921875","-409.85693359375","-0.00000762939453125","-0.00000762939453125"
"aten::fill_","208.32002300000912","8.140192999996245","208.32002300000912","3.24872300002072","360","","2112.119140625","1883.30615234375","0","0"
"autograd::engine::evaluate_function: MeanBackward0","0.01689599999692291","1.6891410000002942","0","0.21855999999656342","10","","0.0048828125","0","0","0"
"MeanBackward0","0.01689599999692291","1.470581000003731","0","0.24390300000016576","10","","0.0048828125","0","0","0"
"aten::expand","0","0.1785450000022538","0","0.14507400000304915","10","","0","0","0","0"
"aten::div","0.01689599999692291","1.0481330000013114","0.01689599999692291","0.7820869999986607","10","","0.0048828125","0.0048828125","0","0"
"autograd::engine::evaluate_function: GatherBackward","0.01648200000356883","4.252742000000784","0","0.23507800000044518","10","","0.0048828125","0","0","0"
"GatherBackward","0.01648200000356883","4.017664000000339","0","1.0065299999995623","10","","0.0048828125","0","0","0"
"aten::select","0","0.17179600000102074","0","0.15315100000449455","20","","0","0","0","0"
"autograd::engine::evaluate_function: NllLossBackward0","65.50039400000288","13.696807999997167","0","1.3000159999986645","20","","13337.0498046875","-6276.7333984375","0","0"
"NllLossBackward0","65.50039400000288","12.396791999998502","0","0.24171599999442697","20","","19613.783203125","-1568.998046875","0","0"
"aten::nll_loss_backward","65.50039400000288","12.155076000004076","1.3356150000006892","0.676458999998169","20","","21182.78125","16474.447265625","0","0"
"aten::zero_","208.30907800000696","9.638090000002412","0","1.7951090000062249","350","","1519.919921875","-592.19921875","0","0"
"autograd::engine::evaluate_function: LogSoftmaxBackward0","244.92360699999705","17.822915999994844","0","0.3088349999892525","20","","-15098.87646484375","-30595.5576171875","0","0"
"LogSoftmaxBackward0","244.92360699999705","17.514081000005593","0","0.16121299999998884","20","","15496.68115234375","784.4990234375","0","0"
"aten::_log_softmax_backward_data","244.92360699999705","17.352868000005603","244.92360699999705","0.47872800000547433","20","","14712.18212890625","15691.48095703125","0","0"
"cudaMalloc","0","75.35802200000407","0","73.69511400000891","207","","-979.3310546875","-979.3310546875","0","0"
"autograd::engine::evaluate_function: ViewBackward0","0","49.16642299999297","0","26.48686900000181","2940","","-9903.42431640625","-6244.361328125","-0.00006103515625","-0.000030517578125"
"ViewBackward0","0","22.679553999991157","0","8.941840000018944","2940","","-3659.06298828125","-2352.5439453125","-0.000030517578125","-0.00002288818359375"
"aten::reshape","0","13.852408999970649","0","6.734006999991136","2960","","-2728.09228515625","-138.75","-0.00000762939453125","-0.00000762939453125"
"autograd::engine::evaluate_function: CloneBackward0","0","0.14430700000282376","0","0.12864099999843165","20","","907.73583984375","907.73583984375","0","0"
"CloneBackward0","0","0.015666000004392118","0","0.015666000004392118","20","","0","0","0","0"
"autograd::engine::evaluate_function: SliceBackward0","410.4576370000045","4.11823899999354","0","0.42744699999294244","40","","-7762.13623046875","-31391.22265625","0","0"
"SliceBackward0","410.4576370000045","3.690792000000598","0","0.15773900000192226","40","","23629.08642578125","-774.00048828125","0","0"
"aten::slice_backward","410.4576370000045","3.5330529999986755","0","0.4716590000053402","40","","24403.0869140625","-5345.7880859375","0","0"
"aten::zeros","138.26648500001104","3.6846900000076275","0","0.5645390000049956","90","","34764.1865234375","1510.4990234375","0","0"
"autograd::engine::evaluate_function: UnsafeViewBackward0","0","0.3174529999997467","0","0.1374360000032466","20","","-2990.5712890625","-1568.998046875","0","0"
"UnsafeViewBackward0","0","0.1800169999965001","0","0.0653219999980647","20","","-1421.5732421875","0","0","0"
"autograd::engine::evaluate_function: MmBackward0","839.148304000001","4.36150600000564","0","0.454037000003038","20","","-19829.81640625","-18113.486328125","0","0"
"MmBackward0","839.148304000001","3.907469000002602","0","0.41366500000702217","20","","-1716.330078125","-22.2998046875","0","0"
"aten::t","0","18.19258199997898","0","7.816606999959331","2000","","-2554.111328125","-1470.58642578125","0.00006103515625","0.0000457763671875"
"aten::transpose","0","19.948178999997907","0","13.963030000023776","4400","","-1274.970703125","152.365234375","0.00003814697265625","0.00002288818359375"
"aten::mm","3335.355576999978","98.31541400004411","3335.355576999978","61.40121400006418","1960","","13898.5654296875","19579.13427734375","-0.00003814697265625","0.00002288818359375"
"autograd::engine::evaluate_function: TBackward0","0","0.4435909999967553","0","0.25608000000147146","20","","207.2119140625","171.2216796875","0","0"
"TBackward0","0","0.18751099999528378","0","0.0438349999957718","20","","35.990234375","36.0029296875","0","0"
"autograd::engine::evaluate_function: NativeLayerNormBackward0","102.8720530000485","64.57833899997733","0","14.517206999974558","500","","-19061.99169921875","-22018.30712890625","-0.00000762939453125","-0.000030517578125"
"NativeLayerNormBackward0","74.6827839999951","39.9946230000176","0","4.149684000016656","500","","3266.99365234375","-245.6513671875","0.000030517578125","0"
"aten::native_layer_norm_backward","74.6827839999951","35.84493900000094","74.6827839999951","11.667312000064644","500","","3512.64501953125","-1256.64990234375","0.000030517578125","0"
"autograd::engine::evaluate_function: AddBackward0","0.4221129999978002","11.548909000006038","0","9.898205000006127","980","","-2520.5908203125","-2472.5654296875","-0.00000762939453125","-0.00000762939453125"
"AddBackward0","0","1.0385969999956433","0","1.0385969999956433","980","","24.009765625","24.009765625","0","0"
"autograd::engine::evaluate_function: AddmmBackward0","2574.766103999991","206.53912099998863","0","29.149051999994786","960","","-43453.55517578125","-44934.86572265625","0.00003814697265625","0.00008392333984375"
"AddmmBackward0","2496.2072729999772","126.16801599998516","0","13.297499999957159","960","","9882.15576171875","-3156.34130859375","0.00000762939453125","-0.0000152587890625"
"cudaOccupancyMaxActiveBlocksPerMultiprocessor","0","2.1352389999972656","0","2.1352389999972656","1200","","-37.82763671875","-37.82763671875","0","0"
"aten::sum","89.95268700001738","57.76401999998116","89.95268700001738","41.137368999998316","1220","","-8713.8212890625","-6686.09619140625","-0.00006103515625","-0.00000762939453125"
"autograd::engine::evaluate_function: MulBackward0","745.1745929999852","51.96625999997347","0","14.411439999992494","960","","-19282.16015625","-71435.0517578125","0.00005340576171875","-0.0000457763671875"
"MulBackward0","590.5368999999796","33.91505999998329","0","4.375159999964992","960","","51820.0498046875","-334.1572265625","0.00006866455078125","0.000030517578125"
"aten::mul","873.6453739999929","49.15001300003729","873.6453739999929","32.52165100003872","1930","","74533.39404296875","76525.0458984375","0.000030517578125","0.0000152587890625"
"autograd::engine::evaluate_function: TanhBackward0","153.19982399999282","10.708284999996424","0","2.8647039999936244","240","","-15089.8974609375","-24115.1337890625","0.00000762939453125","-0.000030517578125"
"TanhBackward0","153.19982399999282","7.8435810000028","0","1.2953649999992922","240","","9025.236328125","-261.36669921875","0.00003814697265625","0.00000762939453125"
"aten::tanh_backward","153.19982399999282","6.5482160000035075","153.19982399999282","4.237042000006884","240","","9286.60302734375","10056.8642578125","0.000030517578125","0.00002288818359375"
"autograd::engine::evaluate_function: PowBackward0","516.9096990000223","33.48095499999099","0","6.228031999967061","240","","-29081.83447265625","-35475.1953125","-0.00000762939453125","-0.00000762939453125"
"PowBackward0","365.3038320000183","22.656740000016057","0","2.526572000004351","240","","6968.6142578125","-23957.4580078125","0.00000762939453125","-0.00000762939453125"
"aten::pow","103.29963300002203","8.064862000006483","103.29963300002203","5.613473999991547","240","","10073.0615234375","10574.7607421875","0.0000152587890625","0.00000762939453125"
"aten::result_type","0","1.124518000050215","0","1.124518000050215","9120","","-12","-12","0","0"
"aten::add_","334.432829000063","20.204908999977633","334.432829000063","12.892127999957884","2440","","-553.08984375","287.2255859375","0.0000152587890625","0.00000762939453125"
"autograd::engine::evaluate_function: TransposeBackward0","0","4.21659899999178","0","1.9866639999987092","240","","-690.279296875","-291.6376953125","0.00000762939453125","0"
"TransposeBackward0","0","2.229934999993071","0","0.5011999999852851","240","","-398.6416015625","-56.076171875","0.00000762939453125","0"
"autograd::engine::evaluate_function: ScaledDotProductEfficientAttentionBackward0","910.4807610000192","744.455697999998","0","6.157630999998888","240","","-15204.3203125","-14400.75390625","-0.0000152587890625","-0.00000762939453125"
"ScaledDotProductEfficientAttentionBackward0","910.4807610000192","738.2980669999992","0","2.7605369999981484","240","","-803.56640625","-600.78466796875","-0.00000762939453125","-0.00000762939453125"
"aten::_scaled_dot_product_efficient_attention_backward","910.4807610000192","735.537530000001","0","6.77214600003208","240","","-202.78173828125","-935.04248046875","0","0"
"aten::_efficient_attention_backward","910.4807610000192","721.9124500000019","871.6126589999996","11.722318000026513","240","","593.572265625","-9525.65673828125","-0.0000152587890625","-0.00002288818359375"
"aten::contiguous","0.9269750000035856","10.108523000004002","0","0.43874799998942765","240","","-1063.47509765625","107.98291015625","0.0000152587890625","0"
"aten::clone","0.9269750000035856","9.669775000014575","0","1.3080570000112057","240","","-1171.4580078125","-156.2509765625","0.0000152587890625","0.00000762939453125"
"cudaFuncGetAttributes","0","1.2575160000005272","0","1.2575160000005272","240","","-163.029296875","-163.029296875","0","0"
"autograd::engine::evaluate_function: PermuteBackward0","0","12.191821999988052","0","5.9505760000117585","720","","-1183.0537109375","-942.33447265625","0.00000762939453125","0"
"PermuteBackward0","0","6.241245999976294","0","2.1262629999790805","720","","-240.71923828125","213.72119140625","0.00000762939453125","-0.00000762939453125"
"aten::permute","0","4.114982999997213","0","3.475172000012593","720","","-454.4404296875","-383.564453125","0.0000152587890625","0.0000152587890625"
"autograd::engine::evaluate_function: SplitBackward0","63.138665999999034","13.685679999993882","0","3.1231310000012162","240","","-1801.4638671875","-8881.2265625","0.0000152587890625","0.0000152587890625"
"SplitBackward0","63.138665999999034","10.562548999992664","0","1.1735730000000912","240","","7079.7626953125","-274.89501953125","0","0"
"autograd::engine::evaluate_function: EmbeddingBackward0","56.28940400001663","13.46529999999539","0","0.9240400000088849","40","","-529.3828125","-6331.77783203125","0","0"
"EmbeddingBackward0","17.26823500001826","12.021253999992506","0","0.23887399998493491","40","","2762.45751953125","-0.0224609375","0","0"
"aten::embedding_backward","17.26823500001826","11.782380000007572","0","0.14168800000986084","40","","2762.47998046875","43.87548828125","0","0"
"aten::embedding_dense_backward","17.26823500001826","11.640691999997712","6.234323000009172","3.5885900000240656","40","","2718.6044921875","-557.3828125","0","0"
"aten::arange","0.06885800000885502","1.5906819999953732","0.03442900000442751","0.4182540000018198","40","","77.20849609375","93.0791015625","0","0"
"aten::resize_","0","0.12827599999890663","0","0.12827599999890663","20","","-1.59375","-1.59375","0","0"
"cudaDeviceGetAttribute","0","0.07654700000025332","0","0.07654700000025332","100","","-1.1591796875","-1.1591796875","0","0"
"cudaPeekAtLastError","0","0.07040100001357495","0","0.07040100001357495","340","","0","0","0","0"
"aten::add","39.03595299999695","0.821176999996882","39.03595299999695","0.5718229999956674","30","","3039.9423828125","3039.91064453125","0","0"
"autograd::engine::evaluate_function: BroadcastBackward","983.3576610000248","130.7397569999958","0","5.24179899999639","10","","-4863.390625","-9618.466796875","0","0"
"BroadcastBackward","983.3576610000248","125.4979579999994","0","3.572581999997143","10","","4755.076171875","0","0","0"
"ReduceAddCoalesced","983.3576610000248","121.92537600000226","949.9902290000338","48.86571400009934","10","","4755.076171875","-6565.1103515625","0","0"
"autograd::engine::evaluate_function: torch::autograd::AccumulateGrad","0","15.382938999973703","0","8.08269099990162","1480","","0","0","0","0"
"torch::autograd::AccumulateGrad","0","7.300248000072083","0","3.8212350000599398","1480","","0","0","0","0"
"aten::detach","0","3.8710790000006092","0","1.9401420000053478","1629","","0","0","0","0"
"detach","0","1.9309369999952615","0","1.9309369999952615","1629","","0","0","0","0"
"aten::_foreach_norm","20.11759800001164","7.197699000000255","20.105438000010327","6.018159000000218","10","","0.72265625","-2.607421875","0","0"
"aten::stack","0.038144000001484525","6.095828000001609","0","2.0112010000231675","10","","0.009765625","0","0","0"
"aten::unsqueeze","0","3.1244989999770185","0","2.4903349999634083","1480","","0","0","0","0"
"aten::linalg_vector_norm","0.03292700000130572","0.5285009999966714","0.03292700000130572","0.3910689999973401","10","","0.0048828125","0.0048828125","0","0"
"aten::reciprocal","0.01443100000009872","0.2933539999995846","0.01443100000009872","0.18869100000313482","10","","0.0048828125","0.0048828125","0","0"
"aten::clamp","0.01593700000247918","0.31751199999870733","0.01593700000247918","0.21043999999691732","10","","0.0048828125","0.0048828125","0","0"
"aten::_foreach_mul_","128.3753870000015","6.1496790000000034","128.3753870000015","4.319599999984028","30","","0","0","0","0"
"Optimizer.step#AdamW.step","420.38981599999545","70.40034499999672","0","26.42927700005914","10","","0","-4789.3095703125","0","-0.00003814697265625"
"aten::lift_fresh","0","0.006633000000845641","0","0.006633000000845641","10","","0","0","0","0"
"aten::detach_","0","0.03782100000185892","0","0.02465800000168383","10","","0","0","0","0"
"detach_","0","0.013163000000175088","0","0.013163000000175088","10","","0","0","0","0"
"aten::_foreach_add_","42.77910199999646","6.736188000001712","42.77910199999646","4.137496000009123","20","","0","0","0","0"
"aten::_foreach_lerp_","63.014014000002994","1.0980969999954104","63.014014000002994","0.6229499999890104","10","","0","0","0","0"
"aten::_foreach_addcmul_","62.966403000001094","2.9015900000000836","62.966403000001094","2.2424899999802","10","","0","0","0","0"
"aten::item","0.021857999999076127","3041.336223999941","0","3.7496899999454616","2974","","0","0","0","0"
"aten::_local_scalar_dense","0.021857999999076127","3037.5865339999955","0.021857999999076127","1.4356429999936373","2974","","0","0","0","0"
"aten::_foreach_sqrt","42.58502699998952","17.388499000001932","42.58502699998952","5.361416999952635","10","","4789.3095703125","0","0","0"
"aten::_foreach_div_","42.63299200000148","2.697015999999363","42.63299200000148","2.0228789999694565","10","","0","0","0","0"
"aten::_foreach_addcdiv_","80.37046100000548","3.4180609999964946","80.37046100000548","2.6919699999929874","10","","0","0","0","0"
"Optimizer.step#AdamW.step","420.76828599999936","0","420.76828599999936","0","10","","0","0","0","0"
"cudaDeviceSynchronize","0","1045.7064620000012","0","1045.7064620000012","12","","0","0","0","0"
"cudaHostAlloc","0","3.590675999998115","0","1.7569359999978915","19","","17.505859375","1.505859375","0","0"
"Memcpy DtoH (Device -> Pinned)","0.021857999999076127","0","0.021857999999076127","0","13","","0","0","0","0"
"aten::random_","0","0.02090000000037253","0","0.02090000000037253","1","","0","0","0","0"
"aten::set_","0","1.5209619999863206","0","1.5209619999863206","296","","0","0","0","0"
"Memcpy DtoH (Device -> Pageable)","107.09929899999126","0","107.09929899999126","0","148","","0","0","0","0"
"void at::native::(anonymous namespace)::fused_dropout_kernel_vec<float, float, unsigned int, 1, 4, bool>(at::cuda::detail::TensorInfo<float const, unsigned int>, at::cuda::detail::TensorInfo<float, unsigned int>, at::cuda::detail::TensorInfo<bool, unsigned int>, unsigned int, float, at::PhiloxCudaState)","8.600938999958336","0","8.600938999958336","0","200","","0","0","0","0"
"autograd::engine::evaluate_function: NativeDropoutBackward0","4.8398399999961255","11.076229999981821","0","2.282797999985516","200","","-446.34326171875","-1402.32763671875","-0.00000762939453125","0"
"NativeDropoutBackward0","4.8398399999961255","8.793431999996304","0","0.8708999999947846","200","","955.984375","-55.1318359375","-0.00000762939453125","0"
"aten::native_dropout_backward","4.8398399999961255","7.92253200000152","4.8398399999961255","3.124739000014961","200","","1011.1162109375","-565.28076171875","-0.00000762939453125","0"
"void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_scale_kernel<bool, float, float>(at::Tensor&, at::Tensor const&, at::Tensor const&, float)::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)","4.8398399999961255","0","4.8398399999961255","0","200","","0","0","0","0"
"fmha_cutlassB_f32_aligned_64x64_k64_dropout_sm80(PyTorchMemEffAttention::AttentionBackwardKernel<cutlass::arch::Sm80, float, true, true, false, 64, 64, 64, false>::Params)","369.79880299999377","0","369.79880299999377","0","96","","0","0","0","0"